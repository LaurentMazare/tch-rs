// THIS FILE IS AUTOMATICALLY GENERATED, DO NOT EDIT BY HAND!

void atg_abs(tensor *, tensor self);
void atg_abs_(tensor *, tensor self);
void atg_abs_out(tensor *, tensor result, tensor self);
void atg_acos(tensor *, tensor self);
void atg_acos_(tensor *, tensor self);
void atg_acos_out(tensor *, tensor result, tensor self);
void atg_adaptive_avg_pool1d(tensor *, tensor self, int64_t *output_size_data, int output_size_len);
void atg_adaptive_avg_pool2d(tensor *, tensor self, int64_t *output_size_data, int output_size_len);
void atg_adaptive_avg_pool2d_backward(tensor *, tensor grad_output, tensor self);
void atg_adaptive_avg_pool2d_backward_out(tensor *, tensor grad_input, tensor grad_output, tensor self);
void atg_adaptive_avg_pool2d_out(tensor *, tensor output, tensor self, int64_t *output_size_data, int output_size_len);
void atg_adaptive_avg_pool3d(tensor *, tensor self, int64_t *output_size_data, int output_size_len);
void atg_adaptive_avg_pool3d_backward(tensor *, tensor grad_output, tensor self);
void atg_adaptive_avg_pool3d_backward_out(tensor *, tensor grad_input, tensor grad_output, tensor self);
void atg_adaptive_avg_pool3d_out(tensor *, tensor output, tensor self, int64_t *output_size_data, int output_size_len);
void atg_adaptive_max_pool1d(tensor *, tensor self, int64_t *output_size_data, int output_size_len);
void atg_adaptive_max_pool2d(tensor *, tensor self, int64_t *output_size_data, int output_size_len);
void atg_adaptive_max_pool2d_backward(tensor *, tensor grad_output, tensor self, tensor indices);
void atg_adaptive_max_pool2d_backward_out(tensor *, tensor grad_input, tensor grad_output, tensor self, tensor indices);
void atg_adaptive_max_pool2d_out(tensor *, tensor output, tensor indices, tensor self, int64_t *output_size_data, int output_size_len);
void atg_adaptive_max_pool3d(tensor *, tensor self, int64_t *output_size_data, int output_size_len);
void atg_adaptive_max_pool3d_backward(tensor *, tensor grad_output, tensor self, tensor indices);
void atg_adaptive_max_pool3d_backward_out(tensor *, tensor grad_input, tensor grad_output, tensor self, tensor indices);
void atg_adaptive_max_pool3d_out(tensor *, tensor output, tensor indices, tensor self, int64_t *output_size_data, int output_size_len);
void atg_add(tensor *, tensor self, tensor other);
void atg_add1(tensor *, tensor self, scalar other);
void atg_add_(tensor *, tensor self, tensor other);
void atg_add_1(tensor *, tensor self, scalar other);
void atg_add_out(tensor *, tensor result, tensor self, tensor other);
void atg_addbmm(tensor *, tensor self, tensor batch1, tensor batch2);
void atg_addbmm_(tensor *, tensor self, tensor batch1, tensor batch2);
void atg_addbmm_out(tensor *, tensor result, tensor self, tensor batch1, tensor batch2);
void atg_addcdiv(tensor *, tensor self, tensor tensor1, tensor tensor2);
void atg_addcdiv_(tensor *, tensor self, tensor tensor1, tensor tensor2);
void atg_addcdiv_out(tensor *, tensor result, tensor self, tensor tensor1, tensor tensor2);
void atg_addcmul(tensor *, tensor self, tensor tensor1, tensor tensor2);
void atg_addcmul_(tensor *, tensor self, tensor tensor1, tensor tensor2);
void atg_addcmul_out(tensor *, tensor result, tensor self, tensor tensor1, tensor tensor2);
void atg_addmm(tensor *, tensor self, tensor mat1, tensor mat2);
void atg_addmm_(tensor *, tensor self, tensor mat1, tensor mat2);
void atg_addmm_out(tensor *, tensor result, tensor self, tensor mat1, tensor mat2);
void atg_addmv(tensor *, tensor self, tensor mat, tensor vec);
void atg_addmv_(tensor *, tensor self, tensor mat, tensor vec);
void atg_addmv_out(tensor *, tensor result, tensor self, tensor mat, tensor vec);
void atg_addr(tensor *, tensor self, tensor vec1, tensor vec2);
void atg_addr_(tensor *, tensor self, tensor vec1, tensor vec2);
void atg_addr_out(tensor *, tensor result, tensor self, tensor vec1, tensor vec2);
void atg_alias(tensor *, tensor self);
void atg_all(tensor *, tensor self);
void atg_all1(tensor *, tensor self, int64_t dim, int keepdim);
void atg_all_out(tensor *, tensor result, tensor self, int64_t dim, int keepdim);
void atg_alpha_dropout(tensor *, tensor input, double p, int train);
void atg_alpha_dropout_(tensor *, tensor self, double p, int train);
void atg_any(tensor *, tensor self);
void atg_any1(tensor *, tensor self, int64_t dim, int keepdim);
void atg_any_out(tensor *, tensor result, tensor self, int64_t dim, int keepdim);
void atg_arange(tensor *, scalar end, int options_kind, int options_device);
void atg_arange1(tensor *, scalar start, scalar end, int options_kind, int options_device);
void atg_arange2(tensor *, scalar start, scalar end, scalar step, int options_kind, int options_device);
void atg_arange_out(tensor *, tensor result, scalar end);
void atg_arange_out1(tensor *, tensor result, scalar start, scalar end);
void atg_arange_out2(tensor *, tensor result, scalar start, scalar end, scalar step);
void atg_argmax(tensor *, tensor self);
void atg_argmax1(tensor *, tensor self, int64_t dim, int keepdim);
void atg_argmin(tensor *, tensor self);
void atg_argmin1(tensor *, tensor self, int64_t dim, int keepdim);
void atg_as_strided(tensor *, tensor self, int64_t *size_data, int size_len, int64_t *stride_data, int stride_len);
void atg_as_strided1(tensor *, tensor self, int64_t *size_data, int size_len, int64_t *stride_data, int stride_len, int64_t storage_offset);
void atg_as_strided_(tensor *, tensor self, int64_t *size_data, int size_len, int64_t *stride_data, int stride_len);
void atg_as_strided_1(tensor *, tensor self, int64_t *size_data, int size_len, int64_t *stride_data, int stride_len, int64_t storage_offset);
void atg_asin(tensor *, tensor self);
void atg_asin_(tensor *, tensor self);
void atg_asin_out(tensor *, tensor result, tensor self);
void atg_atan(tensor *, tensor self);
void atg_atan2(tensor *, tensor self, tensor other);
void atg_atan2_(tensor *, tensor self, tensor other);
void atg_atan2_out(tensor *, tensor result, tensor self, tensor other);
void atg_atan_(tensor *, tensor self);
void atg_atan_out(tensor *, tensor result, tensor self);
void atg_avg_pool1d(tensor *, tensor self, int64_t *kernel_size_data, int kernel_size_len, int64_t *stride_data, int stride_len, int64_t *padding_data, int padding_len, int ceil_mode, int count_include_pad);
void atg_avg_pool2d(tensor *, tensor self, int64_t *kernel_size_data, int kernel_size_len, int64_t *stride_data, int stride_len, int64_t *padding_data, int padding_len, int ceil_mode, int count_include_pad);
void atg_avg_pool2d_backward(tensor *, tensor grad_output, tensor self, int64_t *kernel_size_data, int kernel_size_len, int64_t *stride_data, int stride_len, int64_t *padding_data, int padding_len, int ceil_mode, int count_include_pad);
void atg_avg_pool2d_backward_out(tensor *, tensor grad_input, tensor grad_output, tensor self, int64_t *kernel_size_data, int kernel_size_len, int64_t *stride_data, int stride_len, int64_t *padding_data, int padding_len, int ceil_mode, int count_include_pad);
void atg_avg_pool2d_out(tensor *, tensor output, tensor self, int64_t *kernel_size_data, int kernel_size_len, int64_t *stride_data, int stride_len, int64_t *padding_data, int padding_len, int ceil_mode, int count_include_pad);
void atg_avg_pool3d(tensor *, tensor self, int64_t *kernel_size_data, int kernel_size_len, int64_t *stride_data, int stride_len, int64_t *padding_data, int padding_len, int ceil_mode, int count_include_pad);
void atg_avg_pool3d_backward(tensor *, tensor grad_output, tensor self, int64_t *kernel_size_data, int kernel_size_len, int64_t *stride_data, int stride_len, int64_t *padding_data, int padding_len, int ceil_mode, int count_include_pad);
void atg_avg_pool3d_backward_out(tensor *, tensor grad_input, tensor grad_output, tensor self, int64_t *kernel_size_data, int kernel_size_len, int64_t *stride_data, int stride_len, int64_t *padding_data, int padding_len, int ceil_mode, int count_include_pad);
void atg_avg_pool3d_out(tensor *, tensor output, tensor self, int64_t *kernel_size_data, int kernel_size_len, int64_t *stride_data, int stride_len, int64_t *padding_data, int padding_len, int ceil_mode, int count_include_pad);
void atg_baddbmm(tensor *, tensor self, tensor batch1, tensor batch2);
void atg_baddbmm_(tensor *, tensor self, tensor batch1, tensor batch2);
void atg_baddbmm_out(tensor *, tensor result, tensor self, tensor batch1, tensor batch2);
void atg_bartlett_window(tensor *, int64_t window_length, int options_kind, int options_device);
void atg_bartlett_window1(tensor *, int64_t window_length, int periodic, int options_kind, int options_device);
void atg_batch_norm(tensor *, tensor input, tensor weight, tensor bias, tensor running_mean, tensor running_var, int training, double momentum, double eps, int cudnn_enabled);
void atg_bernoulli(tensor *, tensor self);
void atg_bernoulli1(tensor *, tensor self, double p);
void atg_bernoulli_(tensor *, tensor self, tensor p);
void atg_bernoulli_1(tensor *, tensor self, double p);
void atg_bernoulli_out(tensor *, tensor result, tensor self);
void atg_bilinear(tensor *, tensor input1, tensor input2, tensor weight, tensor bias);
void atg_binary_cross_entropy(tensor *, tensor self, tensor target, tensor weight, int64_t reduction);
void atg_binary_cross_entropy_backward(tensor *, tensor grad_output, tensor self, tensor target, tensor weight, int64_t reduction);
void atg_binary_cross_entropy_backward_out(tensor *, tensor grad_input, tensor grad_output, tensor self, tensor target, tensor weight, int64_t reduction);
void atg_binary_cross_entropy_out(tensor *, tensor output, tensor self, tensor target, tensor weight, int64_t reduction);
void atg_binary_cross_entropy_with_logits(tensor *, tensor self, tensor target, tensor weight, tensor pos_weight, int64_t reduction);
void atg_binary_cross_entropy_with_logits_backward(tensor *, tensor grad_output, tensor self, tensor target, tensor weight, tensor pos_weight, int64_t reduction);
void atg_bincount(tensor *, tensor self, tensor weights, int64_t minlength);
void atg_blackman_window(tensor *, int64_t window_length, int options_kind, int options_device);
void atg_blackman_window1(tensor *, int64_t window_length, int periodic, int options_kind, int options_device);
void atg_bmm(tensor *, tensor self, tensor mat2);
void atg_bmm_out(tensor *, tensor result, tensor self, tensor mat2);
void atg_btrifact(tensor *, tensor self, int pivot);
void atg_btrifact_out(tensor *, tensor A_LU, tensor pivots, tensor self, int pivot);
void atg_btrifact_with_info(tensor *, tensor self, int pivot);
void atg_btrifact_with_info_out(tensor *, tensor A_LU, tensor pivots, tensor info, tensor self, int pivot);
void atg_btrisolve(tensor *, tensor self, tensor LU_data, tensor LU_pivots);
void atg_btrisolve_out(tensor *, tensor result, tensor self, tensor LU_data, tensor LU_pivots);
void atg_cat(tensor *, tensor *tensors_data, int tensors_len, int64_t dim);
void atg_cat_out(tensor *, tensor result, tensor *tensors_data, int tensors_len, int64_t dim);
void atg_cauchy_(tensor *, tensor self, double median, double sigma);
void atg_ceil(tensor *, tensor self);
void atg_ceil_(tensor *, tensor self);
void atg_ceil_out(tensor *, tensor result, tensor self);
void atg_celu(tensor *, tensor self);
void atg_celu_(tensor *, tensor self);
void atg_chain_matmul(tensor *, tensor *matrices_data, int matrices_len);
void atg_cholesky(tensor *, tensor self, int upper);
void atg_cholesky_out(tensor *, tensor result, tensor self, int upper);
void atg_clamp(tensor *, tensor self, scalar min, scalar max);
void atg_clamp_(tensor *, tensor self, scalar min, scalar max);
void atg_clamp_max(tensor *, tensor self, scalar max);
void atg_clamp_max_(tensor *, tensor self, scalar max);
void atg_clamp_max_out(tensor *, tensor result, tensor self, scalar max);
void atg_clamp_min(tensor *, tensor self, scalar min);
void atg_clamp_min_(tensor *, tensor self, scalar min);
void atg_clamp_min_out(tensor *, tensor result, tensor self, scalar min);
void atg_clamp_out(tensor *, tensor result, tensor self, scalar min, scalar max);
void atg_clone(tensor *, tensor self);
void atg_coalesce(tensor *, tensor self);
void atg_constant_pad_nd(tensor *, tensor self, int64_t *pad_data, int pad_len);
void atg_contiguous(tensor *, tensor self);
void atg_conv1d(tensor *, tensor input, tensor weight, tensor bias, int64_t *stride_data, int stride_len, int64_t *padding_data, int padding_len, int64_t *dilation_data, int dilation_len, int64_t groups);
void atg_conv2d(tensor *, tensor input, tensor weight, tensor bias, int64_t *stride_data, int stride_len, int64_t *padding_data, int padding_len, int64_t *dilation_data, int dilation_len, int64_t groups);
void atg_conv3d(tensor *, tensor input, tensor weight, tensor bias, int64_t *stride_data, int stride_len, int64_t *padding_data, int padding_len, int64_t *dilation_data, int dilation_len, int64_t groups);
void atg_conv_tbc(tensor *, tensor self, tensor weight, tensor bias, int64_t pad);
void atg_conv_tbc_backward(tensor *, tensor self, tensor input, tensor weight, tensor bias, int64_t pad);
void atg_conv_transpose1d(tensor *, tensor input, tensor weight, tensor bias, int64_t *stride_data, int stride_len, int64_t *padding_data, int padding_len, int64_t *output_padding_data, int output_padding_len, int64_t groups, int64_t *dilation_data, int dilation_len);
void atg_conv_transpose2d(tensor *, tensor input, tensor weight, tensor bias, int64_t *stride_data, int stride_len, int64_t *padding_data, int padding_len, int64_t *output_padding_data, int output_padding_len, int64_t groups, int64_t *dilation_data, int dilation_len);
void atg_conv_transpose3d(tensor *, tensor input, tensor weight, tensor bias, int64_t *stride_data, int stride_len, int64_t *padding_data, int padding_len, int64_t *output_padding_data, int output_padding_len, int64_t groups, int64_t *dilation_data, int dilation_len);
void atg_convolution(tensor *, tensor input, tensor weight, tensor bias, int64_t *stride_data, int stride_len, int64_t *padding_data, int padding_len, int64_t *dilation_data, int dilation_len, int transposed, int64_t *output_padding_data, int output_padding_len, int64_t groups);
void atg_copy_sparse_to_sparse_(tensor *, tensor self, tensor src, int non_blocking);
void atg_cos(tensor *, tensor self);
void atg_cos_(tensor *, tensor self);
void atg_cos_out(tensor *, tensor result, tensor self);
void atg_cosh(tensor *, tensor self);
void atg_cosh_(tensor *, tensor self);
void atg_cosh_out(tensor *, tensor result, tensor self);
void atg_cosine_embedding_loss(tensor *, tensor input1, tensor input2, tensor target, double margin, int64_t reduction);
void atg_cross(tensor *, tensor self, tensor other, int64_t dim);
void atg_cross_out(tensor *, tensor result, tensor self, tensor other, int64_t dim);
void atg_ctc_loss(tensor *, tensor log_probs, tensor targets, int64_t *input_lengths_data, int input_lengths_len, int64_t *target_lengths_data, int target_lengths_len, int64_t blank, int64_t reduction);
void atg_ctc_loss1(tensor *, tensor log_probs, tensor targets, tensor input_lengths, tensor target_lengths, int64_t blank, int64_t reduction);
void atg_cudnn_affine_grid_generator(tensor *, tensor theta, int64_t N, int64_t C, int64_t H, int64_t W);
void atg_cudnn_affine_grid_generator_backward(tensor *, tensor grad, int64_t N, int64_t C, int64_t H, int64_t W);
void atg_cudnn_batch_norm(tensor *, tensor input, tensor weight, tensor bias, tensor running_mean, tensor running_var, int training, double exponential_average_factor, double epsilon);
void atg_cudnn_batch_norm_backward(tensor *, tensor input, tensor grad_output, tensor weight, tensor running_mean, tensor running_var, tensor save_mean, tensor save_var, double epsilon);
void atg_cudnn_convolution(tensor *, tensor self, tensor weight, tensor bias, int64_t *padding_data, int padding_len, int64_t *stride_data, int stride_len, int64_t *dilation_data, int dilation_len, int64_t groups, int benchmark, int deterministic);
void atg_cudnn_convolution_backward_bias(tensor *, tensor grad_output);
void atg_cudnn_convolution_backward_input(tensor *, int64_t *self_size_data, int self_size_len, tensor grad_output, tensor weight, int64_t *padding_data, int padding_len, int64_t *stride_data, int stride_len, int64_t *dilation_data, int dilation_len, int64_t groups, int benchmark, int deterministic);
void atg_cudnn_convolution_backward_weight(tensor *, int64_t *weight_size_data, int weight_size_len, tensor grad_output, tensor self, int64_t *padding_data, int padding_len, int64_t *stride_data, int stride_len, int64_t *dilation_data, int dilation_len, int64_t groups, int benchmark, int deterministic);
void atg_cudnn_convolution_transpose(tensor *, tensor self, tensor weight, tensor bias, int64_t *padding_data, int padding_len, int64_t *output_padding_data, int output_padding_len, int64_t *stride_data, int stride_len, int64_t *dilation_data, int dilation_len, int64_t groups, int benchmark, int deterministic);
void atg_cudnn_convolution_transpose_backward_bias(tensor *, tensor grad_output);
void atg_cudnn_convolution_transpose_backward_input(tensor *, tensor grad_output, tensor weight, int64_t *padding_data, int padding_len, int64_t *stride_data, int stride_len, int64_t *dilation_data, int dilation_len, int64_t groups, int benchmark, int deterministic);
void atg_cudnn_convolution_transpose_backward_weight(tensor *, int64_t *weight_size_data, int weight_size_len, tensor grad_output, tensor self, int64_t *padding_data, int padding_len, int64_t *stride_data, int stride_len, int64_t *dilation_data, int dilation_len, int64_t groups, int benchmark, int deterministic);
void atg_cudnn_grid_sampler(tensor *, tensor self, tensor grid);
void atg_cudnn_grid_sampler_backward(tensor *, tensor self, tensor grid, tensor grad_output);
void atg_cumprod(tensor *, tensor self, int64_t dim);
void atg_cumprod1(tensor *, tensor self, int64_t dim, int dtype);
void atg_cumprod_out(tensor *, tensor result, tensor self, int64_t dim);
void atg_cumprod_out1(tensor *, tensor result, tensor self, int64_t dim, int dtype);
void atg_cumsum(tensor *, tensor self, int64_t dim);
void atg_cumsum1(tensor *, tensor self, int64_t dim, int dtype);
void atg_cumsum_out(tensor *, tensor result, tensor self, int64_t dim);
void atg_cumsum_out1(tensor *, tensor result, tensor self, int64_t dim, int dtype);
void atg_det(tensor *, tensor self);
void atg_detach(tensor *, tensor self);
void atg_detach_(tensor *, tensor self);
void atg_diag(tensor *, tensor self, int64_t diagonal);
void atg_diag_embed(tensor *, tensor self, int64_t offset, int64_t dim1, int64_t dim2);
void atg_diag_out(tensor *, tensor result, tensor self, int64_t diagonal);
void atg_diagflat(tensor *, tensor self, int64_t offset);
void atg_diagonal(tensor *, tensor self, int64_t offset, int64_t dim1, int64_t dim2);
void atg_digamma(tensor *, tensor self);
void atg_digamma_(tensor *, tensor self);
void atg_digamma_out(tensor *, tensor result, tensor self);
void atg_dist(tensor *, tensor self, tensor other);
void atg_div(tensor *, tensor self, tensor other);
void atg_div1(tensor *, tensor self, scalar other);
void atg_div_(tensor *, tensor self, tensor other);
void atg_div_1(tensor *, tensor self, scalar other);
void atg_div_out(tensor *, tensor result, tensor self, tensor other);
void atg_dot(tensor *, tensor self, tensor tensor);
void atg_dot_out(tensor *, tensor result, tensor self, tensor tensor);
void atg_dropout(tensor *, tensor input, double p, int train);
void atg_dropout_(tensor *, tensor self, double p, int train);
void atg_eig(tensor *, tensor self, int eigenvectors);
void atg_eig_out(tensor *, tensor e, tensor v, tensor self, int eigenvectors);
void atg_elu(tensor *, tensor self);
void atg_elu_(tensor *, tensor self);
void atg_elu_out(tensor *, tensor output, tensor self);
void atg_embedding(tensor *, tensor weight, tensor indices, int64_t padding_idx, int scale_grad_by_freq, int sparse);
void atg_embedding_backward(tensor *, tensor grad, tensor indices, int64_t num_weights, int64_t padding_idx, int scale_grad_by_freq, int sparse);
void atg_embedding_bag(tensor *, tensor weight, tensor indices, tensor offsets, int scale_grad_by_freq, int64_t mode, int sparse);
void atg_embedding_dense_backward(tensor *, tensor grad, tensor indices, int64_t num_weights, int64_t padding_idx, int scale_grad_by_freq);
void atg_embedding_renorm_(tensor *, tensor self, tensor indices, double max_norm, double norm_type);
void atg_embedding_sparse_backward(tensor *, tensor grad, tensor indices, int64_t num_weights, int64_t padding_idx, int scale_grad_by_freq);
void atg_empty(tensor *, int64_t *size_data, int size_len, int options_kind, int options_device);
void atg_empty_like(tensor *, tensor self);
void atg_empty_like1(tensor *, tensor self, int options_kind, int options_device);
void atg_empty_out(tensor *, tensor result, int64_t *size_data, int size_len);
void atg_empty_strided(tensor *, int64_t *size_data, int size_len, int64_t *stride_data, int stride_len, int options_kind, int options_device);
void atg_eq(tensor *, tensor self, scalar other);
void atg_eq1(tensor *, tensor self, tensor other);
void atg_eq_(tensor *, tensor self, scalar other);
void atg_eq_1(tensor *, tensor self, tensor other);
void atg_eq_out(tensor *, tensor result, tensor self, scalar other);
void atg_eq_out1(tensor *, tensor result, tensor self, tensor other);
void atg_erf(tensor *, tensor self);
void atg_erf_(tensor *, tensor self);
void atg_erf_out(tensor *, tensor result, tensor self);
void atg_erfc(tensor *, tensor self);
void atg_erfc_(tensor *, tensor self);
void atg_erfc_out(tensor *, tensor result, tensor self);
void atg_erfinv(tensor *, tensor self);
void atg_erfinv_(tensor *, tensor self);
void atg_erfinv_out(tensor *, tensor result, tensor self);
void atg_exp(tensor *, tensor self);
void atg_exp_(tensor *, tensor self);
void atg_exp_out(tensor *, tensor result, tensor self);
void atg_expand(tensor *, tensor self, int64_t *size_data, int size_len, int implicit);
void atg_expand_as(tensor *, tensor self, tensor other);
void atg_expm1(tensor *, tensor self);
void atg_expm1_(tensor *, tensor self);
void atg_expm1_out(tensor *, tensor result, tensor self);
void atg_exponential_(tensor *, tensor self, double lambd);
void atg_eye(tensor *, int64_t n, int options_kind, int options_device);
void atg_eye1(tensor *, int64_t n, int64_t m, int options_kind, int options_device);
void atg_eye_out(tensor *, tensor result, int64_t n);
void atg_eye_out1(tensor *, tensor result, int64_t n, int64_t m);
void atg_feature_alpha_dropout(tensor *, tensor input, double p, int train);
void atg_feature_alpha_dropout_(tensor *, tensor self, double p, int train);
void atg_feature_dropout(tensor *, tensor input, double p, int train);
void atg_feature_dropout_(tensor *, tensor self, double p, int train);
void atg_fft(tensor *, tensor self, int64_t signal_ndim, int normalized);
void atg_fill_(tensor *, tensor self, scalar value);
void atg_fill_1(tensor *, tensor self, tensor value);
void atg_flatten(tensor *, tensor self, int64_t start_dim, int64_t end_dim);
void atg_flip(tensor *, tensor self, int64_t *dims_data, int dims_len);
void atg_floor(tensor *, tensor self);
void atg_floor_(tensor *, tensor self);
void atg_floor_out(tensor *, tensor result, tensor self);
void atg_fmod(tensor *, tensor self, scalar other);
void atg_fmod1(tensor *, tensor self, tensor other);
void atg_fmod_(tensor *, tensor self, scalar other);
void atg_fmod_1(tensor *, tensor self, tensor other);
void atg_fmod_out(tensor *, tensor result, tensor self, scalar other);
void atg_fmod_out1(tensor *, tensor result, tensor self, tensor other);
void atg_frac(tensor *, tensor self);
void atg_frac_(tensor *, tensor self);
void atg_frac_out(tensor *, tensor result, tensor self);
void atg_fractional_max_pool2d(tensor *, tensor self, int64_t *kernel_size_data, int kernel_size_len, int64_t *output_size_data, int output_size_len, tensor random_samples);
void atg_fractional_max_pool2d_backward(tensor *, tensor grad_output, tensor self, int64_t *kernel_size_data, int kernel_size_len, int64_t *output_size_data, int output_size_len, tensor indices);
void atg_fractional_max_pool2d_backward_out(tensor *, tensor grad_input, tensor grad_output, tensor self, int64_t *kernel_size_data, int kernel_size_len, int64_t *output_size_data, int output_size_len, tensor indices);
void atg_fractional_max_pool2d_out(tensor *, tensor output, tensor indices, tensor self, int64_t *kernel_size_data, int kernel_size_len, int64_t *output_size_data, int output_size_len, tensor random_samples);
void atg_frobenius_norm(tensor *, tensor self);
void atg_frobenius_norm1(tensor *, tensor self, int64_t *dim_data, int dim_len, int keepdim);
void atg_frobenius_norm_out(tensor *, tensor result, tensor self, int64_t *dim_data, int dim_len, int keepdim);
void atg_full(tensor *, int64_t *size_data, int size_len, scalar fill_value, int options_kind, int options_device);
void atg_full_like(tensor *, tensor self, scalar fill_value);
void atg_full_like1(tensor *, tensor self, scalar fill_value, int options_kind, int options_device);
void atg_full_out(tensor *, tensor result, int64_t *size_data, int size_len, scalar fill_value);
void atg_gather(tensor *, tensor self, int64_t dim, tensor index);
void atg_gather_out(tensor *, tensor result, tensor self, int64_t dim, tensor index);
void atg_ge(tensor *, tensor self, scalar other);
void atg_ge1(tensor *, tensor self, tensor other);
void atg_ge_(tensor *, tensor self, scalar other);
void atg_ge_1(tensor *, tensor self, tensor other);
void atg_ge_out(tensor *, tensor result, tensor self, scalar other);
void atg_ge_out1(tensor *, tensor result, tensor self, tensor other);
void atg_gels(tensor *, tensor self, tensor A);
void atg_gels_out(tensor *, tensor X, tensor qr, tensor self, tensor A);
void atg_geometric_(tensor *, tensor self, double p);
void atg_geqrf(tensor *, tensor self);
void atg_geqrf_out(tensor *, tensor result0, tensor result1, tensor self);
void atg_ger(tensor *, tensor self, tensor vec2);
void atg_ger_out(tensor *, tensor result, tensor self, tensor vec2);
void atg_gesv(tensor *, tensor self, tensor A);
void atg_gesv_out(tensor *, tensor solution, tensor lu, tensor self, tensor A);
void atg_glu(tensor *, tensor self, int64_t dim);
void atg_glu_backward(tensor *, tensor grad_output, tensor self, int64_t dim);
void atg_glu_backward_out(tensor *, tensor grad_input, tensor grad_output, tensor self, int64_t dim);
void atg_glu_out(tensor *, tensor output, tensor self, int64_t dim);
void atg_grad(tensor *, tensor self);
void atg_grid_sampler(tensor *, tensor input, tensor grid, int64_t interpolation_mode, int64_t padding_mode);
void atg_grid_sampler_2d(tensor *, tensor input, tensor grid, int64_t interpolation_mode, int64_t padding_mode);
void atg_grid_sampler_2d_backward(tensor *, tensor grad_output, tensor input, tensor grid, int64_t interpolation_mode, int64_t padding_mode);
void atg_grid_sampler_3d(tensor *, tensor input, tensor grid, int64_t interpolation_mode, int64_t padding_mode);
void atg_grid_sampler_3d_backward(tensor *, tensor grad_output, tensor input, tensor grid, int64_t interpolation_mode, int64_t padding_mode);
void atg_group_norm(tensor *, tensor input, int64_t num_groups, tensor weight, tensor bias, double eps, int cudnn_enabled);
void atg_gru(tensor *, tensor input, tensor hx, tensor *params_data, int params_len, int has_biases, int64_t num_layers, double dropout, int train, int bidirectional, int batch_first);
void atg_gru1(tensor *, tensor data, tensor batch_sizes, tensor hx, tensor *params_data, int params_len, int has_biases, int64_t num_layers, double dropout, int train, int bidirectional);
void atg_gru_cell(tensor *, tensor input, tensor hx, tensor w_ih, tensor w_hh, tensor b_ih, tensor b_hh);
void atg_gt(tensor *, tensor self, scalar other);
void atg_gt1(tensor *, tensor self, tensor other);
void atg_gt_(tensor *, tensor self, scalar other);
void atg_gt_1(tensor *, tensor self, tensor other);
void atg_gt_out(tensor *, tensor result, tensor self, scalar other);
void atg_gt_out1(tensor *, tensor result, tensor self, tensor other);
void atg_hamming_window(tensor *, int64_t window_length, int options_kind, int options_device);
void atg_hamming_window1(tensor *, int64_t window_length, int periodic, int options_kind, int options_device);
void atg_hamming_window2(tensor *, int64_t window_length, int periodic, double alpha, int options_kind, int options_device);
void atg_hamming_window3(tensor *, int64_t window_length, int periodic, double alpha, double beta, int options_kind, int options_device);
void atg_hann_window(tensor *, int64_t window_length, int options_kind, int options_device);
void atg_hann_window1(tensor *, int64_t window_length, int periodic, int options_kind, int options_device);
void atg_hardshrink(tensor *, tensor self);
void atg_hardshrink_backward(tensor *, tensor grad_out, tensor self, scalar lambd);
void atg_hardtanh(tensor *, tensor self);
void atg_hardtanh_(tensor *, tensor self);
void atg_hardtanh_out(tensor *, tensor output, tensor self);
void atg_hinge_embedding_loss(tensor *, tensor self, tensor target, double margin, int64_t reduction);
void atg_histc(tensor *, tensor self, int64_t bins);
void atg_histc_out(tensor *, tensor result, tensor self, int64_t bins);
void atg_hspmm(tensor *, tensor mat1, tensor mat2);
void atg_hspmm_out(tensor *, tensor result, tensor mat1, tensor mat2);
void atg_ifft(tensor *, tensor self, int64_t signal_ndim, int normalized);
void atg_index(tensor *, tensor self, tensor *indices_data, int indices_len);
void atg_index_add_(tensor *, tensor self, int64_t dim, tensor index, tensor source);
void atg_index_copy_(tensor *, tensor self, int64_t dim, tensor index, tensor source);
void atg_index_fill_(tensor *, tensor self, int64_t dim, tensor index, scalar value);
void atg_index_fill_1(tensor *, tensor self, int64_t dim, tensor index, tensor value);
void atg_index_put(tensor *, tensor self, tensor *indices_data, int indices_len, tensor values);
void atg_index_put_(tensor *, tensor self, tensor *indices_data, int indices_len, tensor values);
void atg_index_select(tensor *, tensor self, int64_t dim, tensor index);
void atg_index_select_out(tensor *, tensor result, tensor self, int64_t dim, tensor index);
void atg_indices(tensor *, tensor self);
void atg_instance_norm(tensor *, tensor input, tensor weight, tensor bias, tensor running_mean, tensor running_var, int use_input_stats, double momentum, double eps, int cudnn_enabled);
void atg_inverse(tensor *, tensor self);
void atg_inverse_out(tensor *, tensor result, tensor self);
void atg_irfft(tensor *, tensor self, int64_t signal_ndim, int normalized, int onesided, int64_t *signal_sizes_data, int signal_sizes_len);
void atg_isclose(tensor *, tensor self, tensor other, double rtol, double atol, int equal_nan);
void atg_kl_div(tensor *, tensor self, tensor target, int64_t reduction);
void atg_kl_div_backward(tensor *, tensor grad_output, tensor self, tensor target, int64_t reduction);
void atg_kthvalue(tensor *, tensor self, int64_t k, int64_t dim, int keepdim);
void atg_kthvalue_out(tensor *, tensor values, tensor indices, tensor self, int64_t k, int64_t dim, int keepdim);
void atg_l1_loss(tensor *, tensor self, tensor target, int64_t reduction);
void atg_l1_loss_backward(tensor *, tensor grad_output, tensor self, tensor target, int64_t reduction);
void atg_l1_loss_backward_out(tensor *, tensor grad_input, tensor grad_output, tensor self, tensor target, int64_t reduction);
void atg_l1_loss_out(tensor *, tensor output, tensor self, tensor target, int64_t reduction);
void atg_layer_norm(tensor *, tensor input, int64_t *normalized_shape_data, int normalized_shape_len, tensor weight, tensor bias, double eps, int cudnn_enable);
void atg_le(tensor *, tensor self, scalar other);
void atg_le1(tensor *, tensor self, tensor other);
void atg_le_(tensor *, tensor self, scalar other);
void atg_le_1(tensor *, tensor self, tensor other);
void atg_le_out(tensor *, tensor result, tensor self, scalar other);
void atg_le_out1(tensor *, tensor result, tensor self, tensor other);
void atg_leaky_relu(tensor *, tensor self);
void atg_leaky_relu_(tensor *, tensor self);
void atg_leaky_relu_out(tensor *, tensor output, tensor self);
void atg_lerp(tensor *, tensor self, tensor end, scalar weight);
void atg_lerp_(tensor *, tensor self, tensor end, scalar weight);
void atg_lerp_out(tensor *, tensor result, tensor self, tensor end, scalar weight);
void atg_lgamma(tensor *, tensor self);
void atg_lgamma_(tensor *, tensor self);
void atg_lgamma_out(tensor *, tensor result, tensor self);
void atg_linear(tensor *, tensor input, tensor weight, tensor bias);
void atg_linspace(tensor *, scalar start, scalar end, int options_kind, int options_device);
void atg_linspace1(tensor *, scalar start, scalar end, int64_t steps, int options_kind, int options_device);
void atg_linspace_out(tensor *, tensor result, scalar start, scalar end);
void atg_linspace_out1(tensor *, tensor result, scalar start, scalar end, int64_t steps);
void atg_log(tensor *, tensor self);
void atg_log10(tensor *, tensor self);
void atg_log10_(tensor *, tensor self);
void atg_log10_out(tensor *, tensor result, tensor self);
void atg_log1p(tensor *, tensor self);
void atg_log1p_(tensor *, tensor self);
void atg_log1p_out(tensor *, tensor result, tensor self);
void atg_log2(tensor *, tensor self);
void atg_log2_(tensor *, tensor self);
void atg_log2_out(tensor *, tensor result, tensor self);
void atg_log_(tensor *, tensor self);
void atg_log_normal_(tensor *, tensor self, double mean, double std);
void atg_log_out(tensor *, tensor result, tensor self);
void atg_log_sigmoid(tensor *, tensor self);
void atg_log_sigmoid_backward(tensor *, tensor grad_output, tensor self, tensor buffer);
void atg_log_sigmoid_backward_out(tensor *, tensor grad_input, tensor grad_output, tensor self, tensor buffer);
void atg_log_sigmoid_out(tensor *, tensor output, tensor self);
void atg_log_softmax(tensor *, tensor self, int64_t dim);
void atg_log_softmax1(tensor *, tensor self, int64_t dim, int dtype);
void atg_logdet(tensor *, tensor self);
void atg_logspace(tensor *, scalar start, scalar end, int options_kind, int options_device);
void atg_logspace1(tensor *, scalar start, scalar end, int64_t steps, int options_kind, int options_device);
void atg_logspace_out(tensor *, tensor result, scalar start, scalar end);
void atg_logspace_out1(tensor *, tensor result, scalar start, scalar end, int64_t steps);
void atg_logsumexp(tensor *, tensor self, int64_t dim, int keepdim);
void atg_logsumexp_out(tensor *, tensor result, tensor self, int64_t dim, int keepdim);
void atg_lstm(tensor *, tensor input, tensor *hx_data, int hx_len, tensor *params_data, int params_len, int has_biases, int64_t num_layers, double dropout, int train, int bidirectional, int batch_first);
void atg_lstm1(tensor *, tensor data, tensor batch_sizes, tensor *hx_data, int hx_len, tensor *params_data, int params_len, int has_biases, int64_t num_layers, double dropout, int train, int bidirectional);
void atg_lstm_cell(tensor *, tensor input, tensor *hx_data, int hx_len, tensor w_ih, tensor w_hh, tensor b_ih, tensor b_hh);
void atg_lt(tensor *, tensor self, scalar other);
void atg_lt1(tensor *, tensor self, tensor other);
void atg_lt_(tensor *, tensor self, scalar other);
void atg_lt_1(tensor *, tensor self, tensor other);
void atg_lt_out(tensor *, tensor result, tensor self, scalar other);
void atg_lt_out1(tensor *, tensor result, tensor self, tensor other);
void atg_margin_ranking_loss(tensor *, tensor input1, tensor input2, tensor target, double margin, int64_t reduction);
void atg_masked_fill_(tensor *, tensor self, tensor mask, scalar value);
void atg_masked_fill_1(tensor *, tensor self, tensor mask, tensor value);
void atg_masked_scatter_(tensor *, tensor self, tensor mask, tensor source);
void atg_masked_select(tensor *, tensor self, tensor mask);
void atg_masked_select_out(tensor *, tensor result, tensor self, tensor mask);
void atg_matmul(tensor *, tensor self, tensor other);
void atg_matmul_out(tensor *, tensor result, tensor self, tensor other);
void atg_matrix_power(tensor *, tensor self, int64_t n);
void atg_matrix_rank(tensor *, tensor self, int symmetric);
void atg_matrix_rank1(tensor *, tensor self, double tol, int symmetric);
void atg_max(tensor *, tensor self);
void atg_max1(tensor *, tensor self, tensor other);
void atg_max2(tensor *, tensor self, int64_t dim, int keepdim);
void atg_max_out(tensor *, tensor result, tensor self, tensor other);
void atg_max_out1(tensor *, tensor max, tensor max_values, tensor self, int64_t dim, int keepdim);
void atg_max_pool1d(tensor *, tensor self, int64_t *kernel_size_data, int kernel_size_len, int64_t *stride_data, int stride_len, int64_t *padding_data, int padding_len, int64_t *dilation_data, int dilation_len, int ceil_mode);
void atg_max_pool1d_with_indices(tensor *, tensor self, int64_t *kernel_size_data, int kernel_size_len, int64_t *stride_data, int stride_len, int64_t *padding_data, int padding_len, int64_t *dilation_data, int dilation_len, int ceil_mode);
void atg_max_pool2d(tensor *, tensor self, int64_t *kernel_size_data, int kernel_size_len, int64_t *stride_data, int stride_len, int64_t *padding_data, int padding_len, int64_t *dilation_data, int dilation_len, int ceil_mode);
void atg_max_pool2d_with_indices(tensor *, tensor self, int64_t *kernel_size_data, int kernel_size_len, int64_t *stride_data, int stride_len, int64_t *padding_data, int padding_len, int64_t *dilation_data, int dilation_len, int ceil_mode);
void atg_max_pool2d_with_indices_backward(tensor *, tensor grad_output, tensor self, int64_t *kernel_size_data, int kernel_size_len, int64_t *stride_data, int stride_len, int64_t *padding_data, int padding_len, int64_t *dilation_data, int dilation_len, int ceil_mode, tensor indices);
void atg_max_pool2d_with_indices_backward_out(tensor *, tensor grad_input, tensor grad_output, tensor self, int64_t *kernel_size_data, int kernel_size_len, int64_t *stride_data, int stride_len, int64_t *padding_data, int padding_len, int64_t *dilation_data, int dilation_len, int ceil_mode, tensor indices);
void atg_max_pool2d_with_indices_out(tensor *, tensor output, tensor indices, tensor self, int64_t *kernel_size_data, int kernel_size_len, int64_t *stride_data, int stride_len, int64_t *padding_data, int padding_len, int64_t *dilation_data, int dilation_len, int ceil_mode);
void atg_max_pool3d(tensor *, tensor self, int64_t *kernel_size_data, int kernel_size_len, int64_t *stride_data, int stride_len, int64_t *padding_data, int padding_len, int64_t *dilation_data, int dilation_len, int ceil_mode);
void atg_max_pool3d_with_indices(tensor *, tensor self, int64_t *kernel_size_data, int kernel_size_len, int64_t *stride_data, int stride_len, int64_t *padding_data, int padding_len, int64_t *dilation_data, int dilation_len, int ceil_mode);
void atg_max_pool3d_with_indices_backward(tensor *, tensor grad_output, tensor self, int64_t *kernel_size_data, int kernel_size_len, int64_t *stride_data, int stride_len, int64_t *padding_data, int padding_len, int64_t *dilation_data, int dilation_len, int ceil_mode, tensor indices);
void atg_max_pool3d_with_indices_backward_out(tensor *, tensor grad_input, tensor grad_output, tensor self, int64_t *kernel_size_data, int kernel_size_len, int64_t *stride_data, int stride_len, int64_t *padding_data, int padding_len, int64_t *dilation_data, int dilation_len, int ceil_mode, tensor indices);
void atg_max_pool3d_with_indices_out(tensor *, tensor output, tensor indices, tensor self, int64_t *kernel_size_data, int kernel_size_len, int64_t *stride_data, int stride_len, int64_t *padding_data, int padding_len, int64_t *dilation_data, int dilation_len, int ceil_mode);
void atg_max_unpool2d(tensor *, tensor self, tensor indices, int64_t *output_size_data, int output_size_len);
void atg_max_unpool2d_backward(tensor *, tensor grad_output, tensor self, tensor indices, int64_t *output_size_data, int output_size_len);
void atg_max_unpool2d_backward_out(tensor *, tensor grad_input, tensor grad_output, tensor self, tensor indices, int64_t *output_size_data, int output_size_len);
void atg_max_unpool2d_out(tensor *, tensor output, tensor self, tensor indices, int64_t *output_size_data, int output_size_len);
void atg_max_unpool3d(tensor *, tensor self, tensor indices, int64_t *output_size_data, int output_size_len, int64_t *stride_data, int stride_len, int64_t *padding_data, int padding_len);
void atg_max_unpool3d_backward(tensor *, tensor grad_output, tensor self, tensor indices, int64_t *output_size_data, int output_size_len, int64_t *stride_data, int stride_len, int64_t *padding_data, int padding_len);
void atg_max_unpool3d_backward_out(tensor *, tensor grad_input, tensor grad_output, tensor self, tensor indices, int64_t *output_size_data, int output_size_len, int64_t *stride_data, int stride_len, int64_t *padding_data, int padding_len);
void atg_max_unpool3d_out(tensor *, tensor output, tensor self, tensor indices, int64_t *output_size_data, int output_size_len, int64_t *stride_data, int stride_len, int64_t *padding_data, int padding_len);
void atg_max_values(tensor *, tensor self, int64_t dim, int keepdim);
void atg_mean(tensor *, tensor self);
void atg_mean1(tensor *, tensor self, int dtype);
void atg_mean2(tensor *, tensor self, int64_t dim, int keepdim);
void atg_mean3(tensor *, tensor self, int64_t dim, int dtype);
void atg_mean4(tensor *, tensor self, int64_t dim, int keepdim, int dtype);
void atg_mean_out(tensor *, tensor result, tensor self, int64_t dim, int keepdim);
void atg_mean_out1(tensor *, tensor result, tensor self, int64_t dim, int dtype);
void atg_mean_out2(tensor *, tensor result, tensor self, int64_t dim, int keepdim, int dtype);
void atg_median(tensor *, tensor self);
void atg_median1(tensor *, tensor self, int64_t dim, int keepdim);
void atg_median_out(tensor *, tensor values, tensor indices, tensor self, int64_t dim, int keepdim);
void atg_min(tensor *, tensor self);
void atg_min1(tensor *, tensor self, tensor other);
void atg_min2(tensor *, tensor self, int64_t dim, int keepdim);
void atg_min_out(tensor *, tensor result, tensor self, tensor other);
void atg_min_out1(tensor *, tensor min, tensor min_indices, tensor self, int64_t dim, int keepdim);
void atg_min_values(tensor *, tensor self, int64_t dim, int keepdim);
void atg_miopen_batch_norm(tensor *, tensor input, tensor weight, tensor bias, tensor running_mean, tensor running_var, int training, double exponential_average_factor, double epsilon);
void atg_miopen_batch_norm_backward(tensor *, tensor input, tensor grad_output, tensor weight, tensor running_mean, tensor running_var, tensor save_mean, tensor save_var, double epsilon);
void atg_miopen_convolution(tensor *, tensor self, tensor weight, tensor bias, int64_t *padding_data, int padding_len, int64_t *stride_data, int stride_len, int64_t *dilation_data, int dilation_len, int64_t groups, int benchmark, int deterministic);
void atg_miopen_convolution_backward_bias(tensor *, tensor grad_output);
void atg_miopen_convolution_backward_input(tensor *, int64_t *self_size_data, int self_size_len, tensor grad_output, tensor weight, int64_t *padding_data, int padding_len, int64_t *stride_data, int stride_len, int64_t *dilation_data, int dilation_len, int64_t groups, int benchmark, int deterministic);
void atg_miopen_convolution_backward_weight(tensor *, int64_t *weight_size_data, int weight_size_len, tensor grad_output, tensor self, int64_t *padding_data, int padding_len, int64_t *stride_data, int stride_len, int64_t *dilation_data, int dilation_len, int64_t groups, int benchmark, int deterministic);
void atg_miopen_convolution_transpose(tensor *, tensor self, tensor weight, tensor bias, int64_t *padding_data, int padding_len, int64_t *output_padding_data, int output_padding_len, int64_t *stride_data, int stride_len, int64_t *dilation_data, int dilation_len, int64_t groups, int benchmark, int deterministic);
void atg_miopen_convolution_transpose_backward_input(tensor *, tensor grad_output, tensor weight, int64_t *padding_data, int padding_len, int64_t *stride_data, int stride_len, int64_t *dilation_data, int dilation_len, int64_t groups, int benchmark, int deterministic);
void atg_miopen_convolution_transpose_backward_weight(tensor *, int64_t *weight_size_data, int weight_size_len, tensor grad_output, tensor self, int64_t *padding_data, int padding_len, int64_t *stride_data, int stride_len, int64_t *dilation_data, int dilation_len, int64_t groups, int benchmark, int deterministic);
void atg_mkldnn_convolution(tensor *, tensor self, tensor weight, tensor bias, int64_t *padding_data, int padding_len, int64_t *stride_data, int stride_len, int64_t *dilation_data, int dilation_len, int64_t groups);
void atg_mkldnn_convolution_backward_input(tensor *, int64_t *self_size_data, int self_size_len, tensor grad_output, tensor weight, int64_t *padding_data, int padding_len, int64_t *stride_data, int stride_len, int64_t *dilation_data, int dilation_len, int64_t groups, int bias_defined);
void atg_mkldnn_convolution_backward_weights(tensor *, int64_t *weight_size_data, int weight_size_len, tensor grad_output, tensor self, int64_t *padding_data, int padding_len, int64_t *stride_data, int stride_len, int64_t *dilation_data, int dilation_len, int64_t groups, int bias_defined);
void atg_mm(tensor *, tensor self, tensor mat2);
void atg_mm_out(tensor *, tensor result, tensor self, tensor mat2);
void atg_mode(tensor *, tensor self, int64_t dim, int keepdim);
void atg_mode_out(tensor *, tensor values, tensor indices, tensor self, int64_t dim, int keepdim);
void atg_mse_loss(tensor *, tensor self, tensor target, int64_t reduction);
void atg_mse_loss_backward(tensor *, tensor grad_output, tensor self, tensor target, int64_t reduction);
void atg_mse_loss_backward_out(tensor *, tensor grad_input, tensor grad_output, tensor self, tensor target, int64_t reduction);
void atg_mse_loss_out(tensor *, tensor output, tensor self, tensor target, int64_t reduction);
void atg_mul(tensor *, tensor self, tensor other);
void atg_mul1(tensor *, tensor self, scalar other);
void atg_mul_(tensor *, tensor self, tensor other);
void atg_mul_1(tensor *, tensor self, scalar other);
void atg_mul_out(tensor *, tensor result, tensor self, tensor other);
void atg_multilabel_margin_loss(tensor *, tensor self, tensor target, int64_t reduction);
void atg_multilabel_margin_loss_backward(tensor *, tensor grad_output, tensor self, tensor target, int64_t reduction, tensor is_target);
void atg_multilabel_margin_loss_backward_out(tensor *, tensor grad_input, tensor grad_output, tensor self, tensor target, int64_t reduction, tensor is_target);
void atg_multilabel_margin_loss_out(tensor *, tensor output, tensor self, tensor target, int64_t reduction);
void atg_multinomial(tensor *, tensor self, int64_t num_samples, int replacement);
void atg_multinomial_out(tensor *, tensor result, tensor self, int64_t num_samples, int replacement);
void atg_mv(tensor *, tensor self, tensor vec);
void atg_mv_out(tensor *, tensor result, tensor self, tensor vec);
void atg_mvlgamma(tensor *, tensor self, int64_t p);
void atg_mvlgamma_(tensor *, tensor self, int64_t p);
void atg_narrow(tensor *, tensor self, int64_t dim, int64_t start, int64_t length);
void atg_narrow_copy(tensor *, tensor self, int64_t dim, int64_t start, int64_t length);
void atg_native_batch_norm(tensor *, tensor input, tensor weight, tensor bias, tensor running_mean, tensor running_var, int training, double momentum, double eps);
void atg_native_clone(tensor *, tensor self);
void atg_native_norm(tensor *, tensor self);
void atg_native_pow(tensor *, tensor self, scalar exponent);
void atg_native_pow_out(tensor *, tensor result, tensor self, scalar exponent);
void atg_native_resize_as_(tensor *, tensor self, tensor the_template);
void atg_native_zero_(tensor *, tensor self);
void atg_ne(tensor *, tensor self, scalar other);
void atg_ne1(tensor *, tensor self, tensor other);
void atg_ne_(tensor *, tensor self, scalar other);
void atg_ne_1(tensor *, tensor self, tensor other);
void atg_ne_out(tensor *, tensor result, tensor self, scalar other);
void atg_ne_out1(tensor *, tensor result, tensor self, tensor other);
void atg_neg(tensor *, tensor self);
void atg_neg_(tensor *, tensor self);
void atg_neg_out(tensor *, tensor result, tensor self);
void atg_nll_loss(tensor *, tensor self, tensor target, tensor weight, int64_t reduction, int64_t ignore_index);
void atg_nll_loss2d(tensor *, tensor self, tensor target, tensor weight, int64_t reduction, int64_t ignore_index);
void atg_nll_loss2d_backward(tensor *, tensor grad_output, tensor self, tensor target, tensor weight, int64_t reduction, int64_t ignore_index, tensor total_weight);
void atg_nll_loss2d_backward_out(tensor *, tensor grad_input, tensor grad_output, tensor self, tensor target, tensor weight, int64_t reduction, int64_t ignore_index, tensor total_weight);
void atg_nll_loss2d_out(tensor *, tensor output, tensor self, tensor target, tensor weight, int64_t reduction, int64_t ignore_index);
void atg_nll_loss_backward(tensor *, tensor grad_output, tensor self, tensor target, tensor weight, int64_t reduction, int64_t ignore_index, tensor total_weight);
void atg_nll_loss_backward_out(tensor *, tensor grad_input, tensor grad_output, tensor self, tensor target, tensor weight, int64_t reduction, int64_t ignore_index, tensor total_weight);
void atg_nll_loss_out(tensor *, tensor output, tensor self, tensor target, tensor weight, int64_t reduction, int64_t ignore_index);
void atg_nonzero(tensor *, tensor self);
void atg_nonzero_out(tensor *, tensor result, tensor self);
void atg_norm(tensor *, tensor self);
void atg_norm1(tensor *, tensor self, scalar p, int64_t dim, int keepdim);
void atg_norm_except_dim(tensor *, tensor v, int64_t pow, int64_t dim);
void atg_norm_out(tensor *, tensor result, tensor self, scalar p, int64_t dim, int keepdim);
void atg_normal(tensor *, tensor mean, double std);
void atg_normal1(tensor *, double mean, tensor std);
void atg_normal2(tensor *, tensor mean, tensor std);
void atg_normal_(tensor *, tensor self, double mean, double std);
void atg_normal_out(tensor *, tensor output, tensor mean, double std);
void atg_normal_out1(tensor *, tensor output, double mean, tensor std);
void atg_normal_out2(tensor *, tensor output, tensor mean, tensor std);
void atg_nuclear_norm(tensor *, tensor self, int keepdim);
void atg_nuclear_norm_out(tensor *, tensor result, tensor self, int keepdim);
void atg_ones(tensor *, int64_t *size_data, int size_len, int options_kind, int options_device);
void atg_ones_like(tensor *, tensor self);
void atg_ones_like1(tensor *, tensor self, int options_kind, int options_device);
void atg_ones_out(tensor *, tensor result, int64_t *size_data, int size_len);
void atg_orgqr(tensor *, tensor self, tensor input2);
void atg_orgqr_out(tensor *, tensor result, tensor self, tensor input2);
void atg_ormqr(tensor *, tensor self, tensor input2, tensor input3, int left, int transpose);
void atg_ormqr_out(tensor *, tensor result, tensor self, tensor input2, tensor input3, int left, int transpose);
void atg_pairwise_distance(tensor *, tensor x1, tensor x2, double p, double eps, int keepdim);
void atg_pdist(tensor *, tensor self, double p);
void atg_permute(tensor *, tensor self, int64_t *dims_data, int dims_len);
void atg_pin_memory(tensor *, tensor self);
void atg_pinverse(tensor *, tensor self, double rcond);
void atg_pixel_shuffle(tensor *, tensor self, int64_t upscale_factor);
void atg_poisson(tensor *, tensor self);
void atg_polygamma(tensor *, int64_t n, tensor self);
void atg_polygamma_(tensor *, tensor self, int64_t n);
void atg_polygamma_out(tensor *, tensor result, int64_t n, tensor self);
void atg_potri(tensor *, tensor self, int upper);
void atg_potri_out(tensor *, tensor result, tensor self, int upper);
void atg_potrs(tensor *, tensor self, tensor input2, int upper);
void atg_potrs_out(tensor *, tensor result, tensor self, tensor input2, int upper);
void atg_pow(tensor *, tensor self, scalar exponent);
void atg_pow1(tensor *, tensor self, tensor exponent);
void atg_pow2(tensor *, scalar self, tensor exponent);
void atg_pow_(tensor *, tensor self, scalar exponent);
void atg_pow_1(tensor *, tensor self, tensor exponent);
void atg_pow_out(tensor *, tensor result, tensor self, scalar exponent);
void atg_pow_out1(tensor *, tensor result, tensor self, tensor exponent);
void atg_pow_out2(tensor *, tensor result, scalar self, tensor exponent);
void atg_prelu(tensor *, tensor self, tensor weight);
void atg_prelu_backward(tensor *, tensor grad_output, tensor self, tensor weight);
void atg_prod(tensor *, tensor self);
void atg_prod1(tensor *, tensor self, int dtype);
void atg_prod2(tensor *, tensor self, int64_t dim, int keepdim);
void atg_prod3(tensor *, tensor self, int64_t dim, int dtype);
void atg_prod4(tensor *, tensor self, int64_t dim, int keepdim, int dtype);
void atg_prod_out(tensor *, tensor result, tensor self, int64_t dim, int keepdim);
void atg_prod_out1(tensor *, tensor result, tensor self, int64_t dim, int dtype);
void atg_prod_out2(tensor *, tensor result, tensor self, int64_t dim, int keepdim, int dtype);
void atg_pstrf(tensor *, tensor self, int upper);
void atg_pstrf_out(tensor *, tensor u, tensor piv, tensor self, int upper);
void atg_put_(tensor *, tensor self, tensor index, tensor source, int accumulate);
void atg_qr(tensor *, tensor self);
void atg_qr_out(tensor *, tensor Q, tensor R, tensor self);
void atg_rand(tensor *, int64_t *size_data, int size_len, int options_kind, int options_device);
void atg_rand_like(tensor *, tensor self);
void atg_rand_like1(tensor *, tensor self, int options_kind, int options_device);
void atg_rand_out(tensor *, tensor result, int64_t *size_data, int size_len);
void atg_randint(tensor *, int64_t high, int64_t *size_data, int size_len, int options_kind, int options_device);
void atg_randint1(tensor *, int64_t low, int64_t high, int64_t *size_data, int size_len, int options_kind, int options_device);
void atg_randint_like(tensor *, tensor self, int64_t high);
void atg_randint_like1(tensor *, tensor self, int64_t low, int64_t high);
void atg_randint_like2(tensor *, tensor self, int64_t high, int options_kind, int options_device);
void atg_randint_like3(tensor *, tensor self, int64_t low, int64_t high, int options_kind, int options_device);
void atg_randint_out(tensor *, tensor result, int64_t high, int64_t *size_data, int size_len);
void atg_randint_out1(tensor *, tensor result, int64_t low, int64_t high, int64_t *size_data, int size_len);
void atg_randn(tensor *, int64_t *size_data, int size_len, int options_kind, int options_device);
void atg_randn_like(tensor *, tensor self);
void atg_randn_like1(tensor *, tensor self, int options_kind, int options_device);
void atg_randn_out(tensor *, tensor result, int64_t *size_data, int size_len);
void atg_random_(tensor *, tensor self);
void atg_random_1(tensor *, tensor self, int64_t to);
void atg_random_2(tensor *, tensor self, int64_t from, int64_t to);
void atg_randperm(tensor *, int64_t n, int options_kind, int options_device);
void atg_randperm_out(tensor *, tensor result, int64_t n);
void atg_range(tensor *, scalar start, scalar end, int options_kind, int options_device);
void atg_range1(tensor *, scalar start, scalar end, scalar step, int options_kind, int options_device);
void atg_range_out(tensor *, tensor result, scalar start, scalar end);
void atg_range_out1(tensor *, tensor result, scalar start, scalar end, scalar step);
void atg_reciprocal(tensor *, tensor self);
void atg_reciprocal_(tensor *, tensor self);
void atg_reciprocal_out(tensor *, tensor result, tensor self);
void atg_reflection_pad1d(tensor *, tensor self, int64_t *padding_data, int padding_len);
void atg_reflection_pad1d_backward(tensor *, tensor grad_output, tensor self, int64_t *padding_data, int padding_len);
void atg_reflection_pad1d_backward_out(tensor *, tensor grad_input, tensor grad_output, tensor self, int64_t *padding_data, int padding_len);
void atg_reflection_pad1d_out(tensor *, tensor output, tensor self, int64_t *padding_data, int padding_len);
void atg_reflection_pad2d(tensor *, tensor self, int64_t *padding_data, int padding_len);
void atg_reflection_pad2d_backward(tensor *, tensor grad_output, tensor self, int64_t *padding_data, int padding_len);
void atg_reflection_pad2d_backward_out(tensor *, tensor grad_input, tensor grad_output, tensor self, int64_t *padding_data, int padding_len);
void atg_reflection_pad2d_out(tensor *, tensor output, tensor self, int64_t *padding_data, int padding_len);
void atg_relu(tensor *, tensor self);
void atg_relu_(tensor *, tensor self);
void atg_remainder(tensor *, tensor self, scalar other);
void atg_remainder1(tensor *, tensor self, tensor other);
void atg_remainder_(tensor *, tensor self, scalar other);
void atg_remainder_1(tensor *, tensor self, tensor other);
void atg_remainder_out(tensor *, tensor result, tensor self, scalar other);
void atg_remainder_out1(tensor *, tensor result, tensor self, tensor other);
void atg_renorm(tensor *, tensor self, scalar p, int64_t dim, scalar maxnorm);
void atg_renorm_(tensor *, tensor self, scalar p, int64_t dim, scalar maxnorm);
void atg_renorm_out(tensor *, tensor result, tensor self, scalar p, int64_t dim, scalar maxnorm);
void atg_repeat(tensor *, tensor self, int64_t *repeats_data, int repeats_len);
void atg_replication_pad1d(tensor *, tensor self, int64_t *padding_data, int padding_len);
void atg_replication_pad1d_backward(tensor *, tensor grad_output, tensor self, int64_t *padding_data, int padding_len);
void atg_replication_pad1d_backward_out(tensor *, tensor grad_input, tensor grad_output, tensor self, int64_t *padding_data, int padding_len);
void atg_replication_pad1d_out(tensor *, tensor output, tensor self, int64_t *padding_data, int padding_len);
void atg_replication_pad2d(tensor *, tensor self, int64_t *padding_data, int padding_len);
void atg_replication_pad2d_backward(tensor *, tensor grad_output, tensor self, int64_t *padding_data, int padding_len);
void atg_replication_pad2d_backward_out(tensor *, tensor grad_input, tensor grad_output, tensor self, int64_t *padding_data, int padding_len);
void atg_replication_pad2d_out(tensor *, tensor output, tensor self, int64_t *padding_data, int padding_len);
void atg_replication_pad3d(tensor *, tensor self, int64_t *padding_data, int padding_len);
void atg_replication_pad3d_backward(tensor *, tensor grad_output, tensor self, int64_t *padding_data, int padding_len);
void atg_replication_pad3d_backward_out(tensor *, tensor grad_input, tensor grad_output, tensor self, int64_t *padding_data, int padding_len);
void atg_replication_pad3d_out(tensor *, tensor output, tensor self, int64_t *padding_data, int padding_len);
void atg_reshape(tensor *, tensor self, int64_t *shape_data, int shape_len);
void atg_reshape_as(tensor *, tensor self, tensor other);
void atg_resize_(tensor *, tensor self, int64_t *size_data, int size_len);
void atg_resize_as_(tensor *, tensor self, tensor the_template);
void atg_rfft(tensor *, tensor self, int64_t signal_ndim, int normalized, int onesided);
void atg_rnn_relu(tensor *, tensor input, tensor hx, tensor *params_data, int params_len, int has_biases, int64_t num_layers, double dropout, int train, int bidirectional, int batch_first);
void atg_rnn_relu1(tensor *, tensor data, tensor batch_sizes, tensor hx, tensor *params_data, int params_len, int has_biases, int64_t num_layers, double dropout, int train, int bidirectional);
void atg_rnn_relu_cell(tensor *, tensor input, tensor hx, tensor w_ih, tensor w_hh, tensor b_ih, tensor b_hh);
void atg_rnn_tanh(tensor *, tensor input, tensor hx, tensor *params_data, int params_len, int has_biases, int64_t num_layers, double dropout, int train, int bidirectional, int batch_first);
void atg_rnn_tanh1(tensor *, tensor data, tensor batch_sizes, tensor hx, tensor *params_data, int params_len, int has_biases, int64_t num_layers, double dropout, int train, int bidirectional);
void atg_rnn_tanh_cell(tensor *, tensor input, tensor hx, tensor w_ih, tensor w_hh, tensor b_ih, tensor b_hh);
void atg_roipooling2d_backward(tensor *, tensor input, tensor rois, int64_t pooledHeight, int64_t pooledWidth, double spatialScale, tensor gradOutput, tensor argmaxes);
void atg_roll(tensor *, tensor self, int64_t *shifts_data, int shifts_len, int64_t *dims_data, int dims_len);
void atg_rot90(tensor *, tensor self, int64_t k, int64_t *dims_data, int dims_len);
void atg_round(tensor *, tensor self);
void atg_round_(tensor *, tensor self);
void atg_round_out(tensor *, tensor result, tensor self);
void atg_rrelu(tensor *, tensor self, int training);
void atg_rrelu_(tensor *, tensor self, int training);
void atg_rrelu_with_noise(tensor *, tensor self, tensor noise, int training);
void atg_rrelu_with_noise_(tensor *, tensor self, tensor noise, int training);
void atg_rrelu_with_noise_out(tensor *, tensor output, tensor self, tensor noise, int training);
void atg_rsqrt(tensor *, tensor self);
void atg_rsqrt_(tensor *, tensor self);
void atg_rsqrt_out(tensor *, tensor result, tensor self);
void atg_rsub(tensor *, tensor self, tensor other);
void atg_rsub1(tensor *, tensor self, scalar other);
void atg_s_native_addmm(tensor *, tensor self, tensor mat1, tensor mat2);
void atg_s_native_addmm_(tensor *, tensor self, tensor mat1, tensor mat2);
void atg_s_native_addmm_out(tensor *, tensor result, tensor self, tensor mat1, tensor mat2);
void atg_scatter_(tensor *, tensor self, int64_t dim, tensor index, tensor src);
void atg_scatter_1(tensor *, tensor self, int64_t dim, tensor index, scalar value);
void atg_scatter_add_(tensor *, tensor self, int64_t dim, tensor index, tensor src);
void atg_select(tensor *, tensor self, int64_t dim, int64_t index);
void atg_selu(tensor *, tensor self);
void atg_selu_(tensor *, tensor self);
void atg_set_(tensor *, tensor self);
void atg_set_1(tensor *, tensor self, tensor source);
void atg_set_requires_grad(tensor *, tensor self, int r);
void atg_sigmoid(tensor *, tensor self);
void atg_sigmoid_(tensor *, tensor self);
void atg_sigmoid_out(tensor *, tensor result, tensor self);
void atg_sign(tensor *, tensor self);
void atg_sign_(tensor *, tensor self);
void atg_sign_out(tensor *, tensor result, tensor self);
void atg_sin(tensor *, tensor self);
void atg_sin_(tensor *, tensor self);
void atg_sin_out(tensor *, tensor result, tensor self);
void atg_sinh(tensor *, tensor self);
void atg_sinh_(tensor *, tensor self);
void atg_sinh_out(tensor *, tensor result, tensor self);
void atg_slice(tensor *, tensor self, int64_t dim, int64_t start, int64_t end, int64_t step);
void atg_slogdet(tensor *, tensor self);
void atg_smm(tensor *, tensor self, tensor mat2);
void atg_smooth_l1_loss(tensor *, tensor self, tensor target, int64_t reduction);
void atg_smooth_l1_loss_backward(tensor *, tensor grad_output, tensor self, tensor target, int64_t reduction);
void atg_smooth_l1_loss_backward_out(tensor *, tensor grad_input, tensor grad_output, tensor self, tensor target, int64_t reduction);
void atg_smooth_l1_loss_out(tensor *, tensor output, tensor self, tensor target, int64_t reduction);
void atg_soft_margin_loss(tensor *, tensor self, tensor target, int64_t reduction);
void atg_soft_margin_loss_backward(tensor *, tensor grad_output, tensor self, tensor target, int64_t reduction);
void atg_soft_margin_loss_backward_out(tensor *, tensor grad_input, tensor grad_output, tensor self, tensor target, int64_t reduction);
void atg_soft_margin_loss_out(tensor *, tensor output, tensor self, tensor target, int64_t reduction);
void atg_softmax(tensor *, tensor self, int64_t dim);
void atg_softmax1(tensor *, tensor self, int64_t dim, int dtype);
void atg_softplus(tensor *, tensor self);
void atg_softplus_out(tensor *, tensor output, tensor self);
void atg_softshrink(tensor *, tensor self);
void atg_softshrink_out(tensor *, tensor output, tensor self);
void atg_sort(tensor *, tensor self, int64_t dim, int descending);
void atg_sort_out(tensor *, tensor values, tensor indices, tensor self, int64_t dim, int descending);
void atg_sparse_coo_tensor(tensor *, int64_t *size_data, int size_len, int options_kind, int options_device);
void atg_sparse_coo_tensor1(tensor *, tensor indices, tensor values, int options_kind, int options_device);
void atg_sparse_coo_tensor2(tensor *, tensor indices, tensor values, int64_t *size_data, int size_len, int options_kind, int options_device);
void atg_sparse_resize_(tensor *, tensor self, int64_t *size_data, int size_len, int64_t sparse_dim, int64_t dense_dim);
void atg_sparse_resize_and_clear_(tensor *, tensor self, int64_t *size_data, int size_len, int64_t sparse_dim, int64_t dense_dim);
void atg_sqrt(tensor *, tensor self);
void atg_sqrt_(tensor *, tensor self);
void atg_sqrt_out(tensor *, tensor result, tensor self);
void atg_squeeze(tensor *, tensor self);
void atg_squeeze1(tensor *, tensor self, int64_t dim);
void atg_squeeze_(tensor *, tensor self);
void atg_squeeze_1(tensor *, tensor self, int64_t dim);
void atg_sspaddmm(tensor *, tensor self, tensor mat1, tensor mat2);
void atg_sspaddmm_out(tensor *, tensor result, tensor self, tensor mat1, tensor mat2);
void atg_stack(tensor *, tensor *tensors_data, int tensors_len, int64_t dim);
void atg_stack_out(tensor *, tensor result, tensor *tensors_data, int tensors_len, int64_t dim);
void atg_std(tensor *, tensor self, int unbiased);
void atg_std1(tensor *, tensor self, int64_t dim, int unbiased, int keepdim);
void atg_std_out(tensor *, tensor result, tensor self, int64_t dim, int unbiased, int keepdim);
void atg_stft(tensor *, tensor self, int64_t n_fft, int64_t hop_length, int64_t win_length, tensor window, int normalized, int onesided);
void atg_sub(tensor *, tensor self, tensor other);
void atg_sub1(tensor *, tensor self, scalar other);
void atg_sub_(tensor *, tensor self, tensor other);
void atg_sub_1(tensor *, tensor self, scalar other);
void atg_sub_out(tensor *, tensor result, tensor self, tensor other);
void atg_sum(tensor *, tensor self);
void atg_sum1(tensor *, tensor self, int dtype);
void atg_sum2(tensor *, tensor self, int64_t *dim_data, int dim_len, int keepdim);
void atg_sum3(tensor *, tensor self, int64_t *dim_data, int dim_len, int dtype);
void atg_sum4(tensor *, tensor self, int64_t *dim_data, int dim_len, int keepdim, int dtype);
void atg_sum_out(tensor *, tensor result, tensor self, int64_t *dim_data, int dim_len, int keepdim);
void atg_sum_out1(tensor *, tensor result, tensor self, int64_t *dim_data, int dim_len, int dtype);
void atg_sum_out2(tensor *, tensor result, tensor self, int64_t *dim_data, int dim_len, int keepdim, int dtype);
void atg_svd(tensor *, tensor self, int some, int compute_uv);
void atg_svd_out(tensor *, tensor U, tensor S, tensor V, tensor self, int some, int compute_uv);
void atg_symeig(tensor *, tensor self, int eigenvectors, int upper);
void atg_symeig_out(tensor *, tensor e, tensor V, tensor self, int eigenvectors, int upper);
void atg_t(tensor *, tensor self);
void atg_t_(tensor *, tensor self);
void atg_take(tensor *, tensor self, tensor index);
void atg_take_out(tensor *, tensor result, tensor self, tensor index);
void atg_tan(tensor *, tensor self);
void atg_tan_(tensor *, tensor self);
void atg_tan_out(tensor *, tensor result, tensor self);
void atg_tanh(tensor *, tensor self);
void atg_tanh_(tensor *, tensor self);
void atg_tanh_out(tensor *, tensor result, tensor self);
void atg_tensordot(tensor *, tensor self, tensor other, int64_t *dims_self_data, int dims_self_len, int64_t *dims_other_data, int dims_other_len);
void atg_threshold(tensor *, tensor self, scalar threshold, scalar value);
void atg_threshold_(tensor *, tensor self, scalar threshold, scalar value);
void atg_threshold_backward(tensor *, tensor grad_output, tensor self, scalar threshold);
void atg_threshold_out(tensor *, tensor result, tensor self, scalar threshold, scalar value);
void atg_to(tensor *, tensor self, int device);
void atg_to1(tensor *, tensor self, int options_kind, int options_device, int non_blocking, int copy);
void atg_to2(tensor *, tensor self, int dtype, int non_blocking, int copy);
void atg_to3(tensor *, tensor self, tensor other, int non_blocking, int copy);
void atg_to4(tensor *, tensor self, int device, int dtype, int non_blocking, int copy);
void atg_to_dense(tensor *, tensor self);
void atg_to_sparse(tensor *, tensor self);
void atg_to_sparse1(tensor *, tensor self, int64_t sparse_dim);
void atg_topk(tensor *, tensor self, int64_t k, int64_t dim, int largest, int sorted);
void atg_topk_out(tensor *, tensor values, tensor indices, tensor self, int64_t k, int64_t dim, int largest, int sorted);
void atg_totype(tensor *, tensor self, int scalar_type);
void atg_trace(tensor *, tensor self);
void atg_transpose(tensor *, tensor self, int64_t dim0, int64_t dim1);
void atg_transpose_(tensor *, tensor self, int64_t dim0, int64_t dim1);
void atg_tril(tensor *, tensor self, int64_t diagonal);
void atg_tril_(tensor *, tensor self, int64_t diagonal);
void atg_tril_out(tensor *, tensor result, tensor self, int64_t diagonal);
void atg_triplet_margin_loss(tensor *, tensor anchor, tensor positive, tensor negative, double margin, double p, double eps, int swap, int64_t reduction);
void atg_triu(tensor *, tensor self, int64_t diagonal);
void atg_triu_(tensor *, tensor self, int64_t diagonal);
void atg_triu_out(tensor *, tensor result, tensor self, int64_t diagonal);
void atg_trtrs(tensor *, tensor self, tensor A, int upper, int transpose, int unitriangular);
void atg_trtrs_out(tensor *, tensor X, tensor M, tensor self, tensor A, int upper, int transpose, int unitriangular);
void atg_trunc(tensor *, tensor self);
void atg_trunc_(tensor *, tensor self);
void atg_trunc_out(tensor *, tensor result, tensor self);
void atg_type_as(tensor *, tensor self, tensor other);
void atg_unfold(tensor *, tensor self, int64_t dimension, int64_t size, int64_t step);
void atg_uniform_(tensor *, tensor self, double from, double to);
void atg_unsqueeze(tensor *, tensor self, int64_t dim);
void atg_unsqueeze_(tensor *, tensor self, int64_t dim);
void atg_upsample_bilinear2d(tensor *, tensor self, int64_t *output_size_data, int output_size_len, int align_corners);
void atg_upsample_bilinear2d_backward(tensor *, tensor grad_output, int64_t *output_size_data, int output_size_len, int64_t *input_size_data, int input_size_len, int align_corners);
void atg_upsample_bilinear2d_backward_out(tensor *, tensor grad_input, tensor grad_output, int64_t *output_size_data, int output_size_len, int64_t *input_size_data, int input_size_len, int align_corners);
void atg_upsample_bilinear2d_out(tensor *, tensor output, tensor self, int64_t *output_size_data, int output_size_len, int align_corners);
void atg_upsample_linear1d(tensor *, tensor self, int64_t *output_size_data, int output_size_len, int align_corners);
void atg_upsample_linear1d_backward(tensor *, tensor grad_output, int64_t *output_size_data, int output_size_len, int64_t *input_size_data, int input_size_len, int align_corners);
void atg_upsample_linear1d_backward_out(tensor *, tensor grad_input, tensor grad_output, int64_t *output_size_data, int output_size_len, int64_t *input_size_data, int input_size_len, int align_corners);
void atg_upsample_linear1d_out(tensor *, tensor output, tensor self, int64_t *output_size_data, int output_size_len, int align_corners);
void atg_upsample_nearest1d(tensor *, tensor self, int64_t *output_size_data, int output_size_len);
void atg_upsample_nearest1d_backward(tensor *, tensor grad_output, int64_t *output_size_data, int output_size_len, int64_t *input_size_data, int input_size_len);
void atg_upsample_nearest1d_backward_out(tensor *, tensor grad_input, tensor grad_output, int64_t *output_size_data, int output_size_len, int64_t *input_size_data, int input_size_len);
void atg_upsample_nearest1d_out(tensor *, tensor output, tensor self, int64_t *output_size_data, int output_size_len);
void atg_upsample_nearest2d(tensor *, tensor self, int64_t *output_size_data, int output_size_len);
void atg_upsample_nearest2d_backward(tensor *, tensor grad_output, int64_t *output_size_data, int output_size_len, int64_t *input_size_data, int input_size_len);
void atg_upsample_nearest2d_backward_out(tensor *, tensor grad_input, tensor grad_output, int64_t *output_size_data, int output_size_len, int64_t *input_size_data, int input_size_len);
void atg_upsample_nearest2d_out(tensor *, tensor output, tensor self, int64_t *output_size_data, int output_size_len);
void atg_upsample_nearest3d(tensor *, tensor self, int64_t *output_size_data, int output_size_len);
void atg_upsample_nearest3d_backward(tensor *, tensor grad_output, int64_t *output_size_data, int output_size_len, int64_t *input_size_data, int input_size_len);
void atg_upsample_nearest3d_backward_out(tensor *, tensor grad_input, tensor grad_output, int64_t *output_size_data, int output_size_len, int64_t *input_size_data, int input_size_len);
void atg_upsample_nearest3d_out(tensor *, tensor output, tensor self, int64_t *output_size_data, int output_size_len);
void atg_upsample_trilinear3d(tensor *, tensor self, int64_t *output_size_data, int output_size_len, int align_corners);
void atg_upsample_trilinear3d_backward(tensor *, tensor grad_output, int64_t *output_size_data, int output_size_len, int64_t *input_size_data, int input_size_len, int align_corners);
void atg_upsample_trilinear3d_backward_out(tensor *, tensor grad_input, tensor grad_output, int64_t *output_size_data, int output_size_len, int64_t *input_size_data, int input_size_len, int align_corners);
void atg_upsample_trilinear3d_out(tensor *, tensor output, tensor self, int64_t *output_size_data, int output_size_len, int align_corners);
void atg_values(tensor *, tensor self);
void atg_var(tensor *, tensor self, int unbiased);
void atg_var1(tensor *, tensor self, int64_t dim, int unbiased, int keepdim);
void atg_var_out(tensor *, tensor result, tensor self, int64_t dim, int unbiased, int keepdim);
void atg_view(tensor *, tensor self, int64_t *size_data, int size_len);
void atg_view_as(tensor *, tensor self, tensor other);
void atg_where(tensor *, tensor condition, tensor self, tensor other);
void atg_zero_(tensor *, tensor self);
void atg_zeros(tensor *, int64_t *size_data, int size_len, int options_kind, int options_device);
void atg_zeros_like(tensor *, tensor self);
void atg_zeros_like1(tensor *, tensor self, int options_kind, int options_device);
void atg_zeros_out(tensor *, tensor result, int64_t *size_data, int size_len);
