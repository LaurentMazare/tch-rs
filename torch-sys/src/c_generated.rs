/* THIS FILE IS AUTOMATICALLY GENERATED, DO NOT EDIT BY HAND! */
#[allow(clippy::all)]
use crate::{C_scalar, C_tensor};
use libc::c_int;

extern "C" {
    pub fn atg_abs(self_: *mut C_tensor) -> *mut *mut C_tensor;
    pub fn atg_abs_(self_: *mut C_tensor) -> *mut *mut C_tensor;
    pub fn atg_abs_out(result_: *mut C_tensor, self_: *mut C_tensor) -> *mut *mut C_tensor;
    pub fn atg_acos(self_: *mut C_tensor) -> *mut *mut C_tensor;
    pub fn atg_acos_(self_: *mut C_tensor) -> *mut *mut C_tensor;
    pub fn atg_acos_out(result_: *mut C_tensor, self_: *mut C_tensor) -> *mut *mut C_tensor;
    pub fn atg_adaptive_avg_pool1d(self_: *mut C_tensor, output_size_data: *const i64, output_size_len: c_int) -> *mut *mut C_tensor;
    pub fn atg_adaptive_avg_pool2d(self_: *mut C_tensor, output_size_data: *const i64, output_size_len: c_int) -> *mut *mut C_tensor;
    pub fn atg_adaptive_avg_pool2d_backward(grad_output_: *mut C_tensor, self_: *mut C_tensor) -> *mut *mut C_tensor;
    pub fn atg_adaptive_avg_pool2d_backward_out(grad_input_: *mut C_tensor, grad_output_: *mut C_tensor, self_: *mut C_tensor) -> *mut *mut C_tensor;
    pub fn atg_adaptive_avg_pool2d_out(output_: *mut C_tensor, self_: *mut C_tensor, output_size_data: *const i64, output_size_len: c_int) -> *mut *mut C_tensor;
    pub fn atg_adaptive_avg_pool3d(self_: *mut C_tensor, output_size_data: *const i64, output_size_len: c_int) -> *mut *mut C_tensor;
    pub fn atg_adaptive_avg_pool3d_backward(grad_output_: *mut C_tensor, self_: *mut C_tensor) -> *mut *mut C_tensor;
    pub fn atg_adaptive_avg_pool3d_backward_out(grad_input_: *mut C_tensor, grad_output_: *mut C_tensor, self_: *mut C_tensor) -> *mut *mut C_tensor;
    pub fn atg_adaptive_avg_pool3d_out(output_: *mut C_tensor, self_: *mut C_tensor, output_size_data: *const i64, output_size_len: c_int) -> *mut *mut C_tensor;
    pub fn atg_adaptive_max_pool1d(self_: *mut C_tensor, output_size_data: *const i64, output_size_len: c_int) -> *mut *mut C_tensor;
    pub fn atg_adaptive_max_pool2d(self_: *mut C_tensor, output_size_data: *const i64, output_size_len: c_int) -> *mut *mut C_tensor;
    pub fn atg_adaptive_max_pool2d_backward(grad_output_: *mut C_tensor, self_: *mut C_tensor, indices_: *mut C_tensor) -> *mut *mut C_tensor;
    pub fn atg_adaptive_max_pool2d_backward_out(grad_input_: *mut C_tensor, grad_output_: *mut C_tensor, self_: *mut C_tensor, indices_: *mut C_tensor) -> *mut *mut C_tensor;
    pub fn atg_adaptive_max_pool2d_out(output_: *mut C_tensor, indices_: *mut C_tensor, self_: *mut C_tensor, output_size_data: *const i64, output_size_len: c_int) -> *mut *mut C_tensor;
    pub fn atg_adaptive_max_pool3d(self_: *mut C_tensor, output_size_data: *const i64, output_size_len: c_int) -> *mut *mut C_tensor;
    pub fn atg_adaptive_max_pool3d_backward(grad_output_: *mut C_tensor, self_: *mut C_tensor, indices_: *mut C_tensor) -> *mut *mut C_tensor;
    pub fn atg_adaptive_max_pool3d_backward_out(grad_input_: *mut C_tensor, grad_output_: *mut C_tensor, self_: *mut C_tensor, indices_: *mut C_tensor) -> *mut *mut C_tensor;
    pub fn atg_adaptive_max_pool3d_out(output_: *mut C_tensor, indices_: *mut C_tensor, self_: *mut C_tensor, output_size_data: *const i64, output_size_len: c_int) -> *mut *mut C_tensor;
    pub fn atg_add(self_: *mut C_tensor, other_: *mut C_tensor) -> *mut *mut C_tensor;
    pub fn atg_add1(self_: *mut C_tensor, other_: *mut C_scalar) -> *mut *mut C_tensor;
    pub fn atg_add_(self_: *mut C_tensor, other_: *mut C_tensor) -> *mut *mut C_tensor;
    pub fn atg_add_1(self_: *mut C_tensor, other_: *mut C_scalar) -> *mut *mut C_tensor;
    pub fn atg_add_out(result_: *mut C_tensor, self_: *mut C_tensor, other_: *mut C_tensor) -> *mut *mut C_tensor;
    pub fn atg_addbmm(self_: *mut C_tensor, batch1_: *mut C_tensor, batch2_: *mut C_tensor) -> *mut *mut C_tensor;
    pub fn atg_addbmm_(self_: *mut C_tensor, batch1_: *mut C_tensor, batch2_: *mut C_tensor) -> *mut *mut C_tensor;
    pub fn atg_addbmm_out(result_: *mut C_tensor, self_: *mut C_tensor, batch1_: *mut C_tensor, batch2_: *mut C_tensor) -> *mut *mut C_tensor;
    pub fn atg_addcdiv(self_: *mut C_tensor, tensor1_: *mut C_tensor, tensor2_: *mut C_tensor) -> *mut *mut C_tensor;
    pub fn atg_addcdiv_(self_: *mut C_tensor, tensor1_: *mut C_tensor, tensor2_: *mut C_tensor) -> *mut *mut C_tensor;
    pub fn atg_addcdiv_out(result_: *mut C_tensor, self_: *mut C_tensor, tensor1_: *mut C_tensor, tensor2_: *mut C_tensor) -> *mut *mut C_tensor;
    pub fn atg_addcmul(self_: *mut C_tensor, tensor1_: *mut C_tensor, tensor2_: *mut C_tensor) -> *mut *mut C_tensor;
    pub fn atg_addcmul_(self_: *mut C_tensor, tensor1_: *mut C_tensor, tensor2_: *mut C_tensor) -> *mut *mut C_tensor;
    pub fn atg_addcmul_out(result_: *mut C_tensor, self_: *mut C_tensor, tensor1_: *mut C_tensor, tensor2_: *mut C_tensor) -> *mut *mut C_tensor;
    pub fn atg_addmm(self_: *mut C_tensor, mat1_: *mut C_tensor, mat2_: *mut C_tensor) -> *mut *mut C_tensor;
    pub fn atg_addmm_(self_: *mut C_tensor, mat1_: *mut C_tensor, mat2_: *mut C_tensor) -> *mut *mut C_tensor;
    pub fn atg_addmm_out(result_: *mut C_tensor, self_: *mut C_tensor, mat1_: *mut C_tensor, mat2_: *mut C_tensor) -> *mut *mut C_tensor;
    pub fn atg_addmv(self_: *mut C_tensor, mat_: *mut C_tensor, vec_: *mut C_tensor) -> *mut *mut C_tensor;
    pub fn atg_addmv_(self_: *mut C_tensor, mat_: *mut C_tensor, vec_: *mut C_tensor) -> *mut *mut C_tensor;
    pub fn atg_addmv_out(result_: *mut C_tensor, self_: *mut C_tensor, mat_: *mut C_tensor, vec_: *mut C_tensor) -> *mut *mut C_tensor;
    pub fn atg_addr(self_: *mut C_tensor, vec1_: *mut C_tensor, vec2_: *mut C_tensor) -> *mut *mut C_tensor;
    pub fn atg_addr_(self_: *mut C_tensor, vec1_: *mut C_tensor, vec2_: *mut C_tensor) -> *mut *mut C_tensor;
    pub fn atg_addr_out(result_: *mut C_tensor, self_: *mut C_tensor, vec1_: *mut C_tensor, vec2_: *mut C_tensor) -> *mut *mut C_tensor;
    pub fn atg_alias(self_: *mut C_tensor) -> *mut *mut C_tensor;
    pub fn atg_all(self_: *mut C_tensor) -> *mut *mut C_tensor;
    pub fn atg_all1(self_: *mut C_tensor, dim_: i64, keepdim_: c_int) -> *mut *mut C_tensor;
    pub fn atg_all_out(result_: *mut C_tensor, self_: *mut C_tensor, dim_: i64, keepdim_: c_int) -> *mut *mut C_tensor;
    pub fn atg_alpha_dropout(input_: *mut C_tensor, p_: f64, train_: c_int) -> *mut *mut C_tensor;
    pub fn atg_alpha_dropout_(self_: *mut C_tensor, p_: f64, train_: c_int) -> *mut *mut C_tensor;
    pub fn atg_any(self_: *mut C_tensor) -> *mut *mut C_tensor;
    pub fn atg_any1(self_: *mut C_tensor, dim_: i64, keepdim_: c_int) -> *mut *mut C_tensor;
    pub fn atg_any_out(result_: *mut C_tensor, self_: *mut C_tensor, dim_: i64, keepdim_: c_int) -> *mut *mut C_tensor;
    pub fn atg_arange(end_: *mut C_scalar, options_kind: c_int, options_device: c_int) -> *mut *mut C_tensor;
    pub fn atg_arange1(start_: *mut C_scalar, end_: *mut C_scalar, options_kind: c_int, options_device: c_int) -> *mut *mut C_tensor;
    pub fn atg_arange2(start_: *mut C_scalar, end_: *mut C_scalar, step_: *mut C_scalar, options_kind: c_int, options_device: c_int) -> *mut *mut C_tensor;
    pub fn atg_arange_out(result_: *mut C_tensor, end_: *mut C_scalar) -> *mut *mut C_tensor;
    pub fn atg_arange_out1(result_: *mut C_tensor, start_: *mut C_scalar, end_: *mut C_scalar) -> *mut *mut C_tensor;
    pub fn atg_arange_out2(result_: *mut C_tensor, start_: *mut C_scalar, end_: *mut C_scalar, step_: *mut C_scalar) -> *mut *mut C_tensor;
    pub fn atg_argmax(self_: *mut C_tensor) -> *mut *mut C_tensor;
    pub fn atg_argmax1(self_: *mut C_tensor, dim_: i64, keepdim_: c_int) -> *mut *mut C_tensor;
    pub fn atg_argmin(self_: *mut C_tensor) -> *mut *mut C_tensor;
    pub fn atg_argmin1(self_: *mut C_tensor, dim_: i64, keepdim_: c_int) -> *mut *mut C_tensor;
    pub fn atg_as_strided(self_: *mut C_tensor, size_data: *const i64, size_len: c_int, stride_data: *const i64, stride_len: c_int) -> *mut *mut C_tensor;
    pub fn atg_as_strided1(self_: *mut C_tensor, size_data: *const i64, size_len: c_int, stride_data: *const i64, stride_len: c_int, storage_offset_: i64) -> *mut *mut C_tensor;
    pub fn atg_as_strided_(self_: *mut C_tensor, size_data: *const i64, size_len: c_int, stride_data: *const i64, stride_len: c_int) -> *mut *mut C_tensor;
    pub fn atg_as_strided_1(self_: *mut C_tensor, size_data: *const i64, size_len: c_int, stride_data: *const i64, stride_len: c_int, storage_offset_: i64) -> *mut *mut C_tensor;
    pub fn atg_asin(self_: *mut C_tensor) -> *mut *mut C_tensor;
    pub fn atg_asin_(self_: *mut C_tensor) -> *mut *mut C_tensor;
    pub fn atg_asin_out(result_: *mut C_tensor, self_: *mut C_tensor) -> *mut *mut C_tensor;
    pub fn atg_atan(self_: *mut C_tensor) -> *mut *mut C_tensor;
    pub fn atg_atan2(self_: *mut C_tensor, other_: *mut C_tensor) -> *mut *mut C_tensor;
    pub fn atg_atan2_(self_: *mut C_tensor, other_: *mut C_tensor) -> *mut *mut C_tensor;
    pub fn atg_atan2_out(result_: *mut C_tensor, self_: *mut C_tensor, other_: *mut C_tensor) -> *mut *mut C_tensor;
    pub fn atg_atan_(self_: *mut C_tensor) -> *mut *mut C_tensor;
    pub fn atg_atan_out(result_: *mut C_tensor, self_: *mut C_tensor) -> *mut *mut C_tensor;
    pub fn atg_avg_pool1d(self_: *mut C_tensor, kernel_size_data: *const i64, kernel_size_len: c_int, stride_data: *const i64, stride_len: c_int, padding_data: *const i64, padding_len: c_int, ceil_mode_: c_int, count_include_pad_: c_int) -> *mut *mut C_tensor;
    pub fn atg_avg_pool2d(self_: *mut C_tensor, kernel_size_data: *const i64, kernel_size_len: c_int, stride_data: *const i64, stride_len: c_int, padding_data: *const i64, padding_len: c_int, ceil_mode_: c_int, count_include_pad_: c_int) -> *mut *mut C_tensor;
    pub fn atg_avg_pool2d_backward(grad_output_: *mut C_tensor, self_: *mut C_tensor, kernel_size_data: *const i64, kernel_size_len: c_int, stride_data: *const i64, stride_len: c_int, padding_data: *const i64, padding_len: c_int, ceil_mode_: c_int, count_include_pad_: c_int) -> *mut *mut C_tensor;
    pub fn atg_avg_pool2d_backward_out(grad_input_: *mut C_tensor, grad_output_: *mut C_tensor, self_: *mut C_tensor, kernel_size_data: *const i64, kernel_size_len: c_int, stride_data: *const i64, stride_len: c_int, padding_data: *const i64, padding_len: c_int, ceil_mode_: c_int, count_include_pad_: c_int) -> *mut *mut C_tensor;
    pub fn atg_avg_pool2d_out(output_: *mut C_tensor, self_: *mut C_tensor, kernel_size_data: *const i64, kernel_size_len: c_int, stride_data: *const i64, stride_len: c_int, padding_data: *const i64, padding_len: c_int, ceil_mode_: c_int, count_include_pad_: c_int) -> *mut *mut C_tensor;
    pub fn atg_avg_pool3d(self_: *mut C_tensor, kernel_size_data: *const i64, kernel_size_len: c_int, stride_data: *const i64, stride_len: c_int, padding_data: *const i64, padding_len: c_int, ceil_mode_: c_int, count_include_pad_: c_int) -> *mut *mut C_tensor;
    pub fn atg_avg_pool3d_backward(grad_output_: *mut C_tensor, self_: *mut C_tensor, kernel_size_data: *const i64, kernel_size_len: c_int, stride_data: *const i64, stride_len: c_int, padding_data: *const i64, padding_len: c_int, ceil_mode_: c_int, count_include_pad_: c_int) -> *mut *mut C_tensor;
    pub fn atg_avg_pool3d_backward_out(grad_input_: *mut C_tensor, grad_output_: *mut C_tensor, self_: *mut C_tensor, kernel_size_data: *const i64, kernel_size_len: c_int, stride_data: *const i64, stride_len: c_int, padding_data: *const i64, padding_len: c_int, ceil_mode_: c_int, count_include_pad_: c_int) -> *mut *mut C_tensor;
    pub fn atg_avg_pool3d_out(output_: *mut C_tensor, self_: *mut C_tensor, kernel_size_data: *const i64, kernel_size_len: c_int, stride_data: *const i64, stride_len: c_int, padding_data: *const i64, padding_len: c_int, ceil_mode_: c_int, count_include_pad_: c_int) -> *mut *mut C_tensor;
    pub fn atg_baddbmm(self_: *mut C_tensor, batch1_: *mut C_tensor, batch2_: *mut C_tensor) -> *mut *mut C_tensor;
    pub fn atg_baddbmm_(self_: *mut C_tensor, batch1_: *mut C_tensor, batch2_: *mut C_tensor) -> *mut *mut C_tensor;
    pub fn atg_baddbmm_out(result_: *mut C_tensor, self_: *mut C_tensor, batch1_: *mut C_tensor, batch2_: *mut C_tensor) -> *mut *mut C_tensor;
    pub fn atg_bartlett_window(window_length_: i64, options_kind: c_int, options_device: c_int) -> *mut *mut C_tensor;
    pub fn atg_bartlett_window1(window_length_: i64, periodic_: c_int, options_kind: c_int, options_device: c_int) -> *mut *mut C_tensor;
    pub fn atg_batch_norm(input_: *mut C_tensor, weight_: *mut C_tensor, bias_: *mut C_tensor, running_mean_: *mut C_tensor, running_var_: *mut C_tensor, training_: c_int, momentum_: f64, eps_: f64, cudnn_enabled_: c_int) -> *mut *mut C_tensor;
    pub fn atg_bernoulli(self_: *mut C_tensor) -> *mut *mut C_tensor;
    pub fn atg_bernoulli1(self_: *mut C_tensor, p_: f64) -> *mut *mut C_tensor;
    pub fn atg_bernoulli_(self_: *mut C_tensor, p_: *mut C_tensor) -> *mut *mut C_tensor;
    pub fn atg_bernoulli_1(self_: *mut C_tensor, p_: f64) -> *mut *mut C_tensor;
    pub fn atg_bernoulli_out(result_: *mut C_tensor, self_: *mut C_tensor) -> *mut *mut C_tensor;
    pub fn atg_bilinear(input1_: *mut C_tensor, input2_: *mut C_tensor, weight_: *mut C_tensor, bias_: *mut C_tensor) -> *mut *mut C_tensor;
    pub fn atg_binary_cross_entropy(self_: *mut C_tensor, target_: *mut C_tensor, weight_: *mut C_tensor, reduction_: i64) -> *mut *mut C_tensor;
    pub fn atg_binary_cross_entropy_backward(grad_output_: *mut C_tensor, self_: *mut C_tensor, target_: *mut C_tensor, weight_: *mut C_tensor, reduction_: i64) -> *mut *mut C_tensor;
    pub fn atg_binary_cross_entropy_backward_out(grad_input_: *mut C_tensor, grad_output_: *mut C_tensor, self_: *mut C_tensor, target_: *mut C_tensor, weight_: *mut C_tensor, reduction_: i64) -> *mut *mut C_tensor;
    pub fn atg_binary_cross_entropy_out(output_: *mut C_tensor, self_: *mut C_tensor, target_: *mut C_tensor, weight_: *mut C_tensor, reduction_: i64) -> *mut *mut C_tensor;
    pub fn atg_binary_cross_entropy_with_logits(self_: *mut C_tensor, target_: *mut C_tensor, weight_: *mut C_tensor, pos_weight_: *mut C_tensor, reduction_: i64) -> *mut *mut C_tensor;
    pub fn atg_binary_cross_entropy_with_logits_backward(grad_output_: *mut C_tensor, self_: *mut C_tensor, target_: *mut C_tensor, weight_: *mut C_tensor, pos_weight_: *mut C_tensor, reduction_: i64) -> *mut *mut C_tensor;
    pub fn atg_bincount(self_: *mut C_tensor, weights_: *mut C_tensor, minlength_: i64) -> *mut *mut C_tensor;
    pub fn atg_blackman_window(window_length_: i64, options_kind: c_int, options_device: c_int) -> *mut *mut C_tensor;
    pub fn atg_blackman_window1(window_length_: i64, periodic_: c_int, options_kind: c_int, options_device: c_int) -> *mut *mut C_tensor;
    pub fn atg_bmm(self_: *mut C_tensor, mat2_: *mut C_tensor) -> *mut *mut C_tensor;
    pub fn atg_bmm_out(result_: *mut C_tensor, self_: *mut C_tensor, mat2_: *mut C_tensor) -> *mut *mut C_tensor;
    pub fn atg_broadcast_tensors(tensors_data: *const *mut C_tensor, tensors_len: c_int) -> *mut *mut C_tensor;
    pub fn atg_btrifact(self_: *mut C_tensor, pivot_: c_int) -> *mut *mut C_tensor;
    pub fn atg_btrifact_out(A_LU_: *mut C_tensor, pivots_: *mut C_tensor, self_: *mut C_tensor, pivot_: c_int) -> *mut *mut C_tensor;
    pub fn atg_btrifact_with_info(self_: *mut C_tensor, pivot_: c_int) -> *mut *mut C_tensor;
    pub fn atg_btrifact_with_info_out(A_LU_: *mut C_tensor, pivots_: *mut C_tensor, info_: *mut C_tensor, self_: *mut C_tensor, pivot_: c_int) -> *mut *mut C_tensor;
    pub fn atg_btrisolve(self_: *mut C_tensor, LU_data_: *mut C_tensor, LU_pivots_: *mut C_tensor) -> *mut *mut C_tensor;
    pub fn atg_btrisolve_out(result_: *mut C_tensor, self_: *mut C_tensor, LU_data_: *mut C_tensor, LU_pivots_: *mut C_tensor) -> *mut *mut C_tensor;
    pub fn atg_cat(tensors_data: *const *mut C_tensor, tensors_len: c_int, dim_: i64) -> *mut *mut C_tensor;
    pub fn atg_cat_out(result_: *mut C_tensor, tensors_data: *const *mut C_tensor, tensors_len: c_int, dim_: i64) -> *mut *mut C_tensor;
    pub fn atg_cauchy_(self_: *mut C_tensor, median_: f64, sigma_: f64) -> *mut *mut C_tensor;
    pub fn atg_ceil(self_: *mut C_tensor) -> *mut *mut C_tensor;
    pub fn atg_ceil_(self_: *mut C_tensor) -> *mut *mut C_tensor;
    pub fn atg_ceil_out(result_: *mut C_tensor, self_: *mut C_tensor) -> *mut *mut C_tensor;
    pub fn atg_celu(self_: *mut C_tensor) -> *mut *mut C_tensor;
    pub fn atg_celu_(self_: *mut C_tensor) -> *mut *mut C_tensor;
    pub fn atg_chain_matmul(matrices_data: *const *mut C_tensor, matrices_len: c_int) -> *mut *mut C_tensor;
    pub fn atg_cholesky(self_: *mut C_tensor, upper_: c_int) -> *mut *mut C_tensor;
    pub fn atg_cholesky_out(result_: *mut C_tensor, self_: *mut C_tensor, upper_: c_int) -> *mut *mut C_tensor;
    pub fn atg_chunk(self_: *mut C_tensor, chunks_: i64, dim_: i64) -> *mut *mut C_tensor;
    pub fn atg_clamp(self_: *mut C_tensor, min_: *mut C_scalar, max_: *mut C_scalar) -> *mut *mut C_tensor;
    pub fn atg_clamp_(self_: *mut C_tensor, min_: *mut C_scalar, max_: *mut C_scalar) -> *mut *mut C_tensor;
    pub fn atg_clamp_max(self_: *mut C_tensor, max_: *mut C_scalar) -> *mut *mut C_tensor;
    pub fn atg_clamp_max_(self_: *mut C_tensor, max_: *mut C_scalar) -> *mut *mut C_tensor;
    pub fn atg_clamp_max_out(result_: *mut C_tensor, self_: *mut C_tensor, max_: *mut C_scalar) -> *mut *mut C_tensor;
    pub fn atg_clamp_min(self_: *mut C_tensor, min_: *mut C_scalar) -> *mut *mut C_tensor;
    pub fn atg_clamp_min_(self_: *mut C_tensor, min_: *mut C_scalar) -> *mut *mut C_tensor;
    pub fn atg_clamp_min_out(result_: *mut C_tensor, self_: *mut C_tensor, min_: *mut C_scalar) -> *mut *mut C_tensor;
    pub fn atg_clamp_out(result_: *mut C_tensor, self_: *mut C_tensor, min_: *mut C_scalar, max_: *mut C_scalar) -> *mut *mut C_tensor;
    pub fn atg_coalesce(self_: *mut C_tensor) -> *mut *mut C_tensor;
    pub fn atg_constant_pad_nd(self_: *mut C_tensor, pad_data: *const i64, pad_len: c_int) -> *mut *mut C_tensor;
    pub fn atg_contiguous(self_: *mut C_tensor) -> *mut *mut C_tensor;
    pub fn atg_conv1d(input_: *mut C_tensor, weight_: *mut C_tensor, bias_: *mut C_tensor, stride_data: *const i64, stride_len: c_int, padding_data: *const i64, padding_len: c_int, dilation_data: *const i64, dilation_len: c_int, groups_: i64) -> *mut *mut C_tensor;
    pub fn atg_conv2d(input_: *mut C_tensor, weight_: *mut C_tensor, bias_: *mut C_tensor, stride_data: *const i64, stride_len: c_int, padding_data: *const i64, padding_len: c_int, dilation_data: *const i64, dilation_len: c_int, groups_: i64) -> *mut *mut C_tensor;
    pub fn atg_conv3d(input_: *mut C_tensor, weight_: *mut C_tensor, bias_: *mut C_tensor, stride_data: *const i64, stride_len: c_int, padding_data: *const i64, padding_len: c_int, dilation_data: *const i64, dilation_len: c_int, groups_: i64) -> *mut *mut C_tensor;
    pub fn atg_conv_tbc(self_: *mut C_tensor, weight_: *mut C_tensor, bias_: *mut C_tensor, pad_: i64) -> *mut *mut C_tensor;
    pub fn atg_conv_tbc_backward(self_: *mut C_tensor, input_: *mut C_tensor, weight_: *mut C_tensor, bias_: *mut C_tensor, pad_: i64) -> *mut *mut C_tensor;
    pub fn atg_conv_transpose1d(input_: *mut C_tensor, weight_: *mut C_tensor, bias_: *mut C_tensor, stride_data: *const i64, stride_len: c_int, padding_data: *const i64, padding_len: c_int, output_padding_data: *const i64, output_padding_len: c_int, groups_: i64, dilation_data: *const i64, dilation_len: c_int) -> *mut *mut C_tensor;
    pub fn atg_conv_transpose2d(input_: *mut C_tensor, weight_: *mut C_tensor, bias_: *mut C_tensor, stride_data: *const i64, stride_len: c_int, padding_data: *const i64, padding_len: c_int, output_padding_data: *const i64, output_padding_len: c_int, groups_: i64, dilation_data: *const i64, dilation_len: c_int) -> *mut *mut C_tensor;
    pub fn atg_conv_transpose3d(input_: *mut C_tensor, weight_: *mut C_tensor, bias_: *mut C_tensor, stride_data: *const i64, stride_len: c_int, padding_data: *const i64, padding_len: c_int, output_padding_data: *const i64, output_padding_len: c_int, groups_: i64, dilation_data: *const i64, dilation_len: c_int) -> *mut *mut C_tensor;
    pub fn atg_convolution(input_: *mut C_tensor, weight_: *mut C_tensor, bias_: *mut C_tensor, stride_data: *const i64, stride_len: c_int, padding_data: *const i64, padding_len: c_int, dilation_data: *const i64, dilation_len: c_int, transposed_: c_int, output_padding_data: *const i64, output_padding_len: c_int, groups_: i64) -> *mut *mut C_tensor;
    pub fn atg_copy_sparse_to_sparse_(self_: *mut C_tensor, src_: *mut C_tensor, non_blocking_: c_int) -> *mut *mut C_tensor;
    pub fn atg_cos(self_: *mut C_tensor) -> *mut *mut C_tensor;
    pub fn atg_cos_(self_: *mut C_tensor) -> *mut *mut C_tensor;
    pub fn atg_cos_out(result_: *mut C_tensor, self_: *mut C_tensor) -> *mut *mut C_tensor;
    pub fn atg_cosh(self_: *mut C_tensor) -> *mut *mut C_tensor;
    pub fn atg_cosh_(self_: *mut C_tensor) -> *mut *mut C_tensor;
    pub fn atg_cosh_out(result_: *mut C_tensor, self_: *mut C_tensor) -> *mut *mut C_tensor;
    pub fn atg_cosine_embedding_loss(input1_: *mut C_tensor, input2_: *mut C_tensor, target_: *mut C_tensor, margin_: f64, reduction_: i64) -> *mut *mut C_tensor;
    pub fn atg_cross(self_: *mut C_tensor, other_: *mut C_tensor, dim_: i64) -> *mut *mut C_tensor;
    pub fn atg_cross_out(result_: *mut C_tensor, self_: *mut C_tensor, other_: *mut C_tensor, dim_: i64) -> *mut *mut C_tensor;
    pub fn atg_ctc_loss(log_probs_: *mut C_tensor, targets_: *mut C_tensor, input_lengths_data: *const i64, input_lengths_len: c_int, target_lengths_data: *const i64, target_lengths_len: c_int, blank_: i64, reduction_: i64) -> *mut *mut C_tensor;
    pub fn atg_ctc_loss1(log_probs_: *mut C_tensor, targets_: *mut C_tensor, input_lengths_: *mut C_tensor, target_lengths_: *mut C_tensor, blank_: i64, reduction_: i64) -> *mut *mut C_tensor;
    pub fn atg_cudnn_affine_grid_generator(theta_: *mut C_tensor, N_: i64, C_: i64, H_: i64, W_: i64) -> *mut *mut C_tensor;
    pub fn atg_cudnn_affine_grid_generator_backward(grad_: *mut C_tensor, N_: i64, C_: i64, H_: i64, W_: i64) -> *mut *mut C_tensor;
    pub fn atg_cudnn_batch_norm(input_: *mut C_tensor, weight_: *mut C_tensor, bias_: *mut C_tensor, running_mean_: *mut C_tensor, running_var_: *mut C_tensor, training_: c_int, exponential_average_factor_: f64, epsilon_: f64) -> *mut *mut C_tensor;
    pub fn atg_cudnn_batch_norm_backward(input_: *mut C_tensor, grad_output_: *mut C_tensor, weight_: *mut C_tensor, running_mean_: *mut C_tensor, running_var_: *mut C_tensor, save_mean_: *mut C_tensor, save_var_: *mut C_tensor, epsilon_: f64) -> *mut *mut C_tensor;
    pub fn atg_cudnn_convolution(self_: *mut C_tensor, weight_: *mut C_tensor, bias_: *mut C_tensor, padding_data: *const i64, padding_len: c_int, stride_data: *const i64, stride_len: c_int, dilation_data: *const i64, dilation_len: c_int, groups_: i64, benchmark_: c_int, deterministic_: c_int) -> *mut *mut C_tensor;
    pub fn atg_cudnn_convolution_backward_bias(grad_output_: *mut C_tensor) -> *mut *mut C_tensor;
    pub fn atg_cudnn_convolution_backward_input(self_size_data: *const i64, self_size_len: c_int, grad_output_: *mut C_tensor, weight_: *mut C_tensor, padding_data: *const i64, padding_len: c_int, stride_data: *const i64, stride_len: c_int, dilation_data: *const i64, dilation_len: c_int, groups_: i64, benchmark_: c_int, deterministic_: c_int) -> *mut *mut C_tensor;
    pub fn atg_cudnn_convolution_backward_weight(weight_size_data: *const i64, weight_size_len: c_int, grad_output_: *mut C_tensor, self_: *mut C_tensor, padding_data: *const i64, padding_len: c_int, stride_data: *const i64, stride_len: c_int, dilation_data: *const i64, dilation_len: c_int, groups_: i64, benchmark_: c_int, deterministic_: c_int) -> *mut *mut C_tensor;
    pub fn atg_cudnn_convolution_transpose(self_: *mut C_tensor, weight_: *mut C_tensor, bias_: *mut C_tensor, padding_data: *const i64, padding_len: c_int, output_padding_data: *const i64, output_padding_len: c_int, stride_data: *const i64, stride_len: c_int, dilation_data: *const i64, dilation_len: c_int, groups_: i64, benchmark_: c_int, deterministic_: c_int) -> *mut *mut C_tensor;
    pub fn atg_cudnn_convolution_transpose_backward_bias(grad_output_: *mut C_tensor) -> *mut *mut C_tensor;
    pub fn atg_cudnn_convolution_transpose_backward_input(grad_output_: *mut C_tensor, weight_: *mut C_tensor, padding_data: *const i64, padding_len: c_int, stride_data: *const i64, stride_len: c_int, dilation_data: *const i64, dilation_len: c_int, groups_: i64, benchmark_: c_int, deterministic_: c_int) -> *mut *mut C_tensor;
    pub fn atg_cudnn_convolution_transpose_backward_weight(weight_size_data: *const i64, weight_size_len: c_int, grad_output_: *mut C_tensor, self_: *mut C_tensor, padding_data: *const i64, padding_len: c_int, stride_data: *const i64, stride_len: c_int, dilation_data: *const i64, dilation_len: c_int, groups_: i64, benchmark_: c_int, deterministic_: c_int) -> *mut *mut C_tensor;
    pub fn atg_cudnn_grid_sampler(self_: *mut C_tensor, grid_: *mut C_tensor) -> *mut *mut C_tensor;
    pub fn atg_cudnn_grid_sampler_backward(self_: *mut C_tensor, grid_: *mut C_tensor, grad_output_: *mut C_tensor) -> *mut *mut C_tensor;
    pub fn atg_cumprod(self_: *mut C_tensor, dim_: i64) -> *mut *mut C_tensor;
    pub fn atg_cumprod1(self_: *mut C_tensor, dim_: i64, dtype_: c_int) -> *mut *mut C_tensor;
    pub fn atg_cumprod_out(result_: *mut C_tensor, self_: *mut C_tensor, dim_: i64) -> *mut *mut C_tensor;
    pub fn atg_cumprod_out1(result_: *mut C_tensor, self_: *mut C_tensor, dim_: i64, dtype_: c_int) -> *mut *mut C_tensor;
    pub fn atg_cumsum(self_: *mut C_tensor, dim_: i64) -> *mut *mut C_tensor;
    pub fn atg_cumsum1(self_: *mut C_tensor, dim_: i64, dtype_: c_int) -> *mut *mut C_tensor;
    pub fn atg_cumsum_out(result_: *mut C_tensor, self_: *mut C_tensor, dim_: i64) -> *mut *mut C_tensor;
    pub fn atg_cumsum_out1(result_: *mut C_tensor, self_: *mut C_tensor, dim_: i64, dtype_: c_int) -> *mut *mut C_tensor;
    pub fn atg_det(self_: *mut C_tensor) -> *mut *mut C_tensor;
    pub fn atg_detach(self_: *mut C_tensor) -> *mut *mut C_tensor;
    pub fn atg_detach_(self_: *mut C_tensor) -> *mut *mut C_tensor;
    pub fn atg_diag(self_: *mut C_tensor, diagonal_: i64) -> *mut *mut C_tensor;
    pub fn atg_diag_embed(self_: *mut C_tensor, offset_: i64, dim1_: i64, dim2_: i64) -> *mut *mut C_tensor;
    pub fn atg_diag_out(result_: *mut C_tensor, self_: *mut C_tensor, diagonal_: i64) -> *mut *mut C_tensor;
    pub fn atg_diagflat(self_: *mut C_tensor, offset_: i64) -> *mut *mut C_tensor;
    pub fn atg_diagonal(self_: *mut C_tensor, offset_: i64, dim1_: i64, dim2_: i64) -> *mut *mut C_tensor;
    pub fn atg_digamma(self_: *mut C_tensor) -> *mut *mut C_tensor;
    pub fn atg_digamma_(self_: *mut C_tensor) -> *mut *mut C_tensor;
    pub fn atg_digamma_out(result_: *mut C_tensor, self_: *mut C_tensor) -> *mut *mut C_tensor;
    pub fn atg_dist(self_: *mut C_tensor, other_: *mut C_tensor) -> *mut *mut C_tensor;
    pub fn atg_div(self_: *mut C_tensor, other_: *mut C_tensor) -> *mut *mut C_tensor;
    pub fn atg_div1(self_: *mut C_tensor, other_: *mut C_scalar) -> *mut *mut C_tensor;
    pub fn atg_div_(self_: *mut C_tensor, other_: *mut C_tensor) -> *mut *mut C_tensor;
    pub fn atg_div_1(self_: *mut C_tensor, other_: *mut C_scalar) -> *mut *mut C_tensor;
    pub fn atg_div_out(result_: *mut C_tensor, self_: *mut C_tensor, other_: *mut C_tensor) -> *mut *mut C_tensor;
    pub fn atg_dot(self_: *mut C_tensor, tensor_: *mut C_tensor) -> *mut *mut C_tensor;
    pub fn atg_dot_out(result_: *mut C_tensor, self_: *mut C_tensor, tensor_: *mut C_tensor) -> *mut *mut C_tensor;
    pub fn atg_dropout(input_: *mut C_tensor, p_: f64, train_: c_int) -> *mut *mut C_tensor;
    pub fn atg_dropout_(self_: *mut C_tensor, p_: f64, train_: c_int) -> *mut *mut C_tensor;
    pub fn atg_eig(self_: *mut C_tensor, eigenvectors_: c_int) -> *mut *mut C_tensor;
    pub fn atg_eig_out(e_: *mut C_tensor, v_: *mut C_tensor, self_: *mut C_tensor, eigenvectors_: c_int) -> *mut *mut C_tensor;
    pub fn atg_elu(self_: *mut C_tensor) -> *mut *mut C_tensor;
    pub fn atg_elu_(self_: *mut C_tensor) -> *mut *mut C_tensor;
    pub fn atg_elu_out(output_: *mut C_tensor, self_: *mut C_tensor) -> *mut *mut C_tensor;
    pub fn atg_embedding(weight_: *mut C_tensor, indices_: *mut C_tensor, padding_idx_: i64, scale_grad_by_freq_: c_int, sparse_: c_int) -> *mut *mut C_tensor;
    pub fn atg_embedding_backward(grad_: *mut C_tensor, indices_: *mut C_tensor, num_weights_: i64, padding_idx_: i64, scale_grad_by_freq_: c_int, sparse_: c_int) -> *mut *mut C_tensor;
    pub fn atg_embedding_bag(weight_: *mut C_tensor, indices_: *mut C_tensor, offsets_: *mut C_tensor, scale_grad_by_freq_: c_int, mode_: i64, sparse_: c_int) -> *mut *mut C_tensor;
    pub fn atg_embedding_dense_backward(grad_: *mut C_tensor, indices_: *mut C_tensor, num_weights_: i64, padding_idx_: i64, scale_grad_by_freq_: c_int) -> *mut *mut C_tensor;
    pub fn atg_embedding_renorm_(self_: *mut C_tensor, indices_: *mut C_tensor, max_norm_: f64, norm_type_: f64) -> *mut *mut C_tensor;
    pub fn atg_embedding_sparse_backward(grad_: *mut C_tensor, indices_: *mut C_tensor, num_weights_: i64, padding_idx_: i64, scale_grad_by_freq_: c_int) -> *mut *mut C_tensor;
    pub fn atg_empty(size_data: *const i64, size_len: c_int, options_kind: c_int, options_device: c_int) -> *mut *mut C_tensor;
    pub fn atg_empty_like(self_: *mut C_tensor) -> *mut *mut C_tensor;
    pub fn atg_empty_like1(self_: *mut C_tensor, options_kind: c_int, options_device: c_int) -> *mut *mut C_tensor;
    pub fn atg_empty_out(result_: *mut C_tensor, size_data: *const i64, size_len: c_int) -> *mut *mut C_tensor;
    pub fn atg_empty_strided(size_data: *const i64, size_len: c_int, stride_data: *const i64, stride_len: c_int, options_kind: c_int, options_device: c_int) -> *mut *mut C_tensor;
    pub fn atg_eq(self_: *mut C_tensor, other_: *mut C_scalar) -> *mut *mut C_tensor;
    pub fn atg_eq1(self_: *mut C_tensor, other_: *mut C_tensor) -> *mut *mut C_tensor;
    pub fn atg_eq_(self_: *mut C_tensor, other_: *mut C_scalar) -> *mut *mut C_tensor;
    pub fn atg_eq_1(self_: *mut C_tensor, other_: *mut C_tensor) -> *mut *mut C_tensor;
    pub fn atg_eq_out(result_: *mut C_tensor, self_: *mut C_tensor, other_: *mut C_scalar) -> *mut *mut C_tensor;
    pub fn atg_eq_out1(result_: *mut C_tensor, self_: *mut C_tensor, other_: *mut C_tensor) -> *mut *mut C_tensor;
    pub fn atg_erf(self_: *mut C_tensor) -> *mut *mut C_tensor;
    pub fn atg_erf_(self_: *mut C_tensor) -> *mut *mut C_tensor;
    pub fn atg_erf_out(result_: *mut C_tensor, self_: *mut C_tensor) -> *mut *mut C_tensor;
    pub fn atg_erfc(self_: *mut C_tensor) -> *mut *mut C_tensor;
    pub fn atg_erfc_(self_: *mut C_tensor) -> *mut *mut C_tensor;
    pub fn atg_erfc_out(result_: *mut C_tensor, self_: *mut C_tensor) -> *mut *mut C_tensor;
    pub fn atg_erfinv(self_: *mut C_tensor) -> *mut *mut C_tensor;
    pub fn atg_erfinv_(self_: *mut C_tensor) -> *mut *mut C_tensor;
    pub fn atg_erfinv_out(result_: *mut C_tensor, self_: *mut C_tensor) -> *mut *mut C_tensor;
    pub fn atg_exp(self_: *mut C_tensor) -> *mut *mut C_tensor;
    pub fn atg_exp_(self_: *mut C_tensor) -> *mut *mut C_tensor;
    pub fn atg_exp_out(result_: *mut C_tensor, self_: *mut C_tensor) -> *mut *mut C_tensor;
    pub fn atg_expand(self_: *mut C_tensor, size_data: *const i64, size_len: c_int, implicit_: c_int) -> *mut *mut C_tensor;
    pub fn atg_expand_as(self_: *mut C_tensor, other_: *mut C_tensor) -> *mut *mut C_tensor;
    pub fn atg_expm1(self_: *mut C_tensor) -> *mut *mut C_tensor;
    pub fn atg_expm1_(self_: *mut C_tensor) -> *mut *mut C_tensor;
    pub fn atg_expm1_out(result_: *mut C_tensor, self_: *mut C_tensor) -> *mut *mut C_tensor;
    pub fn atg_exponential_(self_: *mut C_tensor, lambd_: f64) -> *mut *mut C_tensor;
    pub fn atg_eye(n_: i64, options_kind: c_int, options_device: c_int) -> *mut *mut C_tensor;
    pub fn atg_eye1(n_: i64, m_: i64, options_kind: c_int, options_device: c_int) -> *mut *mut C_tensor;
    pub fn atg_eye_out(result_: *mut C_tensor, n_: i64) -> *mut *mut C_tensor;
    pub fn atg_eye_out1(result_: *mut C_tensor, n_: i64, m_: i64) -> *mut *mut C_tensor;
    pub fn atg_feature_alpha_dropout(input_: *mut C_tensor, p_: f64, train_: c_int) -> *mut *mut C_tensor;
    pub fn atg_feature_alpha_dropout_(self_: *mut C_tensor, p_: f64, train_: c_int) -> *mut *mut C_tensor;
    pub fn atg_feature_dropout(input_: *mut C_tensor, p_: f64, train_: c_int) -> *mut *mut C_tensor;
    pub fn atg_feature_dropout_(self_: *mut C_tensor, p_: f64, train_: c_int) -> *mut *mut C_tensor;
    pub fn atg_fft(self_: *mut C_tensor, signal_ndim_: i64, normalized_: c_int) -> *mut *mut C_tensor;
    pub fn atg_fill_(self_: *mut C_tensor, value_: *mut C_scalar) -> *mut *mut C_tensor;
    pub fn atg_fill_1(self_: *mut C_tensor, value_: *mut C_tensor) -> *mut *mut C_tensor;
    pub fn atg_flatten(self_: *mut C_tensor, start_dim_: i64, end_dim_: i64) -> *mut *mut C_tensor;
    pub fn atg_flip(self_: *mut C_tensor, dims_data: *const i64, dims_len: c_int) -> *mut *mut C_tensor;
    pub fn atg_floor(self_: *mut C_tensor) -> *mut *mut C_tensor;
    pub fn atg_floor_(self_: *mut C_tensor) -> *mut *mut C_tensor;
    pub fn atg_floor_out(result_: *mut C_tensor, self_: *mut C_tensor) -> *mut *mut C_tensor;
    pub fn atg_fmod(self_: *mut C_tensor, other_: *mut C_scalar) -> *mut *mut C_tensor;
    pub fn atg_fmod1(self_: *mut C_tensor, other_: *mut C_tensor) -> *mut *mut C_tensor;
    pub fn atg_fmod_(self_: *mut C_tensor, other_: *mut C_scalar) -> *mut *mut C_tensor;
    pub fn atg_fmod_1(self_: *mut C_tensor, other_: *mut C_tensor) -> *mut *mut C_tensor;
    pub fn atg_fmod_out(result_: *mut C_tensor, self_: *mut C_tensor, other_: *mut C_scalar) -> *mut *mut C_tensor;
    pub fn atg_fmod_out1(result_: *mut C_tensor, self_: *mut C_tensor, other_: *mut C_tensor) -> *mut *mut C_tensor;
    pub fn atg_frac(self_: *mut C_tensor) -> *mut *mut C_tensor;
    pub fn atg_frac_(self_: *mut C_tensor) -> *mut *mut C_tensor;
    pub fn atg_frac_out(result_: *mut C_tensor, self_: *mut C_tensor) -> *mut *mut C_tensor;
    pub fn atg_fractional_max_pool2d(self_: *mut C_tensor, kernel_size_data: *const i64, kernel_size_len: c_int, output_size_data: *const i64, output_size_len: c_int, random_samples_: *mut C_tensor) -> *mut *mut C_tensor;
    pub fn atg_fractional_max_pool2d_backward(grad_output_: *mut C_tensor, self_: *mut C_tensor, kernel_size_data: *const i64, kernel_size_len: c_int, output_size_data: *const i64, output_size_len: c_int, indices_: *mut C_tensor) -> *mut *mut C_tensor;
    pub fn atg_fractional_max_pool2d_backward_out(grad_input_: *mut C_tensor, grad_output_: *mut C_tensor, self_: *mut C_tensor, kernel_size_data: *const i64, kernel_size_len: c_int, output_size_data: *const i64, output_size_len: c_int, indices_: *mut C_tensor) -> *mut *mut C_tensor;
    pub fn atg_fractional_max_pool2d_out(output_: *mut C_tensor, indices_: *mut C_tensor, self_: *mut C_tensor, kernel_size_data: *const i64, kernel_size_len: c_int, output_size_data: *const i64, output_size_len: c_int, random_samples_: *mut C_tensor) -> *mut *mut C_tensor;
    pub fn atg_frobenius_norm(self_: *mut C_tensor) -> *mut *mut C_tensor;
    pub fn atg_frobenius_norm1(self_: *mut C_tensor, dim_data: *const i64, dim_len: c_int, keepdim_: c_int) -> *mut *mut C_tensor;
    pub fn atg_frobenius_norm_out(result_: *mut C_tensor, self_: *mut C_tensor, dim_data: *const i64, dim_len: c_int, keepdim_: c_int) -> *mut *mut C_tensor;
    pub fn atg_full(size_data: *const i64, size_len: c_int, fill_value_: *mut C_scalar, options_kind: c_int, options_device: c_int) -> *mut *mut C_tensor;
    pub fn atg_full_like(self_: *mut C_tensor, fill_value_: *mut C_scalar) -> *mut *mut C_tensor;
    pub fn atg_full_like1(self_: *mut C_tensor, fill_value_: *mut C_scalar, options_kind: c_int, options_device: c_int) -> *mut *mut C_tensor;
    pub fn atg_full_out(result_: *mut C_tensor, size_data: *const i64, size_len: c_int, fill_value_: *mut C_scalar) -> *mut *mut C_tensor;
    pub fn atg_gather(self_: *mut C_tensor, dim_: i64, index_: *mut C_tensor) -> *mut *mut C_tensor;
    pub fn atg_gather_out(result_: *mut C_tensor, self_: *mut C_tensor, dim_: i64, index_: *mut C_tensor) -> *mut *mut C_tensor;
    pub fn atg_ge(self_: *mut C_tensor, other_: *mut C_scalar) -> *mut *mut C_tensor;
    pub fn atg_ge1(self_: *mut C_tensor, other_: *mut C_tensor) -> *mut *mut C_tensor;
    pub fn atg_ge_(self_: *mut C_tensor, other_: *mut C_scalar) -> *mut *mut C_tensor;
    pub fn atg_ge_1(self_: *mut C_tensor, other_: *mut C_tensor) -> *mut *mut C_tensor;
    pub fn atg_ge_out(result_: *mut C_tensor, self_: *mut C_tensor, other_: *mut C_scalar) -> *mut *mut C_tensor;
    pub fn atg_ge_out1(result_: *mut C_tensor, self_: *mut C_tensor, other_: *mut C_tensor) -> *mut *mut C_tensor;
    pub fn atg_gels(self_: *mut C_tensor, A_: *mut C_tensor) -> *mut *mut C_tensor;
    pub fn atg_gels_out(X_: *mut C_tensor, qr_: *mut C_tensor, self_: *mut C_tensor, A_: *mut C_tensor) -> *mut *mut C_tensor;
    pub fn atg_geometric_(self_: *mut C_tensor, p_: f64) -> *mut *mut C_tensor;
    pub fn atg_geqrf(self_: *mut C_tensor) -> *mut *mut C_tensor;
    pub fn atg_geqrf_out(result0_: *mut C_tensor, result1_: *mut C_tensor, self_: *mut C_tensor) -> *mut *mut C_tensor;
    pub fn atg_ger(self_: *mut C_tensor, vec2_: *mut C_tensor) -> *mut *mut C_tensor;
    pub fn atg_ger_out(result_: *mut C_tensor, self_: *mut C_tensor, vec2_: *mut C_tensor) -> *mut *mut C_tensor;
    pub fn atg_gesv(self_: *mut C_tensor, A_: *mut C_tensor) -> *mut *mut C_tensor;
    pub fn atg_gesv_out(solution_: *mut C_tensor, lu_: *mut C_tensor, self_: *mut C_tensor, A_: *mut C_tensor) -> *mut *mut C_tensor;
    pub fn atg_glu(self_: *mut C_tensor, dim_: i64) -> *mut *mut C_tensor;
    pub fn atg_glu_backward(grad_output_: *mut C_tensor, self_: *mut C_tensor, dim_: i64) -> *mut *mut C_tensor;
    pub fn atg_glu_backward_out(grad_input_: *mut C_tensor, grad_output_: *mut C_tensor, self_: *mut C_tensor, dim_: i64) -> *mut *mut C_tensor;
    pub fn atg_glu_out(output_: *mut C_tensor, self_: *mut C_tensor, dim_: i64) -> *mut *mut C_tensor;
    pub fn atg_grad(self_: *mut C_tensor) -> *mut *mut C_tensor;
    pub fn atg_grid_sampler(input_: *mut C_tensor, grid_: *mut C_tensor, interpolation_mode_: i64, padding_mode_: i64) -> *mut *mut C_tensor;
    pub fn atg_grid_sampler_2d(input_: *mut C_tensor, grid_: *mut C_tensor, interpolation_mode_: i64, padding_mode_: i64) -> *mut *mut C_tensor;
    pub fn atg_grid_sampler_2d_backward(grad_output_: *mut C_tensor, input_: *mut C_tensor, grid_: *mut C_tensor, interpolation_mode_: i64, padding_mode_: i64) -> *mut *mut C_tensor;
    pub fn atg_grid_sampler_3d(input_: *mut C_tensor, grid_: *mut C_tensor, interpolation_mode_: i64, padding_mode_: i64) -> *mut *mut C_tensor;
    pub fn atg_grid_sampler_3d_backward(grad_output_: *mut C_tensor, input_: *mut C_tensor, grid_: *mut C_tensor, interpolation_mode_: i64, padding_mode_: i64) -> *mut *mut C_tensor;
    pub fn atg_group_norm(input_: *mut C_tensor, num_groups_: i64, weight_: *mut C_tensor, bias_: *mut C_tensor, eps_: f64, cudnn_enabled_: c_int) -> *mut *mut C_tensor;
    pub fn atg_gru(input_: *mut C_tensor, hx_: *mut C_tensor, params_data: *const *mut C_tensor, params_len: c_int, has_biases_: c_int, num_layers_: i64, dropout_: f64, train_: c_int, bidirectional_: c_int, batch_first_: c_int) -> *mut *mut C_tensor;
    pub fn atg_gru1(data_: *mut C_tensor, batch_sizes_: *mut C_tensor, hx_: *mut C_tensor, params_data: *const *mut C_tensor, params_len: c_int, has_biases_: c_int, num_layers_: i64, dropout_: f64, train_: c_int, bidirectional_: c_int) -> *mut *mut C_tensor;
    pub fn atg_gru_cell(input_: *mut C_tensor, hx_: *mut C_tensor, w_ih_: *mut C_tensor, w_hh_: *mut C_tensor, b_ih_: *mut C_tensor, b_hh_: *mut C_tensor) -> *mut *mut C_tensor;
    pub fn atg_gt(self_: *mut C_tensor, other_: *mut C_scalar) -> *mut *mut C_tensor;
    pub fn atg_gt1(self_: *mut C_tensor, other_: *mut C_tensor) -> *mut *mut C_tensor;
    pub fn atg_gt_(self_: *mut C_tensor, other_: *mut C_scalar) -> *mut *mut C_tensor;
    pub fn atg_gt_1(self_: *mut C_tensor, other_: *mut C_tensor) -> *mut *mut C_tensor;
    pub fn atg_gt_out(result_: *mut C_tensor, self_: *mut C_tensor, other_: *mut C_scalar) -> *mut *mut C_tensor;
    pub fn atg_gt_out1(result_: *mut C_tensor, self_: *mut C_tensor, other_: *mut C_tensor) -> *mut *mut C_tensor;
    pub fn atg_hamming_window(window_length_: i64, options_kind: c_int, options_device: c_int) -> *mut *mut C_tensor;
    pub fn atg_hamming_window1(window_length_: i64, periodic_: c_int, options_kind: c_int, options_device: c_int) -> *mut *mut C_tensor;
    pub fn atg_hamming_window2(window_length_: i64, periodic_: c_int, alpha_: f64, options_kind: c_int, options_device: c_int) -> *mut *mut C_tensor;
    pub fn atg_hamming_window3(window_length_: i64, periodic_: c_int, alpha_: f64, beta_: f64, options_kind: c_int, options_device: c_int) -> *mut *mut C_tensor;
    pub fn atg_hann_window(window_length_: i64, options_kind: c_int, options_device: c_int) -> *mut *mut C_tensor;
    pub fn atg_hann_window1(window_length_: i64, periodic_: c_int, options_kind: c_int, options_device: c_int) -> *mut *mut C_tensor;
    pub fn atg_hardshrink(self_: *mut C_tensor) -> *mut *mut C_tensor;
    pub fn atg_hardshrink_backward(grad_out_: *mut C_tensor, self_: *mut C_tensor, lambd_: *mut C_scalar) -> *mut *mut C_tensor;
    pub fn atg_hardtanh(self_: *mut C_tensor) -> *mut *mut C_tensor;
    pub fn atg_hardtanh_(self_: *mut C_tensor) -> *mut *mut C_tensor;
    pub fn atg_hardtanh_out(output_: *mut C_tensor, self_: *mut C_tensor) -> *mut *mut C_tensor;
    pub fn atg_hinge_embedding_loss(self_: *mut C_tensor, target_: *mut C_tensor, margin_: f64, reduction_: i64) -> *mut *mut C_tensor;
    pub fn atg_histc(self_: *mut C_tensor, bins_: i64) -> *mut *mut C_tensor;
    pub fn atg_histc_out(result_: *mut C_tensor, self_: *mut C_tensor, bins_: i64) -> *mut *mut C_tensor;
    pub fn atg_hspmm(mat1_: *mut C_tensor, mat2_: *mut C_tensor) -> *mut *mut C_tensor;
    pub fn atg_hspmm_out(result_: *mut C_tensor, mat1_: *mut C_tensor, mat2_: *mut C_tensor) -> *mut *mut C_tensor;
    pub fn atg_ifft(self_: *mut C_tensor, signal_ndim_: i64, normalized_: c_int) -> *mut *mut C_tensor;
    pub fn atg_index(self_: *mut C_tensor, indices_data: *const *mut C_tensor, indices_len: c_int) -> *mut *mut C_tensor;
    pub fn atg_index_add_(self_: *mut C_tensor, dim_: i64, index_: *mut C_tensor, source_: *mut C_tensor) -> *mut *mut C_tensor;
    pub fn atg_index_copy_(self_: *mut C_tensor, dim_: i64, index_: *mut C_tensor, source_: *mut C_tensor) -> *mut *mut C_tensor;
    pub fn atg_index_fill_(self_: *mut C_tensor, dim_: i64, index_: *mut C_tensor, value_: *mut C_scalar) -> *mut *mut C_tensor;
    pub fn atg_index_fill_1(self_: *mut C_tensor, dim_: i64, index_: *mut C_tensor, value_: *mut C_tensor) -> *mut *mut C_tensor;
    pub fn atg_index_put(self_: *mut C_tensor, indices_data: *const *mut C_tensor, indices_len: c_int, values_: *mut C_tensor) -> *mut *mut C_tensor;
    pub fn atg_index_put_(self_: *mut C_tensor, indices_data: *const *mut C_tensor, indices_len: c_int, values_: *mut C_tensor) -> *mut *mut C_tensor;
    pub fn atg_index_select(self_: *mut C_tensor, dim_: i64, index_: *mut C_tensor) -> *mut *mut C_tensor;
    pub fn atg_index_select_out(result_: *mut C_tensor, self_: *mut C_tensor, dim_: i64, index_: *mut C_tensor) -> *mut *mut C_tensor;
    pub fn atg_indices(self_: *mut C_tensor) -> *mut *mut C_tensor;
    pub fn atg_instance_norm(input_: *mut C_tensor, weight_: *mut C_tensor, bias_: *mut C_tensor, running_mean_: *mut C_tensor, running_var_: *mut C_tensor, use_input_stats_: c_int, momentum_: f64, eps_: f64, cudnn_enabled_: c_int) -> *mut *mut C_tensor;
    pub fn atg_inverse(self_: *mut C_tensor) -> *mut *mut C_tensor;
    pub fn atg_inverse_out(result_: *mut C_tensor, self_: *mut C_tensor) -> *mut *mut C_tensor;
    pub fn atg_irfft(self_: *mut C_tensor, signal_ndim_: i64, normalized_: c_int, onesided_: c_int, signal_sizes_data: *const i64, signal_sizes_len: c_int) -> *mut *mut C_tensor;
    pub fn atg_isclose(self_: *mut C_tensor, other_: *mut C_tensor, rtol_: f64, atol_: f64, equal_nan_: c_int) -> *mut *mut C_tensor;
    pub fn atg_kl_div(self_: *mut C_tensor, target_: *mut C_tensor, reduction_: i64) -> *mut *mut C_tensor;
    pub fn atg_kl_div_backward(grad_output_: *mut C_tensor, self_: *mut C_tensor, target_: *mut C_tensor, reduction_: i64) -> *mut *mut C_tensor;
    pub fn atg_kthvalue(self_: *mut C_tensor, k_: i64, dim_: i64, keepdim_: c_int) -> *mut *mut C_tensor;
    pub fn atg_kthvalue_out(values_: *mut C_tensor, indices_: *mut C_tensor, self_: *mut C_tensor, k_: i64, dim_: i64, keepdim_: c_int) -> *mut *mut C_tensor;
    pub fn atg_l1_loss(self_: *mut C_tensor, target_: *mut C_tensor, reduction_: i64) -> *mut *mut C_tensor;
    pub fn atg_l1_loss_backward(grad_output_: *mut C_tensor, self_: *mut C_tensor, target_: *mut C_tensor, reduction_: i64) -> *mut *mut C_tensor;
    pub fn atg_l1_loss_backward_out(grad_input_: *mut C_tensor, grad_output_: *mut C_tensor, self_: *mut C_tensor, target_: *mut C_tensor, reduction_: i64) -> *mut *mut C_tensor;
    pub fn atg_l1_loss_out(output_: *mut C_tensor, self_: *mut C_tensor, target_: *mut C_tensor, reduction_: i64) -> *mut *mut C_tensor;
    pub fn atg_layer_norm(input_: *mut C_tensor, normalized_shape_data: *const i64, normalized_shape_len: c_int, weight_: *mut C_tensor, bias_: *mut C_tensor, eps_: f64, cudnn_enable_: c_int) -> *mut *mut C_tensor;
    pub fn atg_le(self_: *mut C_tensor, other_: *mut C_scalar) -> *mut *mut C_tensor;
    pub fn atg_le1(self_: *mut C_tensor, other_: *mut C_tensor) -> *mut *mut C_tensor;
    pub fn atg_le_(self_: *mut C_tensor, other_: *mut C_scalar) -> *mut *mut C_tensor;
    pub fn atg_le_1(self_: *mut C_tensor, other_: *mut C_tensor) -> *mut *mut C_tensor;
    pub fn atg_le_out(result_: *mut C_tensor, self_: *mut C_tensor, other_: *mut C_scalar) -> *mut *mut C_tensor;
    pub fn atg_le_out1(result_: *mut C_tensor, self_: *mut C_tensor, other_: *mut C_tensor) -> *mut *mut C_tensor;
    pub fn atg_leaky_relu(self_: *mut C_tensor) -> *mut *mut C_tensor;
    pub fn atg_leaky_relu_(self_: *mut C_tensor) -> *mut *mut C_tensor;
    pub fn atg_leaky_relu_out(output_: *mut C_tensor, self_: *mut C_tensor) -> *mut *mut C_tensor;
    pub fn atg_lerp(self_: *mut C_tensor, end_: *mut C_tensor, weight_: *mut C_scalar) -> *mut *mut C_tensor;
    pub fn atg_lerp_(self_: *mut C_tensor, end_: *mut C_tensor, weight_: *mut C_scalar) -> *mut *mut C_tensor;
    pub fn atg_lerp_out(result_: *mut C_tensor, self_: *mut C_tensor, end_: *mut C_tensor, weight_: *mut C_scalar) -> *mut *mut C_tensor;
    pub fn atg_lgamma(self_: *mut C_tensor) -> *mut *mut C_tensor;
    pub fn atg_lgamma_(self_: *mut C_tensor) -> *mut *mut C_tensor;
    pub fn atg_lgamma_out(result_: *mut C_tensor, self_: *mut C_tensor) -> *mut *mut C_tensor;
    pub fn atg_linear(input_: *mut C_tensor, weight_: *mut C_tensor, bias_: *mut C_tensor) -> *mut *mut C_tensor;
    pub fn atg_linspace(start_: *mut C_scalar, end_: *mut C_scalar, options_kind: c_int, options_device: c_int) -> *mut *mut C_tensor;
    pub fn atg_linspace1(start_: *mut C_scalar, end_: *mut C_scalar, steps_: i64, options_kind: c_int, options_device: c_int) -> *mut *mut C_tensor;
    pub fn atg_linspace_out(result_: *mut C_tensor, start_: *mut C_scalar, end_: *mut C_scalar) -> *mut *mut C_tensor;
    pub fn atg_linspace_out1(result_: *mut C_tensor, start_: *mut C_scalar, end_: *mut C_scalar, steps_: i64) -> *mut *mut C_tensor;
    pub fn atg_log(self_: *mut C_tensor) -> *mut *mut C_tensor;
    pub fn atg_log10(self_: *mut C_tensor) -> *mut *mut C_tensor;
    pub fn atg_log10_(self_: *mut C_tensor) -> *mut *mut C_tensor;
    pub fn atg_log10_out(result_: *mut C_tensor, self_: *mut C_tensor) -> *mut *mut C_tensor;
    pub fn atg_log1p(self_: *mut C_tensor) -> *mut *mut C_tensor;
    pub fn atg_log1p_(self_: *mut C_tensor) -> *mut *mut C_tensor;
    pub fn atg_log1p_out(result_: *mut C_tensor, self_: *mut C_tensor) -> *mut *mut C_tensor;
    pub fn atg_log2(self_: *mut C_tensor) -> *mut *mut C_tensor;
    pub fn atg_log2_(self_: *mut C_tensor) -> *mut *mut C_tensor;
    pub fn atg_log2_out(result_: *mut C_tensor, self_: *mut C_tensor) -> *mut *mut C_tensor;
    pub fn atg_log_(self_: *mut C_tensor) -> *mut *mut C_tensor;
    pub fn atg_log_normal_(self_: *mut C_tensor, mean_: f64, std_: f64) -> *mut *mut C_tensor;
    pub fn atg_log_out(result_: *mut C_tensor, self_: *mut C_tensor) -> *mut *mut C_tensor;
    pub fn atg_log_sigmoid(self_: *mut C_tensor) -> *mut *mut C_tensor;
    pub fn atg_log_sigmoid_backward(grad_output_: *mut C_tensor, self_: *mut C_tensor, buffer_: *mut C_tensor) -> *mut *mut C_tensor;
    pub fn atg_log_sigmoid_backward_out(grad_input_: *mut C_tensor, grad_output_: *mut C_tensor, self_: *mut C_tensor, buffer_: *mut C_tensor) -> *mut *mut C_tensor;
    pub fn atg_log_sigmoid_out(output_: *mut C_tensor, self_: *mut C_tensor) -> *mut *mut C_tensor;
    pub fn atg_log_softmax(self_: *mut C_tensor, dim_: i64) -> *mut *mut C_tensor;
    pub fn atg_log_softmax1(self_: *mut C_tensor, dim_: i64, dtype_: c_int) -> *mut *mut C_tensor;
    pub fn atg_logdet(self_: *mut C_tensor) -> *mut *mut C_tensor;
    pub fn atg_logspace(start_: *mut C_scalar, end_: *mut C_scalar, options_kind: c_int, options_device: c_int) -> *mut *mut C_tensor;
    pub fn atg_logspace1(start_: *mut C_scalar, end_: *mut C_scalar, steps_: i64, options_kind: c_int, options_device: c_int) -> *mut *mut C_tensor;
    pub fn atg_logspace_out(result_: *mut C_tensor, start_: *mut C_scalar, end_: *mut C_scalar) -> *mut *mut C_tensor;
    pub fn atg_logspace_out1(result_: *mut C_tensor, start_: *mut C_scalar, end_: *mut C_scalar, steps_: i64) -> *mut *mut C_tensor;
    pub fn atg_logsumexp(self_: *mut C_tensor, dim_: i64, keepdim_: c_int) -> *mut *mut C_tensor;
    pub fn atg_logsumexp_out(result_: *mut C_tensor, self_: *mut C_tensor, dim_: i64, keepdim_: c_int) -> *mut *mut C_tensor;
    pub fn atg_lstm(input_: *mut C_tensor, hx_data: *const *mut C_tensor, hx_len: c_int, params_data: *const *mut C_tensor, params_len: c_int, has_biases_: c_int, num_layers_: i64, dropout_: f64, train_: c_int, bidirectional_: c_int, batch_first_: c_int) -> *mut *mut C_tensor;
    pub fn atg_lstm1(data_: *mut C_tensor, batch_sizes_: *mut C_tensor, hx_data: *const *mut C_tensor, hx_len: c_int, params_data: *const *mut C_tensor, params_len: c_int, has_biases_: c_int, num_layers_: i64, dropout_: f64, train_: c_int, bidirectional_: c_int) -> *mut *mut C_tensor;
    pub fn atg_lstm_cell(input_: *mut C_tensor, hx_data: *const *mut C_tensor, hx_len: c_int, w_ih_: *mut C_tensor, w_hh_: *mut C_tensor, b_ih_: *mut C_tensor, b_hh_: *mut C_tensor) -> *mut *mut C_tensor;
    pub fn atg_lt(self_: *mut C_tensor, other_: *mut C_scalar) -> *mut *mut C_tensor;
    pub fn atg_lt1(self_: *mut C_tensor, other_: *mut C_tensor) -> *mut *mut C_tensor;
    pub fn atg_lt_(self_: *mut C_tensor, other_: *mut C_scalar) -> *mut *mut C_tensor;
    pub fn atg_lt_1(self_: *mut C_tensor, other_: *mut C_tensor) -> *mut *mut C_tensor;
    pub fn atg_lt_out(result_: *mut C_tensor, self_: *mut C_tensor, other_: *mut C_scalar) -> *mut *mut C_tensor;
    pub fn atg_lt_out1(result_: *mut C_tensor, self_: *mut C_tensor, other_: *mut C_tensor) -> *mut *mut C_tensor;
    pub fn atg_margin_ranking_loss(input1_: *mut C_tensor, input2_: *mut C_tensor, target_: *mut C_tensor, margin_: f64, reduction_: i64) -> *mut *mut C_tensor;
    pub fn atg_masked_fill_(self_: *mut C_tensor, mask_: *mut C_tensor, value_: *mut C_scalar) -> *mut *mut C_tensor;
    pub fn atg_masked_fill_1(self_: *mut C_tensor, mask_: *mut C_tensor, value_: *mut C_tensor) -> *mut *mut C_tensor;
    pub fn atg_masked_scatter_(self_: *mut C_tensor, mask_: *mut C_tensor, source_: *mut C_tensor) -> *mut *mut C_tensor;
    pub fn atg_masked_select(self_: *mut C_tensor, mask_: *mut C_tensor) -> *mut *mut C_tensor;
    pub fn atg_masked_select_out(result_: *mut C_tensor, self_: *mut C_tensor, mask_: *mut C_tensor) -> *mut *mut C_tensor;
    pub fn atg_matmul(self_: *mut C_tensor, other_: *mut C_tensor) -> *mut *mut C_tensor;
    pub fn atg_matmul_out(result_: *mut C_tensor, self_: *mut C_tensor, other_: *mut C_tensor) -> *mut *mut C_tensor;
    pub fn atg_matrix_power(self_: *mut C_tensor, n_: i64) -> *mut *mut C_tensor;
    pub fn atg_matrix_rank(self_: *mut C_tensor, symmetric_: c_int) -> *mut *mut C_tensor;
    pub fn atg_matrix_rank1(self_: *mut C_tensor, tol_: f64, symmetric_: c_int) -> *mut *mut C_tensor;
    pub fn atg_max(self_: *mut C_tensor) -> *mut *mut C_tensor;
    pub fn atg_max1(self_: *mut C_tensor, other_: *mut C_tensor) -> *mut *mut C_tensor;
    pub fn atg_max2(self_: *mut C_tensor, dim_: i64, keepdim_: c_int) -> *mut *mut C_tensor;
    pub fn atg_max_out(result_: *mut C_tensor, self_: *mut C_tensor, other_: *mut C_tensor) -> *mut *mut C_tensor;
    pub fn atg_max_out1(max_: *mut C_tensor, max_values_: *mut C_tensor, self_: *mut C_tensor, dim_: i64, keepdim_: c_int) -> *mut *mut C_tensor;
    pub fn atg_max_pool1d(self_: *mut C_tensor, kernel_size_data: *const i64, kernel_size_len: c_int, stride_data: *const i64, stride_len: c_int, padding_data: *const i64, padding_len: c_int, dilation_data: *const i64, dilation_len: c_int, ceil_mode_: c_int) -> *mut *mut C_tensor;
    pub fn atg_max_pool1d_with_indices(self_: *mut C_tensor, kernel_size_data: *const i64, kernel_size_len: c_int, stride_data: *const i64, stride_len: c_int, padding_data: *const i64, padding_len: c_int, dilation_data: *const i64, dilation_len: c_int, ceil_mode_: c_int) -> *mut *mut C_tensor;
    pub fn atg_max_pool2d(self_: *mut C_tensor, kernel_size_data: *const i64, kernel_size_len: c_int, stride_data: *const i64, stride_len: c_int, padding_data: *const i64, padding_len: c_int, dilation_data: *const i64, dilation_len: c_int, ceil_mode_: c_int) -> *mut *mut C_tensor;
    pub fn atg_max_pool2d_with_indices(self_: *mut C_tensor, kernel_size_data: *const i64, kernel_size_len: c_int, stride_data: *const i64, stride_len: c_int, padding_data: *const i64, padding_len: c_int, dilation_data: *const i64, dilation_len: c_int, ceil_mode_: c_int) -> *mut *mut C_tensor;
    pub fn atg_max_pool2d_with_indices_backward(grad_output_: *mut C_tensor, self_: *mut C_tensor, kernel_size_data: *const i64, kernel_size_len: c_int, stride_data: *const i64, stride_len: c_int, padding_data: *const i64, padding_len: c_int, dilation_data: *const i64, dilation_len: c_int, ceil_mode_: c_int, indices_: *mut C_tensor) -> *mut *mut C_tensor;
    pub fn atg_max_pool2d_with_indices_backward_out(grad_input_: *mut C_tensor, grad_output_: *mut C_tensor, self_: *mut C_tensor, kernel_size_data: *const i64, kernel_size_len: c_int, stride_data: *const i64, stride_len: c_int, padding_data: *const i64, padding_len: c_int, dilation_data: *const i64, dilation_len: c_int, ceil_mode_: c_int, indices_: *mut C_tensor) -> *mut *mut C_tensor;
    pub fn atg_max_pool2d_with_indices_out(output_: *mut C_tensor, indices_: *mut C_tensor, self_: *mut C_tensor, kernel_size_data: *const i64, kernel_size_len: c_int, stride_data: *const i64, stride_len: c_int, padding_data: *const i64, padding_len: c_int, dilation_data: *const i64, dilation_len: c_int, ceil_mode_: c_int) -> *mut *mut C_tensor;
    pub fn atg_max_pool3d(self_: *mut C_tensor, kernel_size_data: *const i64, kernel_size_len: c_int, stride_data: *const i64, stride_len: c_int, padding_data: *const i64, padding_len: c_int, dilation_data: *const i64, dilation_len: c_int, ceil_mode_: c_int) -> *mut *mut C_tensor;
    pub fn atg_max_pool3d_with_indices(self_: *mut C_tensor, kernel_size_data: *const i64, kernel_size_len: c_int, stride_data: *const i64, stride_len: c_int, padding_data: *const i64, padding_len: c_int, dilation_data: *const i64, dilation_len: c_int, ceil_mode_: c_int) -> *mut *mut C_tensor;
    pub fn atg_max_pool3d_with_indices_backward(grad_output_: *mut C_tensor, self_: *mut C_tensor, kernel_size_data: *const i64, kernel_size_len: c_int, stride_data: *const i64, stride_len: c_int, padding_data: *const i64, padding_len: c_int, dilation_data: *const i64, dilation_len: c_int, ceil_mode_: c_int, indices_: *mut C_tensor) -> *mut *mut C_tensor;
    pub fn atg_max_pool3d_with_indices_backward_out(grad_input_: *mut C_tensor, grad_output_: *mut C_tensor, self_: *mut C_tensor, kernel_size_data: *const i64, kernel_size_len: c_int, stride_data: *const i64, stride_len: c_int, padding_data: *const i64, padding_len: c_int, dilation_data: *const i64, dilation_len: c_int, ceil_mode_: c_int, indices_: *mut C_tensor) -> *mut *mut C_tensor;
    pub fn atg_max_pool3d_with_indices_out(output_: *mut C_tensor, indices_: *mut C_tensor, self_: *mut C_tensor, kernel_size_data: *const i64, kernel_size_len: c_int, stride_data: *const i64, stride_len: c_int, padding_data: *const i64, padding_len: c_int, dilation_data: *const i64, dilation_len: c_int, ceil_mode_: c_int) -> *mut *mut C_tensor;
    pub fn atg_max_unpool2d(self_: *mut C_tensor, indices_: *mut C_tensor, output_size_data: *const i64, output_size_len: c_int) -> *mut *mut C_tensor;
    pub fn atg_max_unpool2d_backward(grad_output_: *mut C_tensor, self_: *mut C_tensor, indices_: *mut C_tensor, output_size_data: *const i64, output_size_len: c_int) -> *mut *mut C_tensor;
    pub fn atg_max_unpool2d_backward_out(grad_input_: *mut C_tensor, grad_output_: *mut C_tensor, self_: *mut C_tensor, indices_: *mut C_tensor, output_size_data: *const i64, output_size_len: c_int) -> *mut *mut C_tensor;
    pub fn atg_max_unpool2d_out(output_: *mut C_tensor, self_: *mut C_tensor, indices_: *mut C_tensor, output_size_data: *const i64, output_size_len: c_int) -> *mut *mut C_tensor;
    pub fn atg_max_unpool3d(self_: *mut C_tensor, indices_: *mut C_tensor, output_size_data: *const i64, output_size_len: c_int, stride_data: *const i64, stride_len: c_int, padding_data: *const i64, padding_len: c_int) -> *mut *mut C_tensor;
    pub fn atg_max_unpool3d_backward(grad_output_: *mut C_tensor, self_: *mut C_tensor, indices_: *mut C_tensor, output_size_data: *const i64, output_size_len: c_int, stride_data: *const i64, stride_len: c_int, padding_data: *const i64, padding_len: c_int) -> *mut *mut C_tensor;
    pub fn atg_max_unpool3d_backward_out(grad_input_: *mut C_tensor, grad_output_: *mut C_tensor, self_: *mut C_tensor, indices_: *mut C_tensor, output_size_data: *const i64, output_size_len: c_int, stride_data: *const i64, stride_len: c_int, padding_data: *const i64, padding_len: c_int) -> *mut *mut C_tensor;
    pub fn atg_max_unpool3d_out(output_: *mut C_tensor, self_: *mut C_tensor, indices_: *mut C_tensor, output_size_data: *const i64, output_size_len: c_int, stride_data: *const i64, stride_len: c_int, padding_data: *const i64, padding_len: c_int) -> *mut *mut C_tensor;
    pub fn atg_max_values(self_: *mut C_tensor, dim_: i64, keepdim_: c_int) -> *mut *mut C_tensor;
    pub fn atg_mean(self_: *mut C_tensor) -> *mut *mut C_tensor;
    pub fn atg_mean1(self_: *mut C_tensor, dtype_: c_int) -> *mut *mut C_tensor;
    pub fn atg_mean2(self_: *mut C_tensor, dim_: i64, keepdim_: c_int) -> *mut *mut C_tensor;
    pub fn atg_mean3(self_: *mut C_tensor, dim_: i64, dtype_: c_int) -> *mut *mut C_tensor;
    pub fn atg_mean4(self_: *mut C_tensor, dim_: i64, keepdim_: c_int, dtype_: c_int) -> *mut *mut C_tensor;
    pub fn atg_mean_out(result_: *mut C_tensor, self_: *mut C_tensor, dim_: i64, keepdim_: c_int) -> *mut *mut C_tensor;
    pub fn atg_mean_out1(result_: *mut C_tensor, self_: *mut C_tensor, dim_: i64, dtype_: c_int) -> *mut *mut C_tensor;
    pub fn atg_mean_out2(result_: *mut C_tensor, self_: *mut C_tensor, dim_: i64, keepdim_: c_int, dtype_: c_int) -> *mut *mut C_tensor;
    pub fn atg_median(self_: *mut C_tensor) -> *mut *mut C_tensor;
    pub fn atg_median1(self_: *mut C_tensor, dim_: i64, keepdim_: c_int) -> *mut *mut C_tensor;
    pub fn atg_median_out(values_: *mut C_tensor, indices_: *mut C_tensor, self_: *mut C_tensor, dim_: i64, keepdim_: c_int) -> *mut *mut C_tensor;
    pub fn atg_meshgrid(tensors_data: *const *mut C_tensor, tensors_len: c_int) -> *mut *mut C_tensor;
    pub fn atg_min(self_: *mut C_tensor) -> *mut *mut C_tensor;
    pub fn atg_min1(self_: *mut C_tensor, other_: *mut C_tensor) -> *mut *mut C_tensor;
    pub fn atg_min2(self_: *mut C_tensor, dim_: i64, keepdim_: c_int) -> *mut *mut C_tensor;
    pub fn atg_min_out(result_: *mut C_tensor, self_: *mut C_tensor, other_: *mut C_tensor) -> *mut *mut C_tensor;
    pub fn atg_min_out1(min_: *mut C_tensor, min_indices_: *mut C_tensor, self_: *mut C_tensor, dim_: i64, keepdim_: c_int) -> *mut *mut C_tensor;
    pub fn atg_min_values(self_: *mut C_tensor, dim_: i64, keepdim_: c_int) -> *mut *mut C_tensor;
    pub fn atg_miopen_batch_norm(input_: *mut C_tensor, weight_: *mut C_tensor, bias_: *mut C_tensor, running_mean_: *mut C_tensor, running_var_: *mut C_tensor, training_: c_int, exponential_average_factor_: f64, epsilon_: f64) -> *mut *mut C_tensor;
    pub fn atg_miopen_batch_norm_backward(input_: *mut C_tensor, grad_output_: *mut C_tensor, weight_: *mut C_tensor, running_mean_: *mut C_tensor, running_var_: *mut C_tensor, save_mean_: *mut C_tensor, save_var_: *mut C_tensor, epsilon_: f64) -> *mut *mut C_tensor;
    pub fn atg_miopen_convolution(self_: *mut C_tensor, weight_: *mut C_tensor, bias_: *mut C_tensor, padding_data: *const i64, padding_len: c_int, stride_data: *const i64, stride_len: c_int, dilation_data: *const i64, dilation_len: c_int, groups_: i64, benchmark_: c_int, deterministic_: c_int) -> *mut *mut C_tensor;
    pub fn atg_miopen_convolution_backward_bias(grad_output_: *mut C_tensor) -> *mut *mut C_tensor;
    pub fn atg_miopen_convolution_backward_input(self_size_data: *const i64, self_size_len: c_int, grad_output_: *mut C_tensor, weight_: *mut C_tensor, padding_data: *const i64, padding_len: c_int, stride_data: *const i64, stride_len: c_int, dilation_data: *const i64, dilation_len: c_int, groups_: i64, benchmark_: c_int, deterministic_: c_int) -> *mut *mut C_tensor;
    pub fn atg_miopen_convolution_backward_weight(weight_size_data: *const i64, weight_size_len: c_int, grad_output_: *mut C_tensor, self_: *mut C_tensor, padding_data: *const i64, padding_len: c_int, stride_data: *const i64, stride_len: c_int, dilation_data: *const i64, dilation_len: c_int, groups_: i64, benchmark_: c_int, deterministic_: c_int) -> *mut *mut C_tensor;
    pub fn atg_miopen_convolution_transpose(self_: *mut C_tensor, weight_: *mut C_tensor, bias_: *mut C_tensor, padding_data: *const i64, padding_len: c_int, output_padding_data: *const i64, output_padding_len: c_int, stride_data: *const i64, stride_len: c_int, dilation_data: *const i64, dilation_len: c_int, groups_: i64, benchmark_: c_int, deterministic_: c_int) -> *mut *mut C_tensor;
    pub fn atg_miopen_convolution_transpose_backward_input(grad_output_: *mut C_tensor, weight_: *mut C_tensor, padding_data: *const i64, padding_len: c_int, stride_data: *const i64, stride_len: c_int, dilation_data: *const i64, dilation_len: c_int, groups_: i64, benchmark_: c_int, deterministic_: c_int) -> *mut *mut C_tensor;
    pub fn atg_miopen_convolution_transpose_backward_weight(weight_size_data: *const i64, weight_size_len: c_int, grad_output_: *mut C_tensor, self_: *mut C_tensor, padding_data: *const i64, padding_len: c_int, stride_data: *const i64, stride_len: c_int, dilation_data: *const i64, dilation_len: c_int, groups_: i64, benchmark_: c_int, deterministic_: c_int) -> *mut *mut C_tensor;
    pub fn atg_mkldnn_convolution(self_: *mut C_tensor, weight_: *mut C_tensor, bias_: *mut C_tensor, padding_data: *const i64, padding_len: c_int, stride_data: *const i64, stride_len: c_int, dilation_data: *const i64, dilation_len: c_int, groups_: i64) -> *mut *mut C_tensor;
    pub fn atg_mkldnn_convolution_backward_input(self_size_data: *const i64, self_size_len: c_int, grad_output_: *mut C_tensor, weight_: *mut C_tensor, padding_data: *const i64, padding_len: c_int, stride_data: *const i64, stride_len: c_int, dilation_data: *const i64, dilation_len: c_int, groups_: i64, bias_defined_: c_int) -> *mut *mut C_tensor;
    pub fn atg_mkldnn_convolution_backward_weights(weight_size_data: *const i64, weight_size_len: c_int, grad_output_: *mut C_tensor, self_: *mut C_tensor, padding_data: *const i64, padding_len: c_int, stride_data: *const i64, stride_len: c_int, dilation_data: *const i64, dilation_len: c_int, groups_: i64, bias_defined_: c_int) -> *mut *mut C_tensor;
    pub fn atg_mm(self_: *mut C_tensor, mat2_: *mut C_tensor) -> *mut *mut C_tensor;
    pub fn atg_mm_out(result_: *mut C_tensor, self_: *mut C_tensor, mat2_: *mut C_tensor) -> *mut *mut C_tensor;
    pub fn atg_mode(self_: *mut C_tensor, dim_: i64, keepdim_: c_int) -> *mut *mut C_tensor;
    pub fn atg_mode_out(values_: *mut C_tensor, indices_: *mut C_tensor, self_: *mut C_tensor, dim_: i64, keepdim_: c_int) -> *mut *mut C_tensor;
    pub fn atg_mse_loss(self_: *mut C_tensor, target_: *mut C_tensor, reduction_: i64) -> *mut *mut C_tensor;
    pub fn atg_mse_loss_backward(grad_output_: *mut C_tensor, self_: *mut C_tensor, target_: *mut C_tensor, reduction_: i64) -> *mut *mut C_tensor;
    pub fn atg_mse_loss_backward_out(grad_input_: *mut C_tensor, grad_output_: *mut C_tensor, self_: *mut C_tensor, target_: *mut C_tensor, reduction_: i64) -> *mut *mut C_tensor;
    pub fn atg_mse_loss_out(output_: *mut C_tensor, self_: *mut C_tensor, target_: *mut C_tensor, reduction_: i64) -> *mut *mut C_tensor;
    pub fn atg_mul(self_: *mut C_tensor, other_: *mut C_tensor) -> *mut *mut C_tensor;
    pub fn atg_mul1(self_: *mut C_tensor, other_: *mut C_scalar) -> *mut *mut C_tensor;
    pub fn atg_mul_(self_: *mut C_tensor, other_: *mut C_tensor) -> *mut *mut C_tensor;
    pub fn atg_mul_1(self_: *mut C_tensor, other_: *mut C_scalar) -> *mut *mut C_tensor;
    pub fn atg_mul_out(result_: *mut C_tensor, self_: *mut C_tensor, other_: *mut C_tensor) -> *mut *mut C_tensor;
    pub fn atg_multilabel_margin_loss(self_: *mut C_tensor, target_: *mut C_tensor, reduction_: i64) -> *mut *mut C_tensor;
    pub fn atg_multilabel_margin_loss_backward(grad_output_: *mut C_tensor, self_: *mut C_tensor, target_: *mut C_tensor, reduction_: i64, is_target_: *mut C_tensor) -> *mut *mut C_tensor;
    pub fn atg_multilabel_margin_loss_backward_out(grad_input_: *mut C_tensor, grad_output_: *mut C_tensor, self_: *mut C_tensor, target_: *mut C_tensor, reduction_: i64, is_target_: *mut C_tensor) -> *mut *mut C_tensor;
    pub fn atg_multilabel_margin_loss_out(output_: *mut C_tensor, self_: *mut C_tensor, target_: *mut C_tensor, reduction_: i64) -> *mut *mut C_tensor;
    pub fn atg_multinomial(self_: *mut C_tensor, num_samples_: i64, replacement_: c_int) -> *mut *mut C_tensor;
    pub fn atg_multinomial_out(result_: *mut C_tensor, self_: *mut C_tensor, num_samples_: i64, replacement_: c_int) -> *mut *mut C_tensor;
    pub fn atg_mv(self_: *mut C_tensor, vec_: *mut C_tensor) -> *mut *mut C_tensor;
    pub fn atg_mv_out(result_: *mut C_tensor, self_: *mut C_tensor, vec_: *mut C_tensor) -> *mut *mut C_tensor;
    pub fn atg_mvlgamma(self_: *mut C_tensor, p_: i64) -> *mut *mut C_tensor;
    pub fn atg_mvlgamma_(self_: *mut C_tensor, p_: i64) -> *mut *mut C_tensor;
    pub fn atg_narrow(self_: *mut C_tensor, dim_: i64, start_: i64, length_: i64) -> *mut *mut C_tensor;
    pub fn atg_narrow_copy(self_: *mut C_tensor, dim_: i64, start_: i64, length_: i64) -> *mut *mut C_tensor;
    pub fn atg_native_batch_norm(input_: *mut C_tensor, weight_: *mut C_tensor, bias_: *mut C_tensor, running_mean_: *mut C_tensor, running_var_: *mut C_tensor, training_: c_int, momentum_: f64, eps_: f64) -> *mut *mut C_tensor;
    pub fn atg_native_clone(self_: *mut C_tensor) -> *mut *mut C_tensor;
    pub fn atg_native_norm(self_: *mut C_tensor) -> *mut *mut C_tensor;
    pub fn atg_native_pow(self_: *mut C_tensor, exponent_: *mut C_scalar) -> *mut *mut C_tensor;
    pub fn atg_native_pow_out(result_: *mut C_tensor, self_: *mut C_tensor, exponent_: *mut C_scalar) -> *mut *mut C_tensor;
    pub fn atg_native_resize_as_(self_: *mut C_tensor, the_template_: *mut C_tensor) -> *mut *mut C_tensor;
    pub fn atg_native_zero_(self_: *mut C_tensor) -> *mut *mut C_tensor;
    pub fn atg_ne(self_: *mut C_tensor, other_: *mut C_scalar) -> *mut *mut C_tensor;
    pub fn atg_ne1(self_: *mut C_tensor, other_: *mut C_tensor) -> *mut *mut C_tensor;
    pub fn atg_ne_(self_: *mut C_tensor, other_: *mut C_scalar) -> *mut *mut C_tensor;
    pub fn atg_ne_1(self_: *mut C_tensor, other_: *mut C_tensor) -> *mut *mut C_tensor;
    pub fn atg_ne_out(result_: *mut C_tensor, self_: *mut C_tensor, other_: *mut C_scalar) -> *mut *mut C_tensor;
    pub fn atg_ne_out1(result_: *mut C_tensor, self_: *mut C_tensor, other_: *mut C_tensor) -> *mut *mut C_tensor;
    pub fn atg_neg(self_: *mut C_tensor) -> *mut *mut C_tensor;
    pub fn atg_neg_(self_: *mut C_tensor) -> *mut *mut C_tensor;
    pub fn atg_neg_out(result_: *mut C_tensor, self_: *mut C_tensor) -> *mut *mut C_tensor;
    pub fn atg_nll_loss(self_: *mut C_tensor, target_: *mut C_tensor, weight_: *mut C_tensor, reduction_: i64, ignore_index_: i64) -> *mut *mut C_tensor;
    pub fn atg_nll_loss2d(self_: *mut C_tensor, target_: *mut C_tensor, weight_: *mut C_tensor, reduction_: i64, ignore_index_: i64) -> *mut *mut C_tensor;
    pub fn atg_nll_loss2d_backward(grad_output_: *mut C_tensor, self_: *mut C_tensor, target_: *mut C_tensor, weight_: *mut C_tensor, reduction_: i64, ignore_index_: i64, total_weight_: *mut C_tensor) -> *mut *mut C_tensor;
    pub fn atg_nll_loss2d_backward_out(grad_input_: *mut C_tensor, grad_output_: *mut C_tensor, self_: *mut C_tensor, target_: *mut C_tensor, weight_: *mut C_tensor, reduction_: i64, ignore_index_: i64, total_weight_: *mut C_tensor) -> *mut *mut C_tensor;
    pub fn atg_nll_loss2d_out(output_: *mut C_tensor, self_: *mut C_tensor, target_: *mut C_tensor, weight_: *mut C_tensor, reduction_: i64, ignore_index_: i64) -> *mut *mut C_tensor;
    pub fn atg_nll_loss_backward(grad_output_: *mut C_tensor, self_: *mut C_tensor, target_: *mut C_tensor, weight_: *mut C_tensor, reduction_: i64, ignore_index_: i64, total_weight_: *mut C_tensor) -> *mut *mut C_tensor;
    pub fn atg_nll_loss_backward_out(grad_input_: *mut C_tensor, grad_output_: *mut C_tensor, self_: *mut C_tensor, target_: *mut C_tensor, weight_: *mut C_tensor, reduction_: i64, ignore_index_: i64, total_weight_: *mut C_tensor) -> *mut *mut C_tensor;
    pub fn atg_nll_loss_out(output_: *mut C_tensor, self_: *mut C_tensor, target_: *mut C_tensor, weight_: *mut C_tensor, reduction_: i64, ignore_index_: i64) -> *mut *mut C_tensor;
    pub fn atg_nonzero(self_: *mut C_tensor) -> *mut *mut C_tensor;
    pub fn atg_nonzero_out(result_: *mut C_tensor, self_: *mut C_tensor) -> *mut *mut C_tensor;
    pub fn atg_norm(self_: *mut C_tensor) -> *mut *mut C_tensor;
    pub fn atg_norm1(self_: *mut C_tensor, p_: *mut C_scalar, dim_: i64, keepdim_: c_int) -> *mut *mut C_tensor;
    pub fn atg_norm_except_dim(v_: *mut C_tensor, pow_: i64, dim_: i64) -> *mut *mut C_tensor;
    pub fn atg_norm_out(result_: *mut C_tensor, self_: *mut C_tensor, p_: *mut C_scalar, dim_: i64, keepdim_: c_int) -> *mut *mut C_tensor;
    pub fn atg_normal(mean_: *mut C_tensor, std_: f64) -> *mut *mut C_tensor;
    pub fn atg_normal1(mean_: f64, std_: *mut C_tensor) -> *mut *mut C_tensor;
    pub fn atg_normal2(mean_: *mut C_tensor, std_: *mut C_tensor) -> *mut *mut C_tensor;
    pub fn atg_normal_(self_: *mut C_tensor, mean_: f64, std_: f64) -> *mut *mut C_tensor;
    pub fn atg_normal_out(output_: *mut C_tensor, mean_: *mut C_tensor, std_: f64) -> *mut *mut C_tensor;
    pub fn atg_normal_out1(output_: *mut C_tensor, mean_: f64, std_: *mut C_tensor) -> *mut *mut C_tensor;
    pub fn atg_normal_out2(output_: *mut C_tensor, mean_: *mut C_tensor, std_: *mut C_tensor) -> *mut *mut C_tensor;
    pub fn atg_nuclear_norm(self_: *mut C_tensor, keepdim_: c_int) -> *mut *mut C_tensor;
    pub fn atg_nuclear_norm_out(result_: *mut C_tensor, self_: *mut C_tensor, keepdim_: c_int) -> *mut *mut C_tensor;
    pub fn atg_ones(size_data: *const i64, size_len: c_int, options_kind: c_int, options_device: c_int) -> *mut *mut C_tensor;
    pub fn atg_ones_like(self_: *mut C_tensor) -> *mut *mut C_tensor;
    pub fn atg_ones_like1(self_: *mut C_tensor, options_kind: c_int, options_device: c_int) -> *mut *mut C_tensor;
    pub fn atg_ones_out(result_: *mut C_tensor, size_data: *const i64, size_len: c_int) -> *mut *mut C_tensor;
    pub fn atg_orgqr(self_: *mut C_tensor, input2_: *mut C_tensor) -> *mut *mut C_tensor;
    pub fn atg_orgqr_out(result_: *mut C_tensor, self_: *mut C_tensor, input2_: *mut C_tensor) -> *mut *mut C_tensor;
    pub fn atg_ormqr(self_: *mut C_tensor, input2_: *mut C_tensor, input3_: *mut C_tensor, left_: c_int, transpose_: c_int) -> *mut *mut C_tensor;
    pub fn atg_ormqr_out(result_: *mut C_tensor, self_: *mut C_tensor, input2_: *mut C_tensor, input3_: *mut C_tensor, left_: c_int, transpose_: c_int) -> *mut *mut C_tensor;
    pub fn atg_pairwise_distance(x1_: *mut C_tensor, x2_: *mut C_tensor, p_: f64, eps_: f64, keepdim_: c_int) -> *mut *mut C_tensor;
    pub fn atg_pdist(self_: *mut C_tensor, p_: f64) -> *mut *mut C_tensor;
    pub fn atg_permute(self_: *mut C_tensor, dims_data: *const i64, dims_len: c_int) -> *mut *mut C_tensor;
    pub fn atg_pin_memory(self_: *mut C_tensor) -> *mut *mut C_tensor;
    pub fn atg_pinverse(self_: *mut C_tensor, rcond_: f64) -> *mut *mut C_tensor;
    pub fn atg_pixel_shuffle(self_: *mut C_tensor, upscale_factor_: i64) -> *mut *mut C_tensor;
    pub fn atg_poisson(self_: *mut C_tensor) -> *mut *mut C_tensor;
    pub fn atg_polygamma(n_: i64, self_: *mut C_tensor) -> *mut *mut C_tensor;
    pub fn atg_polygamma_(self_: *mut C_tensor, n_: i64) -> *mut *mut C_tensor;
    pub fn atg_polygamma_out(result_: *mut C_tensor, n_: i64, self_: *mut C_tensor) -> *mut *mut C_tensor;
    pub fn atg_potri(self_: *mut C_tensor, upper_: c_int) -> *mut *mut C_tensor;
    pub fn atg_potri_out(result_: *mut C_tensor, self_: *mut C_tensor, upper_: c_int) -> *mut *mut C_tensor;
    pub fn atg_potrs(self_: *mut C_tensor, input2_: *mut C_tensor, upper_: c_int) -> *mut *mut C_tensor;
    pub fn atg_potrs_out(result_: *mut C_tensor, self_: *mut C_tensor, input2_: *mut C_tensor, upper_: c_int) -> *mut *mut C_tensor;
    pub fn atg_pow(self_: *mut C_tensor, exponent_: *mut C_scalar) -> *mut *mut C_tensor;
    pub fn atg_pow1(self_: *mut C_tensor, exponent_: *mut C_tensor) -> *mut *mut C_tensor;
    pub fn atg_pow2(self_scalar_: *mut C_scalar, exponent_: *mut C_tensor) -> *mut *mut C_tensor;
    pub fn atg_pow_(self_: *mut C_tensor, exponent_: *mut C_scalar) -> *mut *mut C_tensor;
    pub fn atg_pow_1(self_: *mut C_tensor, exponent_: *mut C_tensor) -> *mut *mut C_tensor;
    pub fn atg_pow_out(result_: *mut C_tensor, self_: *mut C_tensor, exponent_: *mut C_scalar) -> *mut *mut C_tensor;
    pub fn atg_pow_out1(result_: *mut C_tensor, self_: *mut C_tensor, exponent_: *mut C_tensor) -> *mut *mut C_tensor;
    pub fn atg_pow_out2(result_: *mut C_tensor, self_scalar_: *mut C_scalar, exponent_: *mut C_tensor) -> *mut *mut C_tensor;
    pub fn atg_prelu(self_: *mut C_tensor, weight_: *mut C_tensor) -> *mut *mut C_tensor;
    pub fn atg_prelu_backward(grad_output_: *mut C_tensor, self_: *mut C_tensor, weight_: *mut C_tensor) -> *mut *mut C_tensor;
    pub fn atg_prod(self_: *mut C_tensor) -> *mut *mut C_tensor;
    pub fn atg_prod1(self_: *mut C_tensor, dtype_: c_int) -> *mut *mut C_tensor;
    pub fn atg_prod2(self_: *mut C_tensor, dim_: i64, keepdim_: c_int) -> *mut *mut C_tensor;
    pub fn atg_prod3(self_: *mut C_tensor, dim_: i64, dtype_: c_int) -> *mut *mut C_tensor;
    pub fn atg_prod4(self_: *mut C_tensor, dim_: i64, keepdim_: c_int, dtype_: c_int) -> *mut *mut C_tensor;
    pub fn atg_prod_out(result_: *mut C_tensor, self_: *mut C_tensor, dim_: i64, keepdim_: c_int) -> *mut *mut C_tensor;
    pub fn atg_prod_out1(result_: *mut C_tensor, self_: *mut C_tensor, dim_: i64, dtype_: c_int) -> *mut *mut C_tensor;
    pub fn atg_prod_out2(result_: *mut C_tensor, self_: *mut C_tensor, dim_: i64, keepdim_: c_int, dtype_: c_int) -> *mut *mut C_tensor;
    pub fn atg_pstrf(self_: *mut C_tensor, upper_: c_int) -> *mut *mut C_tensor;
    pub fn atg_pstrf_out(u_: *mut C_tensor, piv_: *mut C_tensor, self_: *mut C_tensor, upper_: c_int) -> *mut *mut C_tensor;
    pub fn atg_put_(self_: *mut C_tensor, index_: *mut C_tensor, source_: *mut C_tensor, accumulate_: c_int) -> *mut *mut C_tensor;
    pub fn atg_qr(self_: *mut C_tensor) -> *mut *mut C_tensor;
    pub fn atg_qr_out(Q_: *mut C_tensor, R_: *mut C_tensor, self_: *mut C_tensor) -> *mut *mut C_tensor;
    pub fn atg_rand(size_data: *const i64, size_len: c_int, options_kind: c_int, options_device: c_int) -> *mut *mut C_tensor;
    pub fn atg_rand_like(self_: *mut C_tensor) -> *mut *mut C_tensor;
    pub fn atg_rand_like1(self_: *mut C_tensor, options_kind: c_int, options_device: c_int) -> *mut *mut C_tensor;
    pub fn atg_rand_out(result_: *mut C_tensor, size_data: *const i64, size_len: c_int) -> *mut *mut C_tensor;
    pub fn atg_randint(high_: i64, size_data: *const i64, size_len: c_int, options_kind: c_int, options_device: c_int) -> *mut *mut C_tensor;
    pub fn atg_randint1(low_: i64, high_: i64, size_data: *const i64, size_len: c_int, options_kind: c_int, options_device: c_int) -> *mut *mut C_tensor;
    pub fn atg_randint_like(self_: *mut C_tensor, high_: i64) -> *mut *mut C_tensor;
    pub fn atg_randint_like1(self_: *mut C_tensor, low_: i64, high_: i64) -> *mut *mut C_tensor;
    pub fn atg_randint_like2(self_: *mut C_tensor, high_: i64, options_kind: c_int, options_device: c_int) -> *mut *mut C_tensor;
    pub fn atg_randint_like3(self_: *mut C_tensor, low_: i64, high_: i64, options_kind: c_int, options_device: c_int) -> *mut *mut C_tensor;
    pub fn atg_randint_out(result_: *mut C_tensor, high_: i64, size_data: *const i64, size_len: c_int) -> *mut *mut C_tensor;
    pub fn atg_randint_out1(result_: *mut C_tensor, low_: i64, high_: i64, size_data: *const i64, size_len: c_int) -> *mut *mut C_tensor;
    pub fn atg_randn(size_data: *const i64, size_len: c_int, options_kind: c_int, options_device: c_int) -> *mut *mut C_tensor;
    pub fn atg_randn_like(self_: *mut C_tensor) -> *mut *mut C_tensor;
    pub fn atg_randn_like1(self_: *mut C_tensor, options_kind: c_int, options_device: c_int) -> *mut *mut C_tensor;
    pub fn atg_randn_out(result_: *mut C_tensor, size_data: *const i64, size_len: c_int) -> *mut *mut C_tensor;
    pub fn atg_random_(self_: *mut C_tensor) -> *mut *mut C_tensor;
    pub fn atg_random_1(self_: *mut C_tensor, to_: i64) -> *mut *mut C_tensor;
    pub fn atg_random_2(self_: *mut C_tensor, from_: i64, to_: i64) -> *mut *mut C_tensor;
    pub fn atg_randperm(n_: i64, options_kind: c_int, options_device: c_int) -> *mut *mut C_tensor;
    pub fn atg_randperm_out(result_: *mut C_tensor, n_: i64) -> *mut *mut C_tensor;
    pub fn atg_range(start_: *mut C_scalar, end_: *mut C_scalar, options_kind: c_int, options_device: c_int) -> *mut *mut C_tensor;
    pub fn atg_range1(start_: *mut C_scalar, end_: *mut C_scalar, step_: *mut C_scalar, options_kind: c_int, options_device: c_int) -> *mut *mut C_tensor;
    pub fn atg_range_out(result_: *mut C_tensor, start_: *mut C_scalar, end_: *mut C_scalar) -> *mut *mut C_tensor;
    pub fn atg_range_out1(result_: *mut C_tensor, start_: *mut C_scalar, end_: *mut C_scalar, step_: *mut C_scalar) -> *mut *mut C_tensor;
    pub fn atg_reciprocal(self_: *mut C_tensor) -> *mut *mut C_tensor;
    pub fn atg_reciprocal_(self_: *mut C_tensor) -> *mut *mut C_tensor;
    pub fn atg_reciprocal_out(result_: *mut C_tensor, self_: *mut C_tensor) -> *mut *mut C_tensor;
    pub fn atg_reflection_pad1d(self_: *mut C_tensor, padding_data: *const i64, padding_len: c_int) -> *mut *mut C_tensor;
    pub fn atg_reflection_pad1d_backward(grad_output_: *mut C_tensor, self_: *mut C_tensor, padding_data: *const i64, padding_len: c_int) -> *mut *mut C_tensor;
    pub fn atg_reflection_pad1d_backward_out(grad_input_: *mut C_tensor, grad_output_: *mut C_tensor, self_: *mut C_tensor, padding_data: *const i64, padding_len: c_int) -> *mut *mut C_tensor;
    pub fn atg_reflection_pad1d_out(output_: *mut C_tensor, self_: *mut C_tensor, padding_data: *const i64, padding_len: c_int) -> *mut *mut C_tensor;
    pub fn atg_reflection_pad2d(self_: *mut C_tensor, padding_data: *const i64, padding_len: c_int) -> *mut *mut C_tensor;
    pub fn atg_reflection_pad2d_backward(grad_output_: *mut C_tensor, self_: *mut C_tensor, padding_data: *const i64, padding_len: c_int) -> *mut *mut C_tensor;
    pub fn atg_reflection_pad2d_backward_out(grad_input_: *mut C_tensor, grad_output_: *mut C_tensor, self_: *mut C_tensor, padding_data: *const i64, padding_len: c_int) -> *mut *mut C_tensor;
    pub fn atg_reflection_pad2d_out(output_: *mut C_tensor, self_: *mut C_tensor, padding_data: *const i64, padding_len: c_int) -> *mut *mut C_tensor;
    pub fn atg_relu(self_: *mut C_tensor) -> *mut *mut C_tensor;
    pub fn atg_relu_(self_: *mut C_tensor) -> *mut *mut C_tensor;
    pub fn atg_remainder(self_: *mut C_tensor, other_: *mut C_scalar) -> *mut *mut C_tensor;
    pub fn atg_remainder1(self_: *mut C_tensor, other_: *mut C_tensor) -> *mut *mut C_tensor;
    pub fn atg_remainder_(self_: *mut C_tensor, other_: *mut C_scalar) -> *mut *mut C_tensor;
    pub fn atg_remainder_1(self_: *mut C_tensor, other_: *mut C_tensor) -> *mut *mut C_tensor;
    pub fn atg_remainder_out(result_: *mut C_tensor, self_: *mut C_tensor, other_: *mut C_scalar) -> *mut *mut C_tensor;
    pub fn atg_remainder_out1(result_: *mut C_tensor, self_: *mut C_tensor, other_: *mut C_tensor) -> *mut *mut C_tensor;
    pub fn atg_renorm(self_: *mut C_tensor, p_: *mut C_scalar, dim_: i64, maxnorm_: *mut C_scalar) -> *mut *mut C_tensor;
    pub fn atg_renorm_(self_: *mut C_tensor, p_: *mut C_scalar, dim_: i64, maxnorm_: *mut C_scalar) -> *mut *mut C_tensor;
    pub fn atg_renorm_out(result_: *mut C_tensor, self_: *mut C_tensor, p_: *mut C_scalar, dim_: i64, maxnorm_: *mut C_scalar) -> *mut *mut C_tensor;
    pub fn atg_repeat(self_: *mut C_tensor, repeats_data: *const i64, repeats_len: c_int) -> *mut *mut C_tensor;
    pub fn atg_replication_pad1d(self_: *mut C_tensor, padding_data: *const i64, padding_len: c_int) -> *mut *mut C_tensor;
    pub fn atg_replication_pad1d_backward(grad_output_: *mut C_tensor, self_: *mut C_tensor, padding_data: *const i64, padding_len: c_int) -> *mut *mut C_tensor;
    pub fn atg_replication_pad1d_backward_out(grad_input_: *mut C_tensor, grad_output_: *mut C_tensor, self_: *mut C_tensor, padding_data: *const i64, padding_len: c_int) -> *mut *mut C_tensor;
    pub fn atg_replication_pad1d_out(output_: *mut C_tensor, self_: *mut C_tensor, padding_data: *const i64, padding_len: c_int) -> *mut *mut C_tensor;
    pub fn atg_replication_pad2d(self_: *mut C_tensor, padding_data: *const i64, padding_len: c_int) -> *mut *mut C_tensor;
    pub fn atg_replication_pad2d_backward(grad_output_: *mut C_tensor, self_: *mut C_tensor, padding_data: *const i64, padding_len: c_int) -> *mut *mut C_tensor;
    pub fn atg_replication_pad2d_backward_out(grad_input_: *mut C_tensor, grad_output_: *mut C_tensor, self_: *mut C_tensor, padding_data: *const i64, padding_len: c_int) -> *mut *mut C_tensor;
    pub fn atg_replication_pad2d_out(output_: *mut C_tensor, self_: *mut C_tensor, padding_data: *const i64, padding_len: c_int) -> *mut *mut C_tensor;
    pub fn atg_replication_pad3d(self_: *mut C_tensor, padding_data: *const i64, padding_len: c_int) -> *mut *mut C_tensor;
    pub fn atg_replication_pad3d_backward(grad_output_: *mut C_tensor, self_: *mut C_tensor, padding_data: *const i64, padding_len: c_int) -> *mut *mut C_tensor;
    pub fn atg_replication_pad3d_backward_out(grad_input_: *mut C_tensor, grad_output_: *mut C_tensor, self_: *mut C_tensor, padding_data: *const i64, padding_len: c_int) -> *mut *mut C_tensor;
    pub fn atg_replication_pad3d_out(output_: *mut C_tensor, self_: *mut C_tensor, padding_data: *const i64, padding_len: c_int) -> *mut *mut C_tensor;
    pub fn atg_reshape(self_: *mut C_tensor, shape_data: *const i64, shape_len: c_int) -> *mut *mut C_tensor;
    pub fn atg_reshape_as(self_: *mut C_tensor, other_: *mut C_tensor) -> *mut *mut C_tensor;
    pub fn atg_resize_(self_: *mut C_tensor, size_data: *const i64, size_len: c_int) -> *mut *mut C_tensor;
    pub fn atg_resize_as_(self_: *mut C_tensor, the_template_: *mut C_tensor) -> *mut *mut C_tensor;
    pub fn atg_rfft(self_: *mut C_tensor, signal_ndim_: i64, normalized_: c_int, onesided_: c_int) -> *mut *mut C_tensor;
    pub fn atg_rnn_relu(input_: *mut C_tensor, hx_: *mut C_tensor, params_data: *const *mut C_tensor, params_len: c_int, has_biases_: c_int, num_layers_: i64, dropout_: f64, train_: c_int, bidirectional_: c_int, batch_first_: c_int) -> *mut *mut C_tensor;
    pub fn atg_rnn_relu1(data_: *mut C_tensor, batch_sizes_: *mut C_tensor, hx_: *mut C_tensor, params_data: *const *mut C_tensor, params_len: c_int, has_biases_: c_int, num_layers_: i64, dropout_: f64, train_: c_int, bidirectional_: c_int) -> *mut *mut C_tensor;
    pub fn atg_rnn_relu_cell(input_: *mut C_tensor, hx_: *mut C_tensor, w_ih_: *mut C_tensor, w_hh_: *mut C_tensor, b_ih_: *mut C_tensor, b_hh_: *mut C_tensor) -> *mut *mut C_tensor;
    pub fn atg_rnn_tanh(input_: *mut C_tensor, hx_: *mut C_tensor, params_data: *const *mut C_tensor, params_len: c_int, has_biases_: c_int, num_layers_: i64, dropout_: f64, train_: c_int, bidirectional_: c_int, batch_first_: c_int) -> *mut *mut C_tensor;
    pub fn atg_rnn_tanh1(data_: *mut C_tensor, batch_sizes_: *mut C_tensor, hx_: *mut C_tensor, params_data: *const *mut C_tensor, params_len: c_int, has_biases_: c_int, num_layers_: i64, dropout_: f64, train_: c_int, bidirectional_: c_int) -> *mut *mut C_tensor;
    pub fn atg_rnn_tanh_cell(input_: *mut C_tensor, hx_: *mut C_tensor, w_ih_: *mut C_tensor, w_hh_: *mut C_tensor, b_ih_: *mut C_tensor, b_hh_: *mut C_tensor) -> *mut *mut C_tensor;
    pub fn atg_roipooling2d_backward(input_: *mut C_tensor, rois_: *mut C_tensor, pooledHeight_: i64, pooledWidth_: i64, spatialScale_: f64, gradOutput_: *mut C_tensor, argmaxes_: *mut C_tensor) -> *mut *mut C_tensor;
    pub fn atg_roll(self_: *mut C_tensor, shifts_data: *const i64, shifts_len: c_int, dims_data: *const i64, dims_len: c_int) -> *mut *mut C_tensor;
    pub fn atg_rot90(self_: *mut C_tensor, k_: i64, dims_data: *const i64, dims_len: c_int) -> *mut *mut C_tensor;
    pub fn atg_round(self_: *mut C_tensor) -> *mut *mut C_tensor;
    pub fn atg_round_(self_: *mut C_tensor) -> *mut *mut C_tensor;
    pub fn atg_round_out(result_: *mut C_tensor, self_: *mut C_tensor) -> *mut *mut C_tensor;
    pub fn atg_rrelu(self_: *mut C_tensor, training_: c_int) -> *mut *mut C_tensor;
    pub fn atg_rrelu_(self_: *mut C_tensor, training_: c_int) -> *mut *mut C_tensor;
    pub fn atg_rrelu_with_noise(self_: *mut C_tensor, noise_: *mut C_tensor, training_: c_int) -> *mut *mut C_tensor;
    pub fn atg_rrelu_with_noise_(self_: *mut C_tensor, noise_: *mut C_tensor, training_: c_int) -> *mut *mut C_tensor;
    pub fn atg_rrelu_with_noise_out(output_: *mut C_tensor, self_: *mut C_tensor, noise_: *mut C_tensor, training_: c_int) -> *mut *mut C_tensor;
    pub fn atg_rsqrt(self_: *mut C_tensor) -> *mut *mut C_tensor;
    pub fn atg_rsqrt_(self_: *mut C_tensor) -> *mut *mut C_tensor;
    pub fn atg_rsqrt_out(result_: *mut C_tensor, self_: *mut C_tensor) -> *mut *mut C_tensor;
    pub fn atg_rsub(self_: *mut C_tensor, other_: *mut C_tensor) -> *mut *mut C_tensor;
    pub fn atg_rsub1(self_: *mut C_tensor, other_: *mut C_scalar) -> *mut *mut C_tensor;
    pub fn atg_s_native_addmm(self_: *mut C_tensor, mat1_: *mut C_tensor, mat2_: *mut C_tensor) -> *mut *mut C_tensor;
    pub fn atg_s_native_addmm_(self_: *mut C_tensor, mat1_: *mut C_tensor, mat2_: *mut C_tensor) -> *mut *mut C_tensor;
    pub fn atg_s_native_addmm_out(result_: *mut C_tensor, self_: *mut C_tensor, mat1_: *mut C_tensor, mat2_: *mut C_tensor) -> *mut *mut C_tensor;
    pub fn atg_scatter_(self_: *mut C_tensor, dim_: i64, index_: *mut C_tensor, src_: *mut C_tensor) -> *mut *mut C_tensor;
    pub fn atg_scatter_1(self_: *mut C_tensor, dim_: i64, index_: *mut C_tensor, value_: *mut C_scalar) -> *mut *mut C_tensor;
    pub fn atg_scatter_add_(self_: *mut C_tensor, dim_: i64, index_: *mut C_tensor, src_: *mut C_tensor) -> *mut *mut C_tensor;
    pub fn atg_select(self_: *mut C_tensor, dim_: i64, index_: i64) -> *mut *mut C_tensor;
    pub fn atg_selu(self_: *mut C_tensor) -> *mut *mut C_tensor;
    pub fn atg_selu_(self_: *mut C_tensor) -> *mut *mut C_tensor;
    pub fn atg_set_(self_: *mut C_tensor) -> *mut *mut C_tensor;
    pub fn atg_set_1(self_: *mut C_tensor, source_: *mut C_tensor) -> *mut *mut C_tensor;
    pub fn atg_set_requires_grad(self_: *mut C_tensor, r_: c_int) -> *mut *mut C_tensor;
    pub fn atg_sigmoid(self_: *mut C_tensor) -> *mut *mut C_tensor;
    pub fn atg_sigmoid_(self_: *mut C_tensor) -> *mut *mut C_tensor;
    pub fn atg_sigmoid_out(result_: *mut C_tensor, self_: *mut C_tensor) -> *mut *mut C_tensor;
    pub fn atg_sign(self_: *mut C_tensor) -> *mut *mut C_tensor;
    pub fn atg_sign_(self_: *mut C_tensor) -> *mut *mut C_tensor;
    pub fn atg_sign_out(result_: *mut C_tensor, self_: *mut C_tensor) -> *mut *mut C_tensor;
    pub fn atg_sin(self_: *mut C_tensor) -> *mut *mut C_tensor;
    pub fn atg_sin_(self_: *mut C_tensor) -> *mut *mut C_tensor;
    pub fn atg_sin_out(result_: *mut C_tensor, self_: *mut C_tensor) -> *mut *mut C_tensor;
    pub fn atg_sinh(self_: *mut C_tensor) -> *mut *mut C_tensor;
    pub fn atg_sinh_(self_: *mut C_tensor) -> *mut *mut C_tensor;
    pub fn atg_sinh_out(result_: *mut C_tensor, self_: *mut C_tensor) -> *mut *mut C_tensor;
    pub fn atg_slice(self_: *mut C_tensor, dim_: i64, start_: i64, end_: i64, step_: i64) -> *mut *mut C_tensor;
    pub fn atg_slogdet(self_: *mut C_tensor) -> *mut *mut C_tensor;
    pub fn atg_smm(self_: *mut C_tensor, mat2_: *mut C_tensor) -> *mut *mut C_tensor;
    pub fn atg_smooth_l1_loss(self_: *mut C_tensor, target_: *mut C_tensor, reduction_: i64) -> *mut *mut C_tensor;
    pub fn atg_smooth_l1_loss_backward(grad_output_: *mut C_tensor, self_: *mut C_tensor, target_: *mut C_tensor, reduction_: i64) -> *mut *mut C_tensor;
    pub fn atg_smooth_l1_loss_backward_out(grad_input_: *mut C_tensor, grad_output_: *mut C_tensor, self_: *mut C_tensor, target_: *mut C_tensor, reduction_: i64) -> *mut *mut C_tensor;
    pub fn atg_smooth_l1_loss_out(output_: *mut C_tensor, self_: *mut C_tensor, target_: *mut C_tensor, reduction_: i64) -> *mut *mut C_tensor;
    pub fn atg_soft_margin_loss(self_: *mut C_tensor, target_: *mut C_tensor, reduction_: i64) -> *mut *mut C_tensor;
    pub fn atg_soft_margin_loss_backward(grad_output_: *mut C_tensor, self_: *mut C_tensor, target_: *mut C_tensor, reduction_: i64) -> *mut *mut C_tensor;
    pub fn atg_soft_margin_loss_backward_out(grad_input_: *mut C_tensor, grad_output_: *mut C_tensor, self_: *mut C_tensor, target_: *mut C_tensor, reduction_: i64) -> *mut *mut C_tensor;
    pub fn atg_soft_margin_loss_out(output_: *mut C_tensor, self_: *mut C_tensor, target_: *mut C_tensor, reduction_: i64) -> *mut *mut C_tensor;
    pub fn atg_softmax(self_: *mut C_tensor, dim_: i64) -> *mut *mut C_tensor;
    pub fn atg_softmax1(self_: *mut C_tensor, dim_: i64, dtype_: c_int) -> *mut *mut C_tensor;
    pub fn atg_softplus(self_: *mut C_tensor) -> *mut *mut C_tensor;
    pub fn atg_softplus_out(output_: *mut C_tensor, self_: *mut C_tensor) -> *mut *mut C_tensor;
    pub fn atg_softshrink(self_: *mut C_tensor) -> *mut *mut C_tensor;
    pub fn atg_softshrink_out(output_: *mut C_tensor, self_: *mut C_tensor) -> *mut *mut C_tensor;
    pub fn atg_sort(self_: *mut C_tensor, dim_: i64, descending_: c_int) -> *mut *mut C_tensor;
    pub fn atg_sort_out(values_: *mut C_tensor, indices_: *mut C_tensor, self_: *mut C_tensor, dim_: i64, descending_: c_int) -> *mut *mut C_tensor;
    pub fn atg_sparse_coo_tensor(size_data: *const i64, size_len: c_int, options_kind: c_int, options_device: c_int) -> *mut *mut C_tensor;
    pub fn atg_sparse_coo_tensor1(indices_: *mut C_tensor, values_: *mut C_tensor, options_kind: c_int, options_device: c_int) -> *mut *mut C_tensor;
    pub fn atg_sparse_coo_tensor2(indices_: *mut C_tensor, values_: *mut C_tensor, size_data: *const i64, size_len: c_int, options_kind: c_int, options_device: c_int) -> *mut *mut C_tensor;
    pub fn atg_sparse_resize_(self_: *mut C_tensor, size_data: *const i64, size_len: c_int, sparse_dim_: i64, dense_dim_: i64) -> *mut *mut C_tensor;
    pub fn atg_sparse_resize_and_clear_(self_: *mut C_tensor, size_data: *const i64, size_len: c_int, sparse_dim_: i64, dense_dim_: i64) -> *mut *mut C_tensor;
    pub fn atg_split(self_: *mut C_tensor, split_size_: i64, dim_: i64) -> *mut *mut C_tensor;
    pub fn atg_split_with_sizes(self_: *mut C_tensor, split_sizes_data: *const i64, split_sizes_len: c_int, dim_: i64) -> *mut *mut C_tensor;
    pub fn atg_sqrt(self_: *mut C_tensor) -> *mut *mut C_tensor;
    pub fn atg_sqrt_(self_: *mut C_tensor) -> *mut *mut C_tensor;
    pub fn atg_sqrt_out(result_: *mut C_tensor, self_: *mut C_tensor) -> *mut *mut C_tensor;
    pub fn atg_squeeze(self_: *mut C_tensor) -> *mut *mut C_tensor;
    pub fn atg_squeeze1(self_: *mut C_tensor, dim_: i64) -> *mut *mut C_tensor;
    pub fn atg_squeeze_(self_: *mut C_tensor) -> *mut *mut C_tensor;
    pub fn atg_squeeze_1(self_: *mut C_tensor, dim_: i64) -> *mut *mut C_tensor;
    pub fn atg_sspaddmm(self_: *mut C_tensor, mat1_: *mut C_tensor, mat2_: *mut C_tensor) -> *mut *mut C_tensor;
    pub fn atg_sspaddmm_out(result_: *mut C_tensor, self_: *mut C_tensor, mat1_: *mut C_tensor, mat2_: *mut C_tensor) -> *mut *mut C_tensor;
    pub fn atg_stack(tensors_data: *const *mut C_tensor, tensors_len: c_int, dim_: i64) -> *mut *mut C_tensor;
    pub fn atg_stack_out(result_: *mut C_tensor, tensors_data: *const *mut C_tensor, tensors_len: c_int, dim_: i64) -> *mut *mut C_tensor;
    pub fn atg_std(self_: *mut C_tensor, unbiased_: c_int) -> *mut *mut C_tensor;
    pub fn atg_std1(self_: *mut C_tensor, dim_: i64, unbiased_: c_int, keepdim_: c_int) -> *mut *mut C_tensor;
    pub fn atg_std_out(result_: *mut C_tensor, self_: *mut C_tensor, dim_: i64, unbiased_: c_int, keepdim_: c_int) -> *mut *mut C_tensor;
    pub fn atg_stft(self_: *mut C_tensor, n_fft_: i64, hop_length_: i64, win_length_: i64, window_: *mut C_tensor, normalized_: c_int, onesided_: c_int) -> *mut *mut C_tensor;
    pub fn atg_sub(self_: *mut C_tensor, other_: *mut C_tensor) -> *mut *mut C_tensor;
    pub fn atg_sub1(self_: *mut C_tensor, other_: *mut C_scalar) -> *mut *mut C_tensor;
    pub fn atg_sub_(self_: *mut C_tensor, other_: *mut C_tensor) -> *mut *mut C_tensor;
    pub fn atg_sub_1(self_: *mut C_tensor, other_: *mut C_scalar) -> *mut *mut C_tensor;
    pub fn atg_sub_out(result_: *mut C_tensor, self_: *mut C_tensor, other_: *mut C_tensor) -> *mut *mut C_tensor;
    pub fn atg_sum(self_: *mut C_tensor) -> *mut *mut C_tensor;
    pub fn atg_sum1(self_: *mut C_tensor, dtype_: c_int) -> *mut *mut C_tensor;
    pub fn atg_sum2(self_: *mut C_tensor, dim_data: *const i64, dim_len: c_int, keepdim_: c_int) -> *mut *mut C_tensor;
    pub fn atg_sum3(self_: *mut C_tensor, dim_data: *const i64, dim_len: c_int, dtype_: c_int) -> *mut *mut C_tensor;
    pub fn atg_sum4(self_: *mut C_tensor, dim_data: *const i64, dim_len: c_int, keepdim_: c_int, dtype_: c_int) -> *mut *mut C_tensor;
    pub fn atg_sum_out(result_: *mut C_tensor, self_: *mut C_tensor, dim_data: *const i64, dim_len: c_int, keepdim_: c_int) -> *mut *mut C_tensor;
    pub fn atg_sum_out1(result_: *mut C_tensor, self_: *mut C_tensor, dim_data: *const i64, dim_len: c_int, dtype_: c_int) -> *mut *mut C_tensor;
    pub fn atg_sum_out2(result_: *mut C_tensor, self_: *mut C_tensor, dim_data: *const i64, dim_len: c_int, keepdim_: c_int, dtype_: c_int) -> *mut *mut C_tensor;
    pub fn atg_svd(self_: *mut C_tensor, some_: c_int, compute_uv_: c_int) -> *mut *mut C_tensor;
    pub fn atg_svd_out(U_: *mut C_tensor, S_: *mut C_tensor, V_: *mut C_tensor, self_: *mut C_tensor, some_: c_int, compute_uv_: c_int) -> *mut *mut C_tensor;
    pub fn atg_symeig(self_: *mut C_tensor, eigenvectors_: c_int, upper_: c_int) -> *mut *mut C_tensor;
    pub fn atg_symeig_out(e_: *mut C_tensor, V_: *mut C_tensor, self_: *mut C_tensor, eigenvectors_: c_int, upper_: c_int) -> *mut *mut C_tensor;
    pub fn atg_t(self_: *mut C_tensor) -> *mut *mut C_tensor;
    pub fn atg_t_(self_: *mut C_tensor) -> *mut *mut C_tensor;
    pub fn atg_take(self_: *mut C_tensor, index_: *mut C_tensor) -> *mut *mut C_tensor;
    pub fn atg_take_out(result_: *mut C_tensor, self_: *mut C_tensor, index_: *mut C_tensor) -> *mut *mut C_tensor;
    pub fn atg_tan(self_: *mut C_tensor) -> *mut *mut C_tensor;
    pub fn atg_tan_(self_: *mut C_tensor) -> *mut *mut C_tensor;
    pub fn atg_tan_out(result_: *mut C_tensor, self_: *mut C_tensor) -> *mut *mut C_tensor;
    pub fn atg_tanh(self_: *mut C_tensor) -> *mut *mut C_tensor;
    pub fn atg_tanh_(self_: *mut C_tensor) -> *mut *mut C_tensor;
    pub fn atg_tanh_out(result_: *mut C_tensor, self_: *mut C_tensor) -> *mut *mut C_tensor;
    pub fn atg_tensordot(self_: *mut C_tensor, other_: *mut C_tensor, dims_self_data: *const i64, dims_self_len: c_int, dims_other_data: *const i64, dims_other_len: c_int) -> *mut *mut C_tensor;
    pub fn atg_threshold(self_: *mut C_tensor, threshold_: *mut C_scalar, value_: *mut C_scalar) -> *mut *mut C_tensor;
    pub fn atg_threshold_(self_: *mut C_tensor, threshold_: *mut C_scalar, value_: *mut C_scalar) -> *mut *mut C_tensor;
    pub fn atg_threshold_backward(grad_output_: *mut C_tensor, self_: *mut C_tensor, threshold_: *mut C_scalar) -> *mut *mut C_tensor;
    pub fn atg_threshold_out(result_: *mut C_tensor, self_: *mut C_tensor, threshold_: *mut C_scalar, value_: *mut C_scalar) -> *mut *mut C_tensor;
    pub fn atg_to(self_: *mut C_tensor, device_: c_int) -> *mut *mut C_tensor;
    pub fn atg_to1(self_: *mut C_tensor, options_kind: c_int, options_device: c_int, non_blocking_: c_int, copy_: c_int) -> *mut *mut C_tensor;
    pub fn atg_to2(self_: *mut C_tensor, dtype_: c_int, non_blocking_: c_int, copy_: c_int) -> *mut *mut C_tensor;
    pub fn atg_to3(self_: *mut C_tensor, other_: *mut C_tensor, non_blocking_: c_int, copy_: c_int) -> *mut *mut C_tensor;
    pub fn atg_to4(self_: *mut C_tensor, device_: c_int, dtype_: c_int, non_blocking_: c_int, copy_: c_int) -> *mut *mut C_tensor;
    pub fn atg_to_dense(self_: *mut C_tensor) -> *mut *mut C_tensor;
    pub fn atg_to_sparse(self_: *mut C_tensor) -> *mut *mut C_tensor;
    pub fn atg_to_sparse1(self_: *mut C_tensor, sparse_dim_: i64) -> *mut *mut C_tensor;
    pub fn atg_topk(self_: *mut C_tensor, k_: i64, dim_: i64, largest_: c_int, sorted_: c_int) -> *mut *mut C_tensor;
    pub fn atg_topk_out(values_: *mut C_tensor, indices_: *mut C_tensor, self_: *mut C_tensor, k_: i64, dim_: i64, largest_: c_int, sorted_: c_int) -> *mut *mut C_tensor;
    pub fn atg_totype(self_: *mut C_tensor, scalar_type_: c_int) -> *mut *mut C_tensor;
    pub fn atg_trace(self_: *mut C_tensor) -> *mut *mut C_tensor;
    pub fn atg_transpose(self_: *mut C_tensor, dim0_: i64, dim1_: i64) -> *mut *mut C_tensor;
    pub fn atg_transpose_(self_: *mut C_tensor, dim0_: i64, dim1_: i64) -> *mut *mut C_tensor;
    pub fn atg_tril(self_: *mut C_tensor, diagonal_: i64) -> *mut *mut C_tensor;
    pub fn atg_tril_(self_: *mut C_tensor, diagonal_: i64) -> *mut *mut C_tensor;
    pub fn atg_tril_out(result_: *mut C_tensor, self_: *mut C_tensor, diagonal_: i64) -> *mut *mut C_tensor;
    pub fn atg_triplet_margin_loss(anchor_: *mut C_tensor, positive_: *mut C_tensor, negative_: *mut C_tensor, margin_: f64, p_: f64, eps_: f64, swap_: c_int, reduction_: i64) -> *mut *mut C_tensor;
    pub fn atg_triu(self_: *mut C_tensor, diagonal_: i64) -> *mut *mut C_tensor;
    pub fn atg_triu_(self_: *mut C_tensor, diagonal_: i64) -> *mut *mut C_tensor;
    pub fn atg_triu_out(result_: *mut C_tensor, self_: *mut C_tensor, diagonal_: i64) -> *mut *mut C_tensor;
    pub fn atg_trtrs(self_: *mut C_tensor, A_: *mut C_tensor, upper_: c_int, transpose_: c_int, unitriangular_: c_int) -> *mut *mut C_tensor;
    pub fn atg_trtrs_out(X_: *mut C_tensor, M_: *mut C_tensor, self_: *mut C_tensor, A_: *mut C_tensor, upper_: c_int, transpose_: c_int, unitriangular_: c_int) -> *mut *mut C_tensor;
    pub fn atg_trunc(self_: *mut C_tensor) -> *mut *mut C_tensor;
    pub fn atg_trunc_(self_: *mut C_tensor) -> *mut *mut C_tensor;
    pub fn atg_trunc_out(result_: *mut C_tensor, self_: *mut C_tensor) -> *mut *mut C_tensor;
    pub fn atg_type_as(self_: *mut C_tensor, other_: *mut C_tensor) -> *mut *mut C_tensor;
    pub fn atg_unbind(self_: *mut C_tensor, dim_: i64) -> *mut *mut C_tensor;
    pub fn atg_unfold(self_: *mut C_tensor, dimension_: i64, size_: i64, step_: i64) -> *mut *mut C_tensor;
    pub fn atg_uniform_(self_: *mut C_tensor, from_: f64, to_: f64) -> *mut *mut C_tensor;
    pub fn atg_unsqueeze(self_: *mut C_tensor, dim_: i64) -> *mut *mut C_tensor;
    pub fn atg_unsqueeze_(self_: *mut C_tensor, dim_: i64) -> *mut *mut C_tensor;
    pub fn atg_upsample_bilinear2d(self_: *mut C_tensor, output_size_data: *const i64, output_size_len: c_int, align_corners_: c_int) -> *mut *mut C_tensor;
    pub fn atg_upsample_bilinear2d_backward(grad_output_: *mut C_tensor, output_size_data: *const i64, output_size_len: c_int, input_size_data: *const i64, input_size_len: c_int, align_corners_: c_int) -> *mut *mut C_tensor;
    pub fn atg_upsample_bilinear2d_backward_out(grad_input_: *mut C_tensor, grad_output_: *mut C_tensor, output_size_data: *const i64, output_size_len: c_int, input_size_data: *const i64, input_size_len: c_int, align_corners_: c_int) -> *mut *mut C_tensor;
    pub fn atg_upsample_bilinear2d_out(output_: *mut C_tensor, self_: *mut C_tensor, output_size_data: *const i64, output_size_len: c_int, align_corners_: c_int) -> *mut *mut C_tensor;
    pub fn atg_upsample_linear1d(self_: *mut C_tensor, output_size_data: *const i64, output_size_len: c_int, align_corners_: c_int) -> *mut *mut C_tensor;
    pub fn atg_upsample_linear1d_backward(grad_output_: *mut C_tensor, output_size_data: *const i64, output_size_len: c_int, input_size_data: *const i64, input_size_len: c_int, align_corners_: c_int) -> *mut *mut C_tensor;
    pub fn atg_upsample_linear1d_backward_out(grad_input_: *mut C_tensor, grad_output_: *mut C_tensor, output_size_data: *const i64, output_size_len: c_int, input_size_data: *const i64, input_size_len: c_int, align_corners_: c_int) -> *mut *mut C_tensor;
    pub fn atg_upsample_linear1d_out(output_: *mut C_tensor, self_: *mut C_tensor, output_size_data: *const i64, output_size_len: c_int, align_corners_: c_int) -> *mut *mut C_tensor;
    pub fn atg_upsample_nearest1d(self_: *mut C_tensor, output_size_data: *const i64, output_size_len: c_int) -> *mut *mut C_tensor;
    pub fn atg_upsample_nearest1d_backward(grad_output_: *mut C_tensor, output_size_data: *const i64, output_size_len: c_int, input_size_data: *const i64, input_size_len: c_int) -> *mut *mut C_tensor;
    pub fn atg_upsample_nearest1d_backward_out(grad_input_: *mut C_tensor, grad_output_: *mut C_tensor, output_size_data: *const i64, output_size_len: c_int, input_size_data: *const i64, input_size_len: c_int) -> *mut *mut C_tensor;
    pub fn atg_upsample_nearest1d_out(output_: *mut C_tensor, self_: *mut C_tensor, output_size_data: *const i64, output_size_len: c_int) -> *mut *mut C_tensor;
    pub fn atg_upsample_nearest2d(self_: *mut C_tensor, output_size_data: *const i64, output_size_len: c_int) -> *mut *mut C_tensor;
    pub fn atg_upsample_nearest2d_backward(grad_output_: *mut C_tensor, output_size_data: *const i64, output_size_len: c_int, input_size_data: *const i64, input_size_len: c_int) -> *mut *mut C_tensor;
    pub fn atg_upsample_nearest2d_backward_out(grad_input_: *mut C_tensor, grad_output_: *mut C_tensor, output_size_data: *const i64, output_size_len: c_int, input_size_data: *const i64, input_size_len: c_int) -> *mut *mut C_tensor;
    pub fn atg_upsample_nearest2d_out(output_: *mut C_tensor, self_: *mut C_tensor, output_size_data: *const i64, output_size_len: c_int) -> *mut *mut C_tensor;
    pub fn atg_upsample_nearest3d(self_: *mut C_tensor, output_size_data: *const i64, output_size_len: c_int) -> *mut *mut C_tensor;
    pub fn atg_upsample_nearest3d_backward(grad_output_: *mut C_tensor, output_size_data: *const i64, output_size_len: c_int, input_size_data: *const i64, input_size_len: c_int) -> *mut *mut C_tensor;
    pub fn atg_upsample_nearest3d_backward_out(grad_input_: *mut C_tensor, grad_output_: *mut C_tensor, output_size_data: *const i64, output_size_len: c_int, input_size_data: *const i64, input_size_len: c_int) -> *mut *mut C_tensor;
    pub fn atg_upsample_nearest3d_out(output_: *mut C_tensor, self_: *mut C_tensor, output_size_data: *const i64, output_size_len: c_int) -> *mut *mut C_tensor;
    pub fn atg_upsample_trilinear3d(self_: *mut C_tensor, output_size_data: *const i64, output_size_len: c_int, align_corners_: c_int) -> *mut *mut C_tensor;
    pub fn atg_upsample_trilinear3d_backward(grad_output_: *mut C_tensor, output_size_data: *const i64, output_size_len: c_int, input_size_data: *const i64, input_size_len: c_int, align_corners_: c_int) -> *mut *mut C_tensor;
    pub fn atg_upsample_trilinear3d_backward_out(grad_input_: *mut C_tensor, grad_output_: *mut C_tensor, output_size_data: *const i64, output_size_len: c_int, input_size_data: *const i64, input_size_len: c_int, align_corners_: c_int) -> *mut *mut C_tensor;
    pub fn atg_upsample_trilinear3d_out(output_: *mut C_tensor, self_: *mut C_tensor, output_size_data: *const i64, output_size_len: c_int, align_corners_: c_int) -> *mut *mut C_tensor;
    pub fn atg_values(self_: *mut C_tensor) -> *mut *mut C_tensor;
    pub fn atg_var(self_: *mut C_tensor, unbiased_: c_int) -> *mut *mut C_tensor;
    pub fn atg_var1(self_: *mut C_tensor, dim_: i64, unbiased_: c_int, keepdim_: c_int) -> *mut *mut C_tensor;
    pub fn atg_var_out(result_: *mut C_tensor, self_: *mut C_tensor, dim_: i64, unbiased_: c_int, keepdim_: c_int) -> *mut *mut C_tensor;
    pub fn atg_view(self_: *mut C_tensor, size_data: *const i64, size_len: c_int) -> *mut *mut C_tensor;
    pub fn atg_view_as(self_: *mut C_tensor, other_: *mut C_tensor) -> *mut *mut C_tensor;
    pub fn atg_where(condition_: *mut C_tensor, self_: *mut C_tensor, other_: *mut C_tensor) -> *mut *mut C_tensor;
    pub fn atg_zero_(self_: *mut C_tensor) -> *mut *mut C_tensor;
    pub fn atg_zeros(size_data: *const i64, size_len: c_int, options_kind: c_int, options_device: c_int) -> *mut *mut C_tensor;
    pub fn atg_zeros_like(self_: *mut C_tensor) -> *mut *mut C_tensor;
    pub fn atg_zeros_like1(self_: *mut C_tensor, options_kind: c_int, options_device: c_int) -> *mut *mut C_tensor;
    pub fn atg_zeros_out(result_: *mut C_tensor, size_data: *const i64, size_len: c_int) -> *mut *mut C_tensor;
}
